{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ual-laptop\\\\Downloads\\\\Lab7\\\\Lab7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "***Check your kernels before starting!***\n",
    "    \n",
    "<p style=\"text-align:center;\">\n",
    "        <img src=\"Images/Best_Practice.png\" width=500 class=\"center\">\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "## Before you continue!\n",
    "\n",
    "Before we get started, let's first install the modules we'll be using. To do this, navigate to the Launcher tab and open a new Terminal. Run these commands:\n",
    "    \n",
    "```python\n",
    "pip3 install --user 'rake-nltk' 'joblib' 'langdetect' \n",
    "pip3 install --user pyLDAvis==3.2.1\n",
    "```\n",
    "    \n",
    "<p style=\"text-align:center;\">\n",
    "        <img src=Images/Launch_Terminal.png width=500 class=\"center\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Finally, re-open this Notebook.\n",
    "    \n",
    "***NOTE 1:*** You only need to install once!\n",
    "\n",
    "***NOTE 2:*** This will take a few minutes... (be patient!)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## The Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is one of the important parts of natural language processing. \n",
    "\n",
    "The goal of topic modeling is to capture the topics from a set of documents and cluster the documents by their topics. Here, a topic is a cluster of terms that happen to co-occur together frequently across documents in a corpus. With many topic models, documents are seen not in terms of their syntax but instead as a mere \"bag of words.\" In other words, documents are just containers for words, where the order they occur doesn't matter. What does matter is that these words co-occurred together in the same document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LDA Topic Model\n",
    "Here we're going to use of the most popular topic models called a LDA (Latent Dirichlet allocation). Since the LDA model doesn’t have to deal with large matrix processing, it has the fastest process speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "        <img src=\"Images/12_LDA.png\" width=500 class=\"center\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA (short for Latent Dirichlet Allocation) is an unsupervised machine-learning model that takes documents as input and finds topics as output. The model also says in what percentage each document talks about each topic.\n",
    "\n",
    "The mechanics of the LDA model are complex, so let's look at it from a high-level. Assumes you have a corpus made up of documents, and each of these documents are made up of terms. (And like the good computational social scientist, you already stemmed and cleaned-up these terms in each document across the corpus.) The LDA model assumes that the terms of every document is actually a particular mixture of some number of topics, where a topic is characterized by a distribution of terms. \n",
    "\n",
    "Both the topics in a document and words in a topic follow something called a Dirichlet distribution. This distribution is somewhat related to a coin-flip. When you flip a coin, you have one of two options: heads or tails. Now, replace \"heads\" and \"tails\" with the number of topics that exist in your corpus. It's highly unlikely that you have only two topics, so we use the Dirichlet distribution to handle a coin with multiple sides. (Obviously, a coin only has two sides, but I want to make the point that essentially the Dirichlet distribution is a coin-toss with multiple sides.) \n",
    "\n",
    "Thus, a topic is represented as a weighted list of words. An example of a topic is shown below:\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "        <img src=\"Images/12_LDA_2.png\" width=800 class=\"center\">\n",
    "</p>\n",
    "\n",
    "The LDA topic model will \"train\" or \"learn\" these data (think back to machine learning!), and determine the probability distribution of every term across all of the topics. (We can also determine from this the probability distribution of documents across these topics.)\n",
    "\n",
    "\n",
    "So, how many topics are there? There is no correct answer of how many topics there are, because you decide how many exist **before** you run the LDA. This is where both the art and science of LDA comes head-to-head. How we choose the number of objects totally dependents on the purpose of the project. However, there are ways to measure if we picked the number of topics that are a good \"fit\" for our specific data. \n",
    "\n",
    "Thus, there are 3 main parameters of the model:\n",
    "- the number of topics, given by the parameter `K`\n",
    "- `Alpha`, which represents document-topic density. With a higher alpha, documents are made up of more topics, and with lower alpha, documents contain fewer topics. Higher alpha results in a more specific topic distribution per document. \n",
    "- `Beta`, which represents topic-word density. With a higher beta, topics are made up of most of the words in the corpus, and with a low beta they consist of few words. `Beta` results in a more specific word distribution per topic.\n",
    "\n",
    "In reality, the last two parameters are not exactly designed like this in the algorithm, but I prefer to stick to these simplified versions which are easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## LDA and Gibbs Sampling\n",
    "(Source - https://medium.com/mlearning-ai/topic-modelling-with-lda-on-the-tweets-mentioning-elon-musk-687076a2c86b)\n",
    "\n",
    "LDA learns these distribution using Gibbs Sampling. The steps which it follows are:\n",
    "\n",
    "Iterate through each document, and randomly assign each word in the document to one of the m topics.\n",
    "\n",
    "If we look at it closely, we will find that this random assignment gives us both topic distributions for all the n documents and word distributions for all the m topics. Initially, these distributions won’t be very accurate.\n",
    "\n",
    "To improve the distribution for each document d, iterate through each word w in d. For each topic t, compute the two probabilities:\n",
    "\n",
    "1. p(topic t | document d) = number of words in document d that are currently assigned to topic t/total no. of words in d\n",
    "\n",
    "2. p(word w | topic t) = the proportion of assignments to topic t over all documents that come from this word w.\n",
    "\n",
    "Having calculated the above two probabilities, reassign w a new topic, where we choose topic t with probability p(topic t | document d) * p(word w | topic t). Note that for each word, we will get a vector of probabilities that will explain how likely this word belongs to each of the topics.\n",
    "\n",
    "After repeating the previous step a large number of times, you’ll eventually reach a roughly steady state where your assignments are pretty good. So use these assignments to estimate the topic mixtures of each document (by counting the proportion of words assigned to each topic within that document) and the words associated to each topic (by counting the proportion of words assigned to each topic overall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Introducing `Gensim()`\n",
    "\n",
    "We're going to be using `gensim` to run our Topic Models, so let's import them here. \n",
    "\n",
    "First, let's import the modules we'll need. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'rake-nltk'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis==3.2.1\n",
      "  Downloading pyLDAvis-3.2.1.tar.gz (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.5/1.7 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.1/1.7 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.6/1.7 MB 11.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.7 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 8.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (0.38.4)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from pyLDAvis==3.2.1) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.2.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from pyLDAvis==3.2.1) (3.1.2)\n",
      "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (2.8.4)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (0.18.3)\n",
      "Collecting funcy (from pyLDAvis==3.2.1)\n",
      "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.7.2->pyLDAvis==3.2.1) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas>=0.17.0->pyLDAvis==3.2.1) (1.16.0)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (setup.py): started\n",
      "  Building wheel for pyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.1-py2.py3-none-any.whl size=136181 sha256=e6fe5b53a00e50be40b2cdc92bd625bbb2bf5e91fe149c2da90345eb061bdd66\n",
      "  Stored in directory: c:\\users\\ual-laptop\\appdata\\local\\pip\\cache\\wheels\\ae\\69\\44\\1708c54aad5a7e712e19420a0b51ab9a7cbb9fb980b527ab41\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: funcy, pyLDAvis\n",
      "Successfully installed funcy-2.0 pyLDAvis-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user 'rake-nltk' 'joblib' 'langdetect' \n",
    "!pip install --user pyLDAvis==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---- --------------------------------- 112.6/981.5 kB 6.8 MB/s eta 0:00:01\n",
      "     ------------------- ------------------ 491.5/981.5 kB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  972.8/981.5 kB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 7.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=33bd888b54ce27929954f02cba05202c55772231e7e964482f4da5c91d2c1e38\n",
      "  Stored in directory: c:\\users\\ual-laptop\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from rake-nltk) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ual-laptop\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake-nltk) (0.4.6)\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.corpora import Dictionary, MmCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dfply import *\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, let's use a dataset of academic articles published in 2021 taken from the field of sociology. (These data are from the OpenAlex project.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Sociology_Text_df = pd.read_csv('Data/Sociology_Papers_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick peek at these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fieldofstudy</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>paperabstract</th>\n",
       "      <th>year</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>f75fa7229c3c41399f9f90441cda53d04402d1a3</td>\n",
       "      <td>There Can Be More Than One: A Black Man’s Jour...</td>\n",
       "      <td>The underrepresentation of Black Americans as ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>bb6f31cb734cce7f45443fea7a1f2677c617e0de</td>\n",
       "      <td>El itinerario reflexivo: de la desazón discipl...</td>\n",
       "      <td>Las diferentes implicaciones del hombre de cie...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>4389016dea443ead00955d9be19a2410f69b89ac</td>\n",
       "      <td>Boundary spanning and identity work in the cli...</td>\n",
       "      <td>Background Research nurses, midwives and allie...</td>\n",
       "      <td>2021</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>4389016dea443ead00955d9be19a2410f69b89ac</td>\n",
       "      <td>Boundary spanning and identity work in the cli...</td>\n",
       "      <td>Background Research nurses, midwives and allie...</td>\n",
       "      <td>2021</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>097142e05e7ec620b5ffb76fdea214f89aced2d1</td>\n",
       "      <td>Fan centricity of German soccer teams: explori...</td>\n",
       "      <td>ABSTRACT The goal of the present study is to c...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fieldofstudy                                        id  \\\n",
       "0    Sociology  f75fa7229c3c41399f9f90441cda53d04402d1a3   \n",
       "1    Sociology  bb6f31cb734cce7f45443fea7a1f2677c617e0de   \n",
       "2    Sociology  4389016dea443ead00955d9be19a2410f69b89ac   \n",
       "3    Sociology  4389016dea443ead00955d9be19a2410f69b89ac   \n",
       "4    Sociology  097142e05e7ec620b5ffb76fdea214f89aced2d1   \n",
       "\n",
       "                                               title  \\\n",
       "0  There Can Be More Than One: A Black Man’s Jour...   \n",
       "1  El itinerario reflexivo: de la desazón discipl...   \n",
       "2  Boundary spanning and identity work in the cli...   \n",
       "3  Boundary spanning and identity work in the cli...   \n",
       "4  Fan centricity of German soccer teams: explori...   \n",
       "\n",
       "                                       paperabstract  year       countries  \n",
       "0  The underrepresentation of Black Americans as ...  2021   United States  \n",
       "1  Las diferentes implicaciones del hombre de cie...  2021           Spain  \n",
       "2  Background Research nurses, midwives and allie...  2021  United Kingdom  \n",
       "3  Background Research nurses, midwives and allie...  2021  United Kingdom  \n",
       "4  ABSTRACT The goal of the present study is to c...  2021         Germany  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sociology_Text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're only going to use the columns `id` (for paper id), the paper's abstract and the countries of the authors on the paper.\n",
    "\n",
    "There may be a few duplicates, so we'll also drop those papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Sociology_Text_df >>\n",
    "select(\"id\",\"paperabstract\",\"countries\")).drop_duplicates(subset=['id'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again take a quick peek at these data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paperabstract</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f75fa7229c3c41399f9f90441cda53d04402d1a3</td>\n",
       "      <td>The underrepresentation of Black Americans as ...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb6f31cb734cce7f45443fea7a1f2677c617e0de</td>\n",
       "      <td>Las diferentes implicaciones del hombre de cie...</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4389016dea443ead00955d9be19a2410f69b89ac</td>\n",
       "      <td>Background Research nurses, midwives and allie...</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>097142e05e7ec620b5ffb76fdea214f89aced2d1</td>\n",
       "      <td>ABSTRACT The goal of the present study is to c...</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a835b7988a81c825b0d88649159b2100f659050b</td>\n",
       "      <td>This chapter focuses on the dynamics surroundi...</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  f75fa7229c3c41399f9f90441cda53d04402d1a3   \n",
       "1  bb6f31cb734cce7f45443fea7a1f2677c617e0de   \n",
       "2  4389016dea443ead00955d9be19a2410f69b89ac   \n",
       "4  097142e05e7ec620b5ffb76fdea214f89aced2d1   \n",
       "6  a835b7988a81c825b0d88649159b2100f659050b   \n",
       "\n",
       "                                       paperabstract       countries  \n",
       "0  The underrepresentation of Black Americans as ...   United States  \n",
       "1  Las diferentes implicaciones del hombre de cie...           Spain  \n",
       "2  Background Research nurses, midwives and allie...  United Kingdom  \n",
       "4  ABSTRACT The goal of the present study is to c...         Germany  \n",
       "6  This chapter focuses on the dynamics surroundi...    South Africa  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the name of the column `paperabstract` to `articles` and let's remove papers with missing abstract texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Text_df >>\n",
    " select(~X.id) >>\n",
    " rename(articles = \"paperabstract\")>>\n",
    "mask(X.articles!=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many rows we have currently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9411, 2)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remove any NAs from our dataset, as many articles many not have any text associated to it. (E.g., the web scraping process is far from perfect, and sometimes we can't extract data.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Text_df = Text_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many rows we dropped.(We shouldn't drop any with these data, but it's good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9411, 2)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 1 \n",
    "    \n",
    "Now you try!\n",
    "\n",
    "For this checkpoint, just read in similar data to the BBC news articles. These data will come from the New York Times. Label the `DataFrame` as `NYTimes_df`. These New York Times article deal with issues related to Silicon Valley and the tech industry in San Francisco. Since these data are really big, we're just going to subset these data and take the first 1000 rows, hence be sure to use `.head(1000)` when reading in these data. \n",
    "\n",
    "```python\n",
    "NYTimes_df = pd.read_csv('Data/New_York_Times_SF_All.csv').head(1000)\n",
    "```\n",
    "    \n",
    "Explore the data just as you did for the BBC data.  Here, you'll focus on the `article` column. \n",
    "\n",
    "Don't forget to remove NAs! \n",
    "\n",
    "***One small caveat (and this may be useful to you for future work you do):*** Here, we'll remove any document that contains less than 50 characters. Documents with just short sentences, for instance, are not all that informative. So also run the following code below.  \n",
    "\n",
    "This code keeps rows (articles) that have a length of greater than 50 characters. \n",
    "    \n",
    "```python\n",
    "NYTimes_df = (NYTimes_df >>\n",
    " mask(~X.article.isnull()) >>\n",
    " mask(X.article.map(len)>=50))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>A Reversal for InDinero, a Once-Struggling Acc...</td>\n",
       "      <td>54a4149838f0d80267d2a507</td>\n",
       "      <td>In 2012, InDinero had spent nearly all of the ...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/business/sma...</td>\n",
       "      <td>Jessica Mah was 20 when she helped found InDin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Jim Harbaugh Inspires a Run on Khakis at Michigan</td>\n",
       "      <td>54a461a438f0d83a07dc3eff</td>\n",
       "      <td>The football coach takes his baggy khakis alon...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/fashion/jim-...</td>\n",
       "      <td>ANN ARBOR, Mich.  In the final days of the yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Recycling Electronic Waste Responsibly: Excuse...</td>\n",
       "      <td>54a48b3938f0d83a07dc487c</td>\n",
       "      <td>With more retail chains offering drop-off bins...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>MAYBE you replaced old electronics over the ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>What Lies Beneath Takes a Gulp of Air</td>\n",
       "      <td>54a48cd038f0d83a07dc48dd</td>\n",
       "      <td>Flora Grubb introduces minimal steel holders f...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/garden/what-...</td>\n",
       "      <td>People love air plants, but it can be a little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Standouts in Tech: Drones, Virtual Reality, In...</td>\n",
       "      <td>54a4943438f0d83a07dc4a97</td>\n",
       "      <td>Farhad Manjoo picks four products from 2014 th...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>LOTS of cool new technology products come out ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime                                           headline  \\\n",
       "0  1/1/15 0:00  A Reversal for InDinero, a Once-Struggling Acc...   \n",
       "1  1/1/15 0:00  Jim Harbaugh Inspires a Run on Khakis at Michigan   \n",
       "2  1/1/15 0:00  Recycling Electronic Waste Responsibly: Excuse...   \n",
       "3  1/1/15 0:00              What Lies Beneath Takes a Gulp of Air   \n",
       "4  1/1/15 0:00  Standouts in Tech: Drones, Virtual Reality, In...   \n",
       "\n",
       "                         id  \\\n",
       "0  54a4149838f0d80267d2a507   \n",
       "1  54a461a438f0d83a07dc3eff   \n",
       "2  54a48b3938f0d83a07dc487c   \n",
       "3  54a48cd038f0d83a07dc48dd   \n",
       "4  54a4943438f0d83a07dc4a97   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  In 2012, InDinero had spent nearly all of the ...   \n",
       "1  The football coach takes his baggy khakis alon...   \n",
       "2  With more retail chains offering drop-off bins...   \n",
       "3  Flora Grubb introduces minimal steel holders f...   \n",
       "4  Farhad Manjoo picks four products from 2014 th...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.nytimes.com/2015/01/01/business/sma...   \n",
       "1  http://www.nytimes.com/2015/01/01/fashion/jim-...   \n",
       "2  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "3  http://www.nytimes.com/2015/01/01/garden/what-...   \n",
       "4  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "\n",
       "                                             article  \n",
       "0  Jessica Mah was 20 when she helped found InDin...  \n",
       "1  ANN ARBOR, Mich.  In the final days of the yea...  \n",
       "2  MAYBE you replaced old electronics over the ho...  \n",
       "3  People love air plants, but it can be a little...  \n",
       "4  LOTS of cool new technology products come out ...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df = pd.read_csv('Data/New_York_Times_SF_All.csv').head(1000)\n",
    "NYTimes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "NYTimes_df_cleaned = NYTimes_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 6)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Preparing the Data\n",
    "\n",
    "First, we'll need to clean the data. Note here that many of the languages of these articles are NOT in English. For our example, we're only going to focus on English language articles, but you can just as easily run LDAs on different languages.\n",
    "\n",
    "Since we don't have data on whether the article was written in English or not, we need to install a package called `langdetect` that will provide a fairly reasonably guess as to what language each article is written in. \n",
    "\n",
    "Let's import `langdetect`. Specifically, we'll use a function called `detect` from this module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the `apply()` method to the `articles` column in our `DataFrame` and apply a function called `detect` from `langdetect`. It will return a two-letter code for the language it detects in every article.\n",
    "\n",
    "**NOTE:** This will take some time, so be patient. \n",
    "\n",
    "**NOTE:** `langdetect` fails when string length is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Text_df >>\n",
    " mask(X.articles.apply(lambda x: len(x)>10)) >>  \n",
    " mutate(lang = X.articles.apply(detect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at our new column `lang`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>countries</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The underrepresentation of Black Americans as ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las diferentes implicaciones del hombre de cie...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Background Research nurses, midwives and allie...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRACT The goal of the present study is to c...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This chapter focuses on the dynamics surroundi...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>The COVID-19 pandemic forced districts, school...</td>\n",
       "      <td>United States</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9407</th>\n",
       "      <td>Review of: Picture Pedagogy: Visual Culture Co...</td>\n",
       "      <td>Israel</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9408</th>\n",
       "      <td>ABSTRACT This paper reports on an Australian n...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>Movements seeking to infuse markets with moral...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9410</th>\n",
       "      <td>Іntroduction. Historical and legal science, as...</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9395 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               articles       countries lang\n",
       "0     The underrepresentation of Black Americans as ...   United States   en\n",
       "1     Las diferentes implicaciones del hombre de cie...           Spain   es\n",
       "2     Background Research nurses, midwives and allie...  United Kingdom   en\n",
       "3     ABSTRACT The goal of the present study is to c...         Germany   en\n",
       "4     This chapter focuses on the dynamics surroundi...    South Africa   en\n",
       "...                                                 ...             ...  ...\n",
       "9406  The COVID-19 pandemic forced districts, school...   United States   en\n",
       "9407  Review of: Picture Pedagogy: Visual Culture Co...          Israel   en\n",
       "9408  ABSTRACT This paper reports on an Australian n...       Australia   en\n",
       "9409  Movements seeking to infuse markets with moral...  United Kingdom   en\n",
       "9410  Іntroduction. Historical and legal science, as...         Ukraine   en\n",
       "\n",
       "[9395 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It seems to mostly work! \n",
    "\n",
    "Now let's use the `pandas` method `.value_counts()` to see how many papers' abstracts are written in each language. \n",
    "\n",
    "As you can see, `en` (English) is far in the majority. (Given that English is the lingua franca of the sciences and since many databases have English-language biases, this shouldn't come as a surprise.) Since English data are plentiful, we'll use them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    9077\n",
       "fr      69\n",
       "et      68\n",
       "pt      61\n",
       "es      59\n",
       "id      10\n",
       "ru       9\n",
       "de       8\n",
       "af       7\n",
       "hr       7\n",
       "hu       7\n",
       "it       3\n",
       "fa       3\n",
       "bg       1\n",
       "ca       1\n",
       "lv       1\n",
       "cy       1\n",
       "tr       1\n",
       "sv       1\n",
       "ar       1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want English article, let's subset on the new column we just made that contains the language for each article. Let's subset just on English (or `en`) articles, denoted by `en` in the `lang` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Text_df >>\n",
    " mask(X.lang=='en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run `value_counts` again to check our work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    9077\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 2\n",
    "    \n",
    "Now you try!\n",
    "\n",
    "Using the New York Times `DataFrame`, count the number of articles that are in English, and keep only those English  articles. \n",
    "\n",
    "Note, that you'll focus only on the column called `article`. This may take some time! \n",
    "\n",
    "Also recall how we removed any article with less than 50 characters. This is because `detect` will only work if there's enough text to use to determine the language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292 entries, 0 to 291\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   datetime  292 non-null    object\n",
      " 1   headline  292 non-null    object\n",
      " 2   id        292 non-null    object\n",
      " 3   abstract  292 non-null    object\n",
      " 4   url       292 non-null    object\n",
      " 5   article   292 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 13.8+ KB\n"
     ]
    }
   ],
   "source": [
    "NYTimes_df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYTimes_df_cleaned = (NYTimes_df_cleaned >>\n",
    " mask(X.article.apply(lambda x: len(x)>10)) >>  \n",
    " mutate(lang = X.article.apply(detect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>A Reversal for InDinero, a Once-Struggling Acc...</td>\n",
       "      <td>54a4149838f0d80267d2a507</td>\n",
       "      <td>In 2012, InDinero had spent nearly all of the ...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/business/sma...</td>\n",
       "      <td>Jessica Mah was 20 when she helped found InDin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Jim Harbaugh Inspires a Run on Khakis at Michigan</td>\n",
       "      <td>54a461a438f0d83a07dc3eff</td>\n",
       "      <td>The football coach takes his baggy khakis alon...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/fashion/jim-...</td>\n",
       "      <td>ANN ARBOR, Mich.  In the final days of the yea...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Recycling Electronic Waste Responsibly: Excuse...</td>\n",
       "      <td>54a48b3938f0d83a07dc487c</td>\n",
       "      <td>With more retail chains offering drop-off bins...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>MAYBE you replaced old electronics over the ho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>What Lies Beneath Takes a Gulp of Air</td>\n",
       "      <td>54a48cd038f0d83a07dc48dd</td>\n",
       "      <td>Flora Grubb introduces minimal steel holders f...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/garden/what-...</td>\n",
       "      <td>People love air plants, but it can be a little...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Standouts in Tech: Drones, Virtual Reality, In...</td>\n",
       "      <td>54a4943438f0d83a07dc4a97</td>\n",
       "      <td>Farhad Manjoo picks four products from 2014 th...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>LOTS of cool new technology products come out ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime                                           headline  \\\n",
       "0  1/1/15 0:00  A Reversal for InDinero, a Once-Struggling Acc...   \n",
       "1  1/1/15 0:00  Jim Harbaugh Inspires a Run on Khakis at Michigan   \n",
       "2  1/1/15 0:00  Recycling Electronic Waste Responsibly: Excuse...   \n",
       "3  1/1/15 0:00              What Lies Beneath Takes a Gulp of Air   \n",
       "4  1/1/15 0:00  Standouts in Tech: Drones, Virtual Reality, In...   \n",
       "\n",
       "                         id  \\\n",
       "0  54a4149838f0d80267d2a507   \n",
       "1  54a461a438f0d83a07dc3eff   \n",
       "2  54a48b3938f0d83a07dc487c   \n",
       "3  54a48cd038f0d83a07dc48dd   \n",
       "4  54a4943438f0d83a07dc4a97   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  In 2012, InDinero had spent nearly all of the ...   \n",
       "1  The football coach takes his baggy khakis alon...   \n",
       "2  With more retail chains offering drop-off bins...   \n",
       "3  Flora Grubb introduces minimal steel holders f...   \n",
       "4  Farhad Manjoo picks four products from 2014 th...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.nytimes.com/2015/01/01/business/sma...   \n",
       "1  http://www.nytimes.com/2015/01/01/fashion/jim-...   \n",
       "2  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "3  http://www.nytimes.com/2015/01/01/garden/what-...   \n",
       "4  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "\n",
       "                                             article lang  \n",
       "0  Jessica Mah was 20 when she helped found InDin...   en  \n",
       "1  ANN ARBOR, Mich.  In the final days of the yea...   en  \n",
       "2  MAYBE you replaced old electronics over the ho...   en  \n",
       "3  People love air plants, but it can be a little...   en  \n",
       "4  LOTS of cool new technology products come out ...   en  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    292\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df_cleaned.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Corpus\n",
    "\n",
    "Now, we're going to have to do the dirty work of cleaning each paper and preparing it for our LDA. Thankfully, we've actually done this process before, so it should be rather easy. \n",
    "\n",
    "If you are a bit shaky on this process, review the previous labs on cleaning data for a good refresher. \n",
    "\n",
    "We're going to remove punctuation and lemmatize these articles, as well as remove any English stop words from it. In this process, we'll convert each article into a list of tokens to be processed by the LDA. \n",
    "\n",
    "Below, let's define the punctuation, lemmatizer, and stop words, as well as the function that will do the heavy lifting that we explored last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def token_process(doc):\n",
    "    \n",
    "    ## stop words and updates\n",
    "    ## Note, you should add more terms to this list to see what may or may not be useful.\n",
    "    ## Also note, that I also remove punctuation here by adding the string module\n",
    "    stop_en = stopwords.words('english') + list(string.punctuation) + [u'abstract',u'...',u',',u'.',u'?',u'!',u':',u';', u')', u'“', u\"'\", u\"_\",\n",
    "                                                                       u'(',u'[',u']',u'{',u'}',u'%',u'@',u'-',u'`',\n",
    "                                           u'new',u'tr',u'th',u'to',u'on',u'of',u'mr', u\"n't\",\n",
    "                                           u'monday','tuesday',u'wednesday',u'thursday',u'friday',u'saturday',u'sunday','want','befor','becaus'\n",
    "                                           u'said',u'ms',u'york',u'say',u'could',u'q',u'got',u'found',u'began','|',\"''\",\"'s\",\"``\",\"--\",\n",
    "                                           'mr','year','would','one','way','l','ms.','$','mr.','dr.','get','before','like','know','day','because',\n",
    "                                           '\"','see','look','dont','im','&','b','also','de','la','el','en','un','two','al','su','es','lo','se']\n",
    "        \n",
    "    #stemming\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    #lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    #remove punctuation\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #tokenize\n",
    "    tokens = [w.strip() for sent in sent_tokenize(doc) for w in word_tokenize(sent)] if doc else None\n",
    "    \n",
    "    #remove numbers\n",
    "    num_pat = re.compile(r'^(-|\\+)?(\\d*).?(\\d+)')\n",
    "    tokens = filter(lambda x: not num_pat.match(x), tokens)\n",
    "    \n",
    "    #remove dates\n",
    "    date_pat =  re.compile(r'^(\\d{1,2})(/|-)(\\d{1,2})(/|-)(\\d{2,4})$')\n",
    "    tokens = filter(lambda x: not date_pat.match(x), tokens)\n",
    "    \n",
    "    #use stemmer\n",
    "    stemmed_tokens = map(lambda x: stemmer.stem(x), tokens)\n",
    "    \n",
    "    #filter out empty tokens and stopwords\n",
    "    stemmed_tokens = filter(lambda x: x and x.strip() not in stop_en, stemmed_tokens)\n",
    "\n",
    "    #use lemmatizer\n",
    "    lemmatized_and_stemmed_tokens = map(lambda x: lemmatizer.lemmatize(x), stemmed_tokens)\n",
    "\n",
    "    #again filter out empty tokens and stopwords\n",
    "    lemmatized_and_stemmed_tokens = filter(lambda x: x and x.strip() not in stop_en, lemmatized_and_stemmed_tokens)\n",
    "\n",
    "    #remove any lingering white space tokens\n",
    "    lemmatized_and_stemmed_tokens = filter(lambda x: x and x.strip() not in [u' '],lemmatized_and_stemmed_tokens)\n",
    "\n",
    "    #remove any ngram whose length is less than 3\n",
    "    lemmatized_and_stemmed_tokens = filter(lambda x: len(x)>2,lemmatized_and_stemmed_tokens)\n",
    "\n",
    "    x = ' '.join(lemmatized_and_stemmed_tokens)\n",
    "    \n",
    "    #create ngrams from n=2 to 3\n",
    "    bigrams = [bigram[0]+\"_\"+bigram[1] for bigram in list(nltk.ngrams(x.split(' '),2))]\n",
    "    trigrams = [trigram[0]+\"_\"+trigram[1]+\"_\"+trigram[2] for trigram in list(nltk.ngrams(x.split(' '),3))]\n",
    "    \n",
    "    x = x.split(' ')\n",
    "    x.extend(bigrams)\n",
    "    x.extend(trigrams)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply `token_process`, a modified (and combined) function from last time that we apply to the abstract text column. \n",
    "\n",
    "This function will produce tokens that have been put in lower case, lemmatized, and will remove stop words and punctuation. Here, I add more stop words and punctuations that may be unique to this corpus. When you actually do this with your own data, you will need to go back and update this list accordingly.  \n",
    "\n",
    "We'll apply `token_process()` to each row in `articles` by using the `.apply(lambda x:)` `pandas` method. The end result is an paper that was once one long string now turned into a list of tokens that have been cleaned up and ready for processing. \n",
    "\n",
    "N.B., this may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Text_df >>\n",
    " mutate(abstracts_filtered = X.articles.apply(lambda doc: token_process(doc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at this new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [underrepresent, black, american, graduat, stu...\n",
       "2       [background, research, nurs, midwiv, alli, hea...\n",
       "3       [goal, present, studi, conceptu, fan, centric,...\n",
       "4       [chapter, focus, dynam, surround, inclusionari...\n",
       "5       [articl, put, privileg, theori, convers, child...\n",
       "                              ...                        \n",
       "9406    [covid19, pandem, forc, district, school, teac...\n",
       "9407    [review, pictur, pedagogi, visual, cultur, con...\n",
       "9408    [paper, report, australian, nation, investig, ...\n",
       "9409    [movement, seek, infus, market, moral, valu, o...\n",
       "9410    [іntroduct, histor, legal, scienc, well, scien...\n",
       "Name: abstracts_filtered, Length: 9077, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.abstracts_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is now a list of terms extracted from each paper's abstract texts. These data are often refered to as a \"bag of words.\" These sorts of models don't care as much **where** the term is in the document (or abstract in this case), just that these terms are in a document \"bag\" containing these terms (\"words\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Using `RAKE` to Filter Terms, an Alternative Approach\n",
    "\n",
    "Alternatively, we can extract terms using RAKE, which is short for Rapid Automatic Keyword Extraction algorithm. It is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text.\n",
    "\n",
    "Keyphrases are a set of words (or groups of words) that summarize the important points of the paragraph. It isn’t a conclusive summary of the text, it’s just a list of relevant concepts that were discussed in the article.\n",
    "\n",
    "## How Does Keyphrase Extraction Work?\n",
    "\n",
    "***Lemmatize Text:*** It doesn’t make sense to include each and every word in the vocabulary of the text passage when words like writing’, ‘written’, ‘wrote’ as they mean the same: ‘write’. So, we lemmatize text, i.e., bring each word to its root form before anything else.\n",
    "\n",
    "***Select Potential Phrases:*** Text passages contain many words, but not all of them are relevant. Most of them might be frequently used words like ‘a’, ‘that’, ‘then’ and so on. Such words, called stopwords, must be filtered else they will contaminate the output. Consecutive words bearing contextual similarity must be grouped together.\n",
    "\n",
    "***Score Each Phrase:*** Once you have a list of possible phrases, you need to rank them to figure out which one is the most important.\n",
    "\n",
    "Let's give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses stopwords for english from NLTK, and all puntuation characters by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in parameters. For instance, we want unigrams (e.g., min_length=1) through trigrams (e.g., max_length=3), we want to use our stopword list, and remove punctuations. \n",
    "\n",
    "Also, `Rake` will return the same term multiple times, so let's also set `include_repeated_phrases` to `False` so that phrases only show up once in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake(min_length=1,max_length=3,stopwords=stopwords.words('english'),punctuations=string.punctuation,include_repeated_phrases=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `extract_keywords_from_text` to extract `Rake` identified keywords from the text. \n",
    "\n",
    "Let's give it a try with the text below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_rake_text=\"Feature extraction is not that complex. There are many algorithms available that can help you with feature extraction. Rapid Automatic Key Word Extraction is one of those.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.extract_keywords_from_text(example_rake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get keyword phrases ranked highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['many algorithms available', 'feature extraction', 'one', 'help', 'complex']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in `Rake` into a function that we can apply to a corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Phrases_Rake(input_text):\n",
    "    try:\n",
    "        r = Rake(min_length=1,max_length=3,stopwords=stopwords.words('english'),punctuations=string.punctuation,include_repeated_phrases=False)\n",
    "        r.extract_keywords_from_text(input_text)\n",
    "        return r.get_ranked_phrases()\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try!\n",
    "\n",
    "Let's apply `Rake` to our `Text_df` article data and save it to a new column called `abstracts_filtered_rake`. \n",
    "\n",
    "**N.B.**, this may take a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = (Text_df >>\n",
    " mutate(abstracts_filtered_rake = X.articles.apply(lambda doc: Extract_Phrases_Rake(doc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look.\n",
    "\n",
    "How do the two columns, `abstracts_filtered` and `abstracts_filtered_rake` differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>countries</th>\n",
       "      <th>lang</th>\n",
       "      <th>abstracts_filtered</th>\n",
       "      <th>abstracts_filtered_rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The underrepresentation of Black Americans as ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>en</td>\n",
       "      <td>[underrepresent, black, american, graduat, stu...</td>\n",
       "      <td>[criminal justice programs, essay sheds light,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Background Research nurses, midwives and allie...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>en</td>\n",
       "      <td>[background, research, nurs, midwiv, alli, hea...</td>\n",
       "      <td>[tensions involved extend, negotiate complex i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRACT The goal of the present study is to c...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>en</td>\n",
       "      <td>[goal, present, studi, conceptu, fan, centric,...</td>\n",
       "      <td>[two broad themes, inductive coding procedures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This chapter focuses on the dynamics surroundi...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>en</td>\n",
       "      <td>[chapter, focus, dynam, surround, inclusionari...</td>\n",
       "      <td>[importance despite aspects, constraining feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRACT This article puts privilege theory in...</td>\n",
       "      <td>United States</td>\n",
       "      <td>en</td>\n",
       "      <td>[articl, put, privileg, theori, convers, child...</td>\n",
       "      <td>[suggests future directions, largely invisible...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles       countries lang  \\\n",
       "0  The underrepresentation of Black Americans as ...   United States   en   \n",
       "2  Background Research nurses, midwives and allie...  United Kingdom   en   \n",
       "3  ABSTRACT The goal of the present study is to c...         Germany   en   \n",
       "4  This chapter focuses on the dynamics surroundi...    South Africa   en   \n",
       "5  ABSTRACT This article puts privilege theory in...   United States   en   \n",
       "\n",
       "                                  abstracts_filtered  \\\n",
       "0  [underrepresent, black, american, graduat, stu...   \n",
       "2  [background, research, nurs, midwiv, alli, hea...   \n",
       "3  [goal, present, studi, conceptu, fan, centric,...   \n",
       "4  [chapter, focus, dynam, surround, inclusionari...   \n",
       "5  [articl, put, privileg, theori, convers, child...   \n",
       "\n",
       "                             abstracts_filtered_rake  \n",
       "0  [criminal justice programs, essay sheds light,...  \n",
       "2  [tensions involved extend, negotiate complex i...  \n",
       "3  [two broad themes, inductive coding procedures...  \n",
       "4  [importance despite aspects, constraining feat...  \n",
       "5  [suggests future directions, largely invisible...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 3\n",
    "    \n",
    "Now you try!\n",
    "\n",
    "Filter the articles in just the same way as we did here for the sociology papers. Use both the first pre-defined function and the `Rake` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "NYTimes_df_cleaned = (NYTimes_df_cleaned >>\n",
    " mutate(abstracts_filtered = X.article.apply(lambda doc: token_process(doc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [jessica, mah, help, indinero, back, believ, h...\n",
       "1      [ann, arbor, mich, final, rumor, intensifi, ji...\n",
       "2      [mayb, replac, old, electron, holiday, sweep, ...\n",
       "3      [peopl, love, air, plant, littl, tricki, figur...\n",
       "4      [lot, cool, technolog, product, come, everi, u...\n",
       "                             ...                        \n",
       "287    [startup, uber, lyft, make, accept, carpool, t...\n",
       "288    [updat, jeb, bush, technolog, guru, rough, fir...\n",
       "289    [critic, element, puerto, rico, plan, avert, f...\n",
       "290    [hong, kong, last, decad, foreign, technolog, ...\n",
       "291    [never, scientif, career, quit, maryclair, kin...\n",
       "Name: abstracts_filtered, Length: 292, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df_cleaned.abstracts_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Extract_Phrases_Rake(input_text):\n",
    "    try:\n",
    "        r = Rake(min_length=1,max_length=3,stopwords=stopwords.words('english'),punctuations=string.punctuation,include_repeated_phrases=False)\n",
    "        r.extract_keywords_from_text(input_text)\n",
    "        return r.get_ranked_phrases()\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTimes_df_cleaned = (NYTimes_df_cleaned >>\n",
    " mutate(abstracts_filtered_rake = X.article.apply(lambda doc: Extract_Phrases_Rake(doc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>lang</th>\n",
       "      <th>abstracts_filtered</th>\n",
       "      <th>abstracts_filtered_rake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>A Reversal for InDinero, a Once-Struggling Acc...</td>\n",
       "      <td>54a4149838f0d80267d2a507</td>\n",
       "      <td>In 2012, InDinero had spent nearly all of the ...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/business/sma...</td>\n",
       "      <td>Jessica Mah was 20 when she helped found InDin...</td>\n",
       "      <td>en</td>\n",
       "      <td>[jessica, mah, help, indinero, back, believ, h...</td>\n",
       "      <td>[whether theyre working, specialty job boards,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Jim Harbaugh Inspires a Run on Khakis at Michigan</td>\n",
       "      <td>54a461a438f0d83a07dc3eff</td>\n",
       "      <td>The football coach takes his baggy khakis alon...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/fashion/jim-...</td>\n",
       "      <td>ANN ARBOR, Mich.  In the final days of the yea...</td>\n",
       "      <td>en</td>\n",
       "      <td>[ann, arbor, mich, final, rumor, intensifi, ji...</td>\n",
       "      <td>[van boven clothing, san francisco sports, san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Recycling Electronic Waste Responsibly: Excuse...</td>\n",
       "      <td>54a48b3938f0d83a07dc487c</td>\n",
       "      <td>With more retail chains offering drop-off bins...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>MAYBE you replaced old electronics over the ho...</td>\n",
       "      <td>en</td>\n",
       "      <td>[mayb, replac, old, electron, holiday, sweep, ...</td>\n",
       "      <td>[theyve tried hard, theres always ebay, includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>What Lies Beneath Takes a Gulp of Air</td>\n",
       "      <td>54a48cd038f0d83a07dc48dd</td>\n",
       "      <td>Flora Grubb introduces minimal steel holders f...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/garden/what-...</td>\n",
       "      <td>People love air plants, but it can be a little...</td>\n",
       "      <td>en</td>\n",
       "      <td>[peopl, love, air, plant, littl, tricki, figur...</td>\n",
       "      <td>[spindly steel base, flora grubb gardens, said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>Standouts in Tech: Drones, Virtual Reality, In...</td>\n",
       "      <td>54a4943438f0d83a07dc4a97</td>\n",
       "      <td>Farhad Manjoo picks four products from 2014 th...</td>\n",
       "      <td>http://www.nytimes.com/2015/01/01/technology/p...</td>\n",
       "      <td>LOTS of cool new technology products come out ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[lot, cool, technolog, product, come, everi, u...</td>\n",
       "      <td>[white kitchen stove, two pizzas sitting, stil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime                                           headline  \\\n",
       "0  1/1/15 0:00  A Reversal for InDinero, a Once-Struggling Acc...   \n",
       "1  1/1/15 0:00  Jim Harbaugh Inspires a Run on Khakis at Michigan   \n",
       "2  1/1/15 0:00  Recycling Electronic Waste Responsibly: Excuse...   \n",
       "3  1/1/15 0:00              What Lies Beneath Takes a Gulp of Air   \n",
       "4  1/1/15 0:00  Standouts in Tech: Drones, Virtual Reality, In...   \n",
       "\n",
       "                         id  \\\n",
       "0  54a4149838f0d80267d2a507   \n",
       "1  54a461a438f0d83a07dc3eff   \n",
       "2  54a48b3938f0d83a07dc487c   \n",
       "3  54a48cd038f0d83a07dc48dd   \n",
       "4  54a4943438f0d83a07dc4a97   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  In 2012, InDinero had spent nearly all of the ...   \n",
       "1  The football coach takes his baggy khakis alon...   \n",
       "2  With more retail chains offering drop-off bins...   \n",
       "3  Flora Grubb introduces minimal steel holders f...   \n",
       "4  Farhad Manjoo picks four products from 2014 th...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.nytimes.com/2015/01/01/business/sma...   \n",
       "1  http://www.nytimes.com/2015/01/01/fashion/jim-...   \n",
       "2  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "3  http://www.nytimes.com/2015/01/01/garden/what-...   \n",
       "4  http://www.nytimes.com/2015/01/01/technology/p...   \n",
       "\n",
       "                                             article lang  \\\n",
       "0  Jessica Mah was 20 when she helped found InDin...   en   \n",
       "1  ANN ARBOR, Mich.  In the final days of the yea...   en   \n",
       "2  MAYBE you replaced old electronics over the ho...   en   \n",
       "3  People love air plants, but it can be a little...   en   \n",
       "4  LOTS of cool new technology products come out ...   en   \n",
       "\n",
       "                                  abstracts_filtered  \\\n",
       "0  [jessica, mah, help, indinero, back, believ, h...   \n",
       "1  [ann, arbor, mich, final, rumor, intensifi, ji...   \n",
       "2  [mayb, replac, old, electron, holiday, sweep, ...   \n",
       "3  [peopl, love, air, plant, littl, tricki, figur...   \n",
       "4  [lot, cool, technolog, product, come, everi, u...   \n",
       "\n",
       "                             abstracts_filtered_rake  \n",
       "0  [whether theyre working, specialty job boards,...  \n",
       "1  [van boven clothing, san francisco sports, san...  \n",
       "2  [theyve tried hard, theres always ebay, includ...  \n",
       "3  [spindly steel base, flora grubb gardens, said...  \n",
       "4  [white kitchen stove, two pizzas sitting, stil...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Preparing to Run the LDA\n",
    "\n",
    "We'll need to turn this column into a format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, convert this column to a `list` using the `.tolist()` method. \n",
    "\n",
    "Here, let's go ahead and use the `Rake` filtered corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_corpus = Text_df[\"abstracts_filtered_rake\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the corpus is rather long, and since this is meant for demonstrative purposes, let's just use the first 4,000 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_corpus = initial_corpus[0:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick peek at a random document. Feel free to change the index number to take a look at any other document in the corpus.\n",
    "\n",
    "***Warning!: The FULL `initial_corpus` list is very LONG!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rural south india',\n",
       " 'participatory action research',\n",
       " 'knowledge generation phase',\n",
       " 'elucidate forces shaping',\n",
       " 'critical participatory approaches',\n",
       " 'critical disability perspectives',\n",
       " 'participatory analysis conducted',\n",
       " 'restricted occupational possibilities',\n",
       " 'occupational injustice related',\n",
       " 'critical occupational science',\n",
       " 'utilized participatory filmmaking',\n",
       " 'diverse human occupations',\n",
       " 'critical theoretical analysis',\n",
       " 'ways contested responsibility',\n",
       " 'occupational injustices generated',\n",
       " 'theoretical analysis',\n",
       " 'occupational injustices',\n",
       " 'occupational marginalization',\n",
       " 'occupational degradation',\n",
       " 'sanctioned occupations',\n",
       " 'filmmaking process',\n",
       " 'data generated',\n",
       " 'study context',\n",
       " 'situating understandings',\n",
       " 'service providers',\n",
       " 'presenting findings',\n",
       " 'paper illustrates',\n",
       " 'paper contributes',\n",
       " 'nuanced understanding',\n",
       " 'fore fronted',\n",
       " 'findings address',\n",
       " 'enhancing understanding',\n",
       " 'complex layers',\n",
       " 'community members',\n",
       " 'child co',\n",
       " 'ways',\n",
       " 'co',\n",
       " 'well',\n",
       " 'used',\n",
       " 'sociocultural',\n",
       " 'situations',\n",
       " 'researchers',\n",
       " 'project',\n",
       " 'production',\n",
       " 'perpetuation',\n",
       " 'parents',\n",
       " 'par',\n",
       " 'non',\n",
       " 'made',\n",
       " 'issues',\n",
       " 'informed',\n",
       " 'individualization',\n",
       " 'economic',\n",
       " 'diversifying',\n",
       " 'disabilities',\n",
       " 'contributions',\n",
       " 'contribute',\n",
       " 'children',\n",
       " 'centering',\n",
       " 'carried',\n",
       " 'abstract']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_corpus[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Creating the Dictionary\n",
    "\n",
    "From the module `corpora`, we'll use the function `Dictionary` to convert our list of tokens into a `corpora-specific Dictionary` object. We do this because we want to do some \"trimming\" of the corpus that is more easily done (e.g., doesn't take up too much memory) in this format. \n",
    "\n",
    "(Indeed, the biggest challenge with text analysis is memory constraints, so converting objects into other form may be annoying, but is a necessity to avoid a memory leakage issue, halting your code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary_LDA = corpora.Dictionary(initial_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many terms are in our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90552\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary_LDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Most Frequent N-Grams\n",
    "\n",
    "Let's take a look at what are the most popular (frequent) terms in our corpus. Thankfully, using `corpora` to transform our initial corpus, we can use a feature called `.cfs` (short for collection frequencies) from `dictionary_LDA` to get frequency counts. In other words, how many times does this n-gram appear in our corpus? \n",
    "\n",
    "Below, we use a `Dictionary` to cycle through each term in `dictionary_LDA` and return it's frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = {dictionary_LDA[id_]:value_ for id_, value_ in dictionary_LDA.cfs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can use the module `heapq` and the function `nlargest` to get the n-largest terms.\n",
    "\n",
    "Let's look at the 30 most frequency terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'study',\n",
       " 'research',\n",
       " 'abstract',\n",
       " 'however',\n",
       " 'based',\n",
       " 'use',\n",
       " 'development',\n",
       " 'used',\n",
       " 'students',\n",
       " 'role',\n",
       " 'work',\n",
       " 'article',\n",
       " 'analysis',\n",
       " 'context',\n",
       " 'need',\n",
       " 'understanding',\n",
       " 'education',\n",
       " 'covid',\n",
       " 'argue',\n",
       " 'time',\n",
       " 'practice',\n",
       " 'results',\n",
       " 'paper',\n",
       " '1',\n",
       " 'field',\n",
       " 'concept',\n",
       " 'explore',\n",
       " 'one',\n",
       " 'order']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlargest(30,term_frequency, key=term_frequency.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at specific term frequencies. Let's look at the frequency for the term `covid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency['covid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also get a document count. In other words, how many documents does this n-gram appear?\n",
    "\n",
    "Instead of using the `.cfs` feature, we'll use `.dfs` instead (document frequencies). We'll repeat the same procedure as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document_frequency = {dictionary_LDA[id_]:value_ for id_, value_ in dictionary_LDA.dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'study',\n",
       " 'research',\n",
       " 'abstract',\n",
       " 'however',\n",
       " 'based',\n",
       " 'use',\n",
       " 'development',\n",
       " 'used',\n",
       " 'students',\n",
       " 'role',\n",
       " 'work',\n",
       " 'article',\n",
       " 'analysis',\n",
       " 'context',\n",
       " 'need',\n",
       " 'understanding',\n",
       " 'education',\n",
       " 'covid',\n",
       " 'argue',\n",
       " 'time',\n",
       " 'practice',\n",
       " 'results',\n",
       " 'paper',\n",
       " '1',\n",
       " 'field',\n",
       " 'concept',\n",
       " 'explore',\n",
       " 'one',\n",
       " 'order']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlargest(30,term_document_frequency, key=term_document_frequency.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_document_frequency['covid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that many of the top terms are overlaping!\n",
    "\n",
    "This is a good trick to know! You'll likely need to go through your corpus several times to trim many of these unwanted terms. Using document frequencies is a good way to find such terms! This is because terms that exist across multiple documents are often not helpful!\n",
    "\n",
    "For your future work, be sure to go through and use document frequencies to filter out these non-useful terms.\n",
    "\n",
    "Let's use these top terms are remove them from our corpus. \n",
    "\n",
    "First, let's combine these lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = list(set(nlargest(30,term_document_frequency, key=term_document_frequency.get)) & set(nlargest(30,term_frequency, key=term_frequency.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['practice',\n",
       " 'understanding',\n",
       " 'use',\n",
       " 'education',\n",
       " 'covid',\n",
       " 'article',\n",
       " '1',\n",
       " 'need',\n",
       " 'field',\n",
       " 'analysis',\n",
       " 'research',\n",
       " 'time',\n",
       " 'work',\n",
       " 'used',\n",
       " 'well',\n",
       " 'development',\n",
       " 'explore',\n",
       " 'order',\n",
       " 'abstract',\n",
       " 'one',\n",
       " 'argue',\n",
       " 'based',\n",
       " 'paper',\n",
       " 'role',\n",
       " 'results',\n",
       " 'concept',\n",
       " 'study',\n",
       " 'students',\n",
       " 'however',\n",
       " 'context']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do want to keep some terms, like `covid` and `education`, so let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = [term for term in terms_to_remove if term not in ['covid','education']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method called `filter_tokens` to remove these terms. Since this method requires the `id` of the term (and not the term itself), we cause the other method `token2id` to pass in the string to return its id to then pass it into `filter_tokens`.\n",
    "\n",
    "Let's use a `for loop` to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in terms_to_remove:\n",
    "    dictionary_LDA.filter_tokens(bad_ids=[dictionary_LDA.token2id[term]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test this and see if it worked. The term `use` shouldn't be in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"use\" in dictionary_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Filtering Out Words by Counts\n",
    "\n",
    "Many of the words are going to be superfluous: one off words that don't have any meaning that we didn't catch with the stop words. This is rather common, as capturing every token that doesn't have any meaning is near impossible. \n",
    "\n",
    "Instead, we can create a cutoff value that removes terms if they appear less than `n` number of times in the corpus. Here, we can use the `.filter_extremes()` method applied to our `corpora Dictionary`. Use two parameters to filter the dictionary based on frequency in the corpus:\n",
    "\n",
    "- `no_above`: A number between 0 and 1  (a float) refering to a percentage that represents the portion of a word in total corpus size.\n",
    "\n",
    "- `no_below`: An integer (NOT a number between 0 and 1!) reflecting the number of times when a word shows in corpus. It is a threshold.\n",
    "\n",
    "I set `no_below` to 10, so any term that occurs in less than ten documents will be removed. \n",
    "\n",
    "**Note:** This is a bit confusing, but we don't need to save this filtering onto itself. It automatically does it in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary_LDA.filter_extremes(no_below=10,\n",
    "                               no_above=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many terms are now left. How does this compare to the previous number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2496\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary_LDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Creating the Corpus\n",
    "\n",
    "Now, let's prepare the corpus before we submit it to the LDA model. \n",
    "\n",
    "Recall that the LDA model sees documents as a \"bag of words.\" In other words, documents are a big burlap sack of words, and the fact that these words were used in this document means something. Namely, that documents are themselves just collections of topics. We just don't know how many topics and which terms are in these topics. This is the job of the LDA to uncover!\n",
    "\n",
    "For the package `gensim`, we can't merely pass in the list of tokens in its current form. Instead we need to pass it in a very particular format, namely as a list of tuples. In other words, each element in the tuple is a combination of the token: as a unique identifier given as some number, followed by the number of times it appears in this specific document. \n",
    "\n",
    "Let's actually see what this means. First, let's convert our list of documents currently stored as a list of tokens (again, this is found in `initial_corpus`) into a list of tuples of token IDs and the number of times the token appears in the document. \n",
    "\n",
    "We'll use the method `.doc2bow()` &mdash; in other words, document to \"bag of words\" &mdash; to take each \"document\" in the list `initial_corpus` and convert the string tokens into these tuples. \n",
    "\n",
    "So, we use list comprehension to loop through each article in `initial_corpus` and convert every list to a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "LDA_corpus = [dictionary_LDA.doc2bow(doc_) for doc_ in initial_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's again see the first document in the corpus and what it looks like now. \n",
    "\n",
    "***Warning!: The full `LDA_corpus` is going to be LONG!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see a list of tuples `[(,)]`, where the first entry are the unique IDs assigned to each token, followed by the number of times the token appears in this document. \n",
    "\n",
    "Since we used `Rake`, the second value in every tuple will always be 1, since that's how we set up or filtering. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Comparing the Dictionary to the Corpus\n",
    "\n",
    "Let's see how this corresponds to what we have in our `LDA_corpus`. \n",
    "\n",
    "We can use `dictionary_LDA` to convert from a token ID to the actual token. So let's try that out. \n",
    "\n",
    "Let's look at what corresponds to that first ID entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'academy'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_LDA[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for yourself! To do this, use `Control-F` or `Command-F` [depending on your OS] in your browser and search for this term in the first document in `intial_corpus`. \n",
    "\n",
    "It should appear once in the list below for the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criminal justice programs',\n",
       " 'essay sheds light',\n",
       " 'academy creates challenges',\n",
       " 'essay discusses',\n",
       " 'various experiences',\n",
       " 'potentially contribute',\n",
       " 'highest levels',\n",
       " 'graduate students',\n",
       " 'black representation',\n",
       " 'black men',\n",
       " 'black americans',\n",
       " 'academy',\n",
       " 'well',\n",
       " 'underrepresentation',\n",
       " 'sharing',\n",
       " 'recognized',\n",
       " 'lack',\n",
       " 'faculty',\n",
       " 'exist',\n",
       " 'dynamics',\n",
       " 'dearth',\n",
       " 'criminology']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even do this with the original article. Print out the original raw article and search again for the term to find the number of times it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underrepresentation of Black Americans as graduate students and faculty in Criminology and Criminal Justice programs is well-recognized. This essay discusses some of the dynamics of the academy that potentially contribute to the lack of Black representation at the highest levels of the academy. Through the sharing of various experiences, this essay sheds light on how the dearth of Black men in the academy creates challenges for the few Black men that do exist in the academy.\n"
     ]
    }
   ],
   "source": [
    "print(Text_df.articles.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can simply have python go through the first document and count the number of occurances of this term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_corpus[0].count(dictionary_LDA[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how many times `'dynamics'` appears in the whole entire corpus. To do that we'll create a `for-loop` that iterates through the `initial_corpus`, counts every occurance of `'dynamics'` in each document, saves that to a list, and finally sums up that list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "output = list() # creating a blank list \n",
    "for item in initial_corpus:\n",
    "    tally = (item.count(dictionary_LDA[0])) # counting each occurance of \"alli\" \n",
    "    output.append(int(tally)) # appending those frequencies to a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the lists together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(sum(output)) # adding the list together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Counting within the Dictionary \n",
    "\n",
    "On another note, if you want to just view a couple of terms in the `dictionary_LDA`, you can iterate through and print out some values.  \n",
    "\n",
    "Let's have some fun and print out every 100th word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "academy\n",
      "data\n",
      "different\n",
      "interaction\n",
      "discusses\n",
      "areas\n",
      "curriculum\n",
      "deal\n",
      "majority\n",
      "study aims\n",
      "immigration\n",
      "advances\n",
      "helpful\n",
      "aims\n",
      "connection\n",
      "heart\n",
      "digital platforms\n",
      "inclusive education\n",
      "either\n",
      "far\n",
      "peculiarities\n",
      "produce\n",
      "china ’\n",
      "socially\n",
      "future studies\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(dictionary_LDA),100): \n",
    "    print(dictionary_LDA[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now what if we want both the actual terms and their frequency counts? We can do that too!  \n",
    "We can make a `for-loop` that goes through `dictionary_LDA` and combine those names with the tuples in `corpus`, replacing the ID entry with the actual word. This is just a way to make the `corpus` tuples understandable to the human eye.   \n",
    "\n",
    "We're only going through the first document - to go through all we can simply do just corpus without any bracket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('academy', 1),\n",
       "  ('dearth', 1),\n",
       "  ('dynamics', 1),\n",
       "  ('exist', 1),\n",
       "  ('faculty', 1),\n",
       "  ('lack', 1),\n",
       "  ('recognized', 1),\n",
       "  ('sharing', 1)]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(dictionary_LDA[id], freq) for id, freq in cp] for cp in LDA_corpus[:1]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 4 \n",
    "\n",
    "Now you try!\n",
    "\n",
    "Prepare the `Dictionary`, `corpus`, and the `initial_corpus` for the New York Times data. \n",
    "\n",
    "Label the `Dictionary` as `NYTimes_dictionary_LDA`, the `corpus` as `NYTimes_corpus`, and the `initial_corpus` as `NYTimes_initial_corpus`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYTimes_initial_corpus = NYTimes_df_cleaned[\"abstracts_filtered_rake\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYTimes_initial_corpus = NYTimes_initial_corpus[0:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uncommonly skilled politician',\n",
       " 'stage management orchestrated',\n",
       " 'shoreham nuclear plant',\n",
       " 'sexual orientation .)',\n",
       " 'satisfy everyones hopes',\n",
       " 'sagging political image',\n",
       " 'record 65 percent',\n",
       " 'reading passages aloud',\n",
       " 'proposing tax increases',\n",
       " 'owned gulfstream g',\n",
       " 'mother seated onstage',\n",
       " 'mary anne krupsak',\n",
       " 'married matilda n',\n",
       " 'governors unrealized promise',\n",
       " 'five million cast',\n",
       " '8 billion deficit',\n",
       " '244 batting average',\n",
       " '1964 worlds fair',\n",
       " '000 signing bonus',\n",
       " 'youve done everything',\n",
       " 'whose tortuous deliberations',\n",
       " 'westchester county executive',\n",
       " 'roman catholic politicians',\n",
       " 'relatively barren field',\n",
       " 'old sing sing',\n",
       " 'morning telephone calls',\n",
       " 'former housing secretary',\n",
       " 'five percentage points',\n",
       " 'fight drug abuse',\n",
       " 'enjoyed socratic arguments',\n",
       " 'businessman lewis e',\n",
       " 'admired figure outside',\n",
       " 'two chartered airplanes',\n",
       " 'income public housing',\n",
       " 'compelling public presence',\n",
       " 'please dont let',\n",
       " 'play center field',\n",
       " 'often unrestrained personality',\n",
       " 'entered elective politics',\n",
       " 'maria cuomo cole',\n",
       " 'madeline cuomo odonohue',\n",
       " 'cuomo theatrically fixed',\n",
       " 'cuomo remained strained',\n",
       " 'cuomo plays hard',\n",
       " 'cuomo burst beyond',\n",
       " 'class neighborhoods proclaiming',\n",
       " 'challenging ronald reagan',\n",
       " '000 filing fee',\n",
       " 'never fully believed',\n",
       " 'empire state plaza',\n",
       " 'two close advisers',\n",
       " 'see new york',\n",
       " 'stopped taking notes',\n",
       " 'signed ethics legislation',\n",
       " 'personally opposed abortion',\n",
       " 'latin american studies',\n",
       " 'instant prospective candidate',\n",
       " 'freshman baseball team',\n",
       " 'encouraging renewed speculation',\n",
       " 'new yorks history',\n",
       " 'overmatched republican opponent',\n",
       " 'inaugural address struck',\n",
       " 'governors mansion came',\n",
       " 'cuomo inevitably grew',\n",
       " 'entered public life',\n",
       " 'law school success',\n",
       " 'cuomos remaining years',\n",
       " 'judge adrian p',\n",
       " 'entering elective politics',\n",
       " 'johns preparatory school',\n",
       " 'new york times',\n",
       " 'national political career',\n",
       " 'supporters grew disenchanted',\n",
       " 'republicans simply agreed',\n",
       " 'presidential flirtation left',\n",
       " 'pirates scout wrote',\n",
       " 'many democrats assumed',\n",
       " 'land dispute involving',\n",
       " 'democratic field amid',\n",
       " 'argument suggested indecision',\n",
       " 'first round mr',\n",
       " 'two advisers mr',\n",
       " 'theres another part',\n",
       " 'surprise one evening',\n",
       " 'state party leaders',\n",
       " 'pick one thing',\n",
       " 'dont remember dithering',\n",
       " 'disparaged life upstate',\n",
       " 'someone like mr',\n",
       " 'governor endorsed mr',\n",
       " 'cuomo would produce',\n",
       " 'government never wavered',\n",
       " 'political oratory seemed',\n",
       " 'depicting president reagan',\n",
       " 'taken seriously even',\n",
       " 'pataki could pose',\n",
       " 'could appropriately support',\n",
       " 'one point mr',\n",
       " 'local government officials',\n",
       " 'stalled state budget',\n",
       " 'cuomo came within',\n",
       " 'class led mr',\n",
       " 'disdain politics even',\n",
       " 'three years later',\n",
       " 'im sleeping less',\n",
       " '1977 mayoral primary',\n",
       " 'cuomo later said',\n",
       " 'democratic national convention',\n",
       " 'johns law school',\n",
       " 'many democrats failed',\n",
       " 'entering private practice',\n",
       " 'elected chief executive',\n",
       " 'brooklyn law firm',\n",
       " 'cuomo served longer',\n",
       " '1984 democratic convention',\n",
       " 'cuomos son andrew',\n",
       " 'cuomo defeated mr',\n",
       " 'presidential election year',\n",
       " 'death penalty became',\n",
       " 'cuomos first job',\n",
       " 'liberal party line',\n",
       " 'orourke four years',\n",
       " 'carey asked mr',\n",
       " 'cuomo went back',\n",
       " 'new york',\n",
       " 'cuomos advisers',\n",
       " 'percentage point',\n",
       " 'local officials',\n",
       " 'executive mansion',\n",
       " 'republican opponent',\n",
       " 'law firm',\n",
       " 'chief executive',\n",
       " 'struck mr',\n",
       " 'cuomo secretary',\n",
       " 'democratic convention',\n",
       " 'law career',\n",
       " 'chief judge',\n",
       " 'weeks later',\n",
       " '000 votes',\n",
       " 'national politics',\n",
       " 'andrew p',\n",
       " 'cuomo seemed',\n",
       " 'andrew cuomo',\n",
       " 'liberal politics',\n",
       " 'convention center',\n",
       " 'worsening times',\n",
       " 'within days',\n",
       " 'whose relationship',\n",
       " 'states history',\n",
       " 'spoke suggested',\n",
       " 'saturdays served',\n",
       " 'roman catholicism',\n",
       " 'next morning',\n",
       " 'neighborhood dispute',\n",
       " 'lifelong disdain',\n",
       " 'legislature agreed',\n",
       " 'led pundits',\n",
       " 'grew wealthy',\n",
       " 'george e',\n",
       " 'formidable figure',\n",
       " 'filing deadline',\n",
       " 'enjoyed victories',\n",
       " 'done better',\n",
       " 'divisive fight',\n",
       " 'democratic nomination',\n",
       " 'democratic congressman',\n",
       " 'death penalty',\n",
       " 'brunswick pirates',\n",
       " 'always practice',\n",
       " 'cuomo could',\n",
       " 'state address',\n",
       " 'national party',\n",
       " 'two needed',\n",
       " 'two images',\n",
       " 'two headed',\n",
       " 'two cities',\n",
       " 'new yorkers',\n",
       " 'new schedule',\n",
       " 'new hampshire',\n",
       " 'smaller school',\n",
       " 'public opinion',\n",
       " 'cuomos manner',\n",
       " 'cuomos intention',\n",
       " 'cuomos identity',\n",
       " 'cuomos chance',\n",
       " 'years afterward',\n",
       " 'ruthless one',\n",
       " 'often expressed',\n",
       " 'often directed',\n",
       " 'moscone center',\n",
       " 'keynote address',\n",
       " 'explanation failed',\n",
       " 'engine failed',\n",
       " 'early years',\n",
       " 'baseball career',\n",
       " 'another scenario',\n",
       " 'another rejected',\n",
       " '5 p',\n",
       " 'urged mr',\n",
       " 'undercutting mr',\n",
       " 'pataki mr',\n",
       " 'overwhelm mr',\n",
       " 'named mr',\n",
       " 'invite mr',\n",
       " 'hammering mr',\n",
       " 'defeating mr',\n",
       " 'centrist mr',\n",
       " 'immaculata cuomo',\n",
       " 'cuomo volunteered',\n",
       " 'cuomo tied',\n",
       " 'cuomo seized',\n",
       " 'cuomo said',\n",
       " 'cuomo replied',\n",
       " 'cuomo proceeded',\n",
       " 'cuomo noted',\n",
       " 'cuomo forged',\n",
       " 'cuomo finished',\n",
       " 'cuomo endure',\n",
       " 'cuomo described',\n",
       " 'cuomo became',\n",
       " 'cuomo asserted',\n",
       " 'christopher cuomo',\n",
       " 'state government',\n",
       " 'son andrew',\n",
       " 'seemed inexhaustible',\n",
       " 'reagan policies',\n",
       " 'national travel',\n",
       " 'national stature',\n",
       " 'mario grew',\n",
       " 'many ways',\n",
       " 'persuade even',\n",
       " 'party favorite',\n",
       " 'liberal wing',\n",
       " 'liberal vision',\n",
       " 'liberal thought',\n",
       " 'johns alumnus',\n",
       " 'even disingenuousness',\n",
       " 'could trim',\n",
       " 'presidential run',\n",
       " 'old man',\n",
       " 'would never',\n",
       " 'prevent government',\n",
       " 'never wanted',\n",
       " 'never identified',\n",
       " 'government afloat',\n",
       " 'activist government',\n",
       " 'state senator',\n",
       " 'state revenues',\n",
       " 'state payroll',\n",
       " 'state legislature',\n",
       " 'state funds',\n",
       " 'ninth state',\n",
       " 'first engaged',\n",
       " 'first bid',\n",
       " 'mario cuomo',\n",
       " 'cuomo turned',\n",
       " 'youre telling',\n",
       " 'write books',\n",
       " 'would recall',\n",
       " 'wonderful year',\n",
       " 'willkie farr',\n",
       " 'widely expected',\n",
       " 'whole heart',\n",
       " 'white house',\n",
       " 'water mark',\n",
       " 'washington post',\n",
       " 'victory brought',\n",
       " 'unsatisfying victory',\n",
       " 'unlikely position',\n",
       " 'united states',\n",
       " 'union organizers',\n",
       " 'unhappy passage',\n",
       " 'unending fascination',\n",
       " 'ugly business',\n",
       " 'traveling across',\n",
       " 'tim russert',\n",
       " 'threat hangs',\n",
       " 'third term',\n",
       " 'term governor',\n",
       " 'tenacious debater',\n",
       " 'supreme court',\n",
       " 'support network',\n",
       " 'suit prohibiting',\n",
       " 'successfully lobbied',\n",
       " 'step aside',\n",
       " 'states boundaries',\n",
       " 'speaking generally',\n",
       " 'somehow got',\n",
       " 'small town',\n",
       " 'similarly resolute',\n",
       " 'shabbos goy',\n",
       " 'seven members',\n",
       " 'san francisco',\n",
       " 'running mate',\n",
       " 'rolling cadences',\n",
       " 'rich enough',\n",
       " 'restless intellect',\n",
       " 'republican nominee',\n",
       " 'reportedly receiving',\n",
       " 'rent strike',\n",
       " 'relatively low',\n",
       " 'regular appearance',\n",
       " 'reagans description',\n",
       " 'raw truth',\n",
       " 'quarrelsome mood',\n",
       " 'pulled back',\n",
       " 'providing shelter',\n",
       " 'providing services',\n",
       " 'profile job',\n",
       " 'prison strike',\n",
       " 'prison cells',\n",
       " 'primary brawl',\n",
       " 'presidential ambitions',\n",
       " 'president sees',\n",
       " 'preserved 55',\n",
       " 'precise parsing',\n",
       " 'power declines',\n",
       " 'potential dangers',\n",
       " 'polish neighborhood',\n",
       " 'pointed sense',\n",
       " 'playboy magazine',\n",
       " 'personal ambition',\n",
       " 'pataki defeated',\n",
       " 'partys choice',\n",
       " 'overseas travel',\n",
       " 'orthodox synagogue',\n",
       " 'original ethnic',\n",
       " 'october 1991',\n",
       " 'obvious potential',\n",
       " 'notre dame',\n",
       " 'next year',\n",
       " 'next term',\n",
       " 'news media',\n",
       " 'news conference',\n",
       " 'net result',\n",
       " 'need help',\n",
       " 'nearly derailed',\n",
       " 'muscular campaigning',\n",
       " 'mohawk reservation',\n",
       " 'mark conrad',\n",
       " 'lindsay recruited',\n",
       " 'lieutenant governor',\n",
       " 'lehrmans wristwatch',\n",
       " 'left blind',\n",
       " 'last weeks',\n",
       " 'large intellect',\n",
       " 'large initiative',\n",
       " 'laden early',\n",
       " 'labor unions',\n",
       " 'june 15',\n",
       " 'july 16',\n",
       " 'increasingly discredited',\n",
       " 'including judith',\n",
       " 'impoverished americans',\n",
       " 'im telling',\n",
       " 'hugh l',\n",
       " 'host meet',\n",
       " 'heart failure',\n",
       " 'grown weary',\n",
       " 'grim footnotes',\n",
       " 'governor carey',\n",
       " 'governor aboard',\n",
       " 'gotten credit',\n",
       " 'general election',\n",
       " 'friday evening',\n",
       " 'french theologian',\n",
       " 'fourth term',\n",
       " 'forest hills',\n",
       " 'forceful defense',\n",
       " 'flight back',\n",
       " 'fiscal prudence',\n",
       " 'fiscal obstacles',\n",
       " 'financial consultant',\n",
       " 'fellow student',\n",
       " 'february 1987',\n",
       " 'familiar theme',\n",
       " 'experience fed',\n",
       " 'expensive watch',\n",
       " 'exhaustive ruminations',\n",
       " 'everyone else',\n",
       " 'enough votes',\n",
       " 'eloquent spokesman',\n",
       " 'electric spirit',\n",
       " 'election ticket',\n",
       " 'economics adviser',\n",
       " 'despite friction',\n",
       " 'deep cuts',\n",
       " 'declaration reflected',\n",
       " 'confidential assistant',\n",
       " 'closest friends',\n",
       " 'careers worth',\n",
       " 'capital offenses',\n",
       " 'cant find',\n",
       " 'cannot turn',\n",
       " 'block construction',\n",
       " 'big house',\n",
       " 'bad back',\n",
       " 'answer questions',\n",
       " 'american neighborhood',\n",
       " 'always given',\n",
       " 'always bothered',\n",
       " 'always attuned',\n",
       " 'also offered',\n",
       " 'almost 100',\n",
       " 'age 50',\n",
       " 'age 19',\n",
       " '90 minutes',\n",
       " '67 acres',\n",
       " '1955 ),',\n",
       " '190 pounds',\n",
       " '19 guards',\n",
       " '14 grandchildren',\n",
       " 'home mr',\n",
       " 'cuomo family',\n",
       " 'cuomo announced',\n",
       " 'first time',\n",
       " 'johns university',\n",
       " 'volatile city',\n",
       " 'shining city',\n",
       " 'op city',\n",
       " 'jersey city',\n",
       " 'city wanted',\n",
       " 'one lawyer',\n",
       " 'judge burke',\n",
       " 'turbulent time',\n",
       " 'time pollster',\n",
       " 'third time',\n",
       " 'every time',\n",
       " 'though mr',\n",
       " '1974 mr',\n",
       " 'never run',\n",
       " 'state university',\n",
       " 'state legislators',\n",
       " 'cuomo settled',\n",
       " 'cuomo returned',\n",
       " 'cuomo pressed',\n",
       " 'cuomo liked',\n",
       " 'put first',\n",
       " 'unpopular view',\n",
       " 'turned ashen',\n",
       " 'seemed unaware',\n",
       " 'people asked',\n",
       " 'national recession',\n",
       " 'national audience',\n",
       " 'months saying',\n",
       " 'mario worked',\n",
       " 'harsh campaign',\n",
       " 'election campaign',\n",
       " 'different view',\n",
       " 'democrats embraced',\n",
       " 'conning people',\n",
       " 'class families',\n",
       " 'characteristically turned',\n",
       " 'campaign adviser',\n",
       " 'affirmative view',\n",
       " '600 people',\n",
       " 'would put',\n",
       " 'would challenge',\n",
       " 'serious challenge',\n",
       " 'reporter back',\n",
       " 'reporter across',\n",
       " 'really waiting',\n",
       " 'president clinton',\n",
       " 'planes waiting',\n",
       " 'partys nominee',\n",
       " 'legislators discovered',\n",
       " 'koch said',\n",
       " 'home soared',\n",
       " 'george clinton',\n",
       " 'finance much',\n",
       " 'family confirmed',\n",
       " 'carey announced',\n",
       " 'albany building',\n",
       " '52nd man',\n",
       " 'state employees',\n",
       " 'first woman',\n",
       " 'first love',\n",
       " 'television set',\n",
       " 'surpassed rockefeller',\n",
       " 'struggling americans',\n",
       " 'spellbinding speaker',\n",
       " 'speak english',\n",
       " 'south jamaica',\n",
       " 'sometimes brought',\n",
       " 'second term',\n",
       " 'redemptive moment',\n",
       " 'radio call',\n",
       " 'queens neighborhood',\n",
       " 'proclaimed 1988',\n",
       " 'presidency became',\n",
       " 'positive source',\n",
       " 'popularity ratings',\n",
       " 'mondale fail',\n",
       " 'might respond',\n",
       " 'mafia existed',\n",
       " 'long island',\n",
       " 'kochs candidacy',\n",
       " 'keynote speech',\n",
       " 'kept talking',\n",
       " 'ive sworn',\n",
       " 'held hostage',\n",
       " 'grocery store',\n",
       " 'greater good',\n",
       " 'give speeches',\n",
       " 'game leaving',\n",
       " 'fourth child',\n",
       " 'final week',\n",
       " 'fellow st',\n",
       " 'everyone seems',\n",
       " 'election behind',\n",
       " 'effectively lost',\n",
       " 'deprecating humor',\n",
       " 'defeated gov',\n",
       " 'december 1991',\n",
       " 'crushing defeat',\n",
       " 'collar italian',\n",
       " 'become governor',\n",
       " 'barely noticed',\n",
       " 'annual veto',\n",
       " 'also perceived',\n",
       " '53 hours',\n",
       " '2 fastball',\n",
       " 'city decided',\n",
       " 'saying thats',\n",
       " 'keep saying',\n",
       " 'much interest',\n",
       " 'koch declined',\n",
       " 'albany airport',\n",
       " 'sleep well',\n",
       " 'runoff handily',\n",
       " 'school',\n",
       " 'public',\n",
       " 'years',\n",
       " 'politics',\n",
       " 'one',\n",
       " 'life',\n",
       " 'law',\n",
       " 'entering',\n",
       " 'dont',\n",
       " 'came',\n",
       " 'mr',\n",
       " 'cuomo',\n",
       " 'reagan',\n",
       " 'many',\n",
       " 'democrats',\n",
       " 'class',\n",
       " 'party',\n",
       " 'johns',\n",
       " 'even',\n",
       " 'could',\n",
       " 'convention',\n",
       " 'never',\n",
       " 'government',\n",
       " 'state',\n",
       " 'first',\n",
       " 'year',\n",
       " 'wrote',\n",
       " 'would',\n",
       " 'went',\n",
       " 'upstate',\n",
       " 'three',\n",
       " 'taking',\n",
       " 'taken',\n",
       " 'supporters',\n",
       " 'support',\n",
       " 'speculation',\n",
       " 'son',\n",
       " 'someone',\n",
       " 'simply',\n",
       " 'signed',\n",
       " 'said',\n",
       " 'private',\n",
       " 'primary',\n",
       " 'president',\n",
       " 'pick',\n",
       " 'pataki',\n",
       " 'part',\n",
       " 'orourke',\n",
       " 'oratory',\n",
       " 'longer',\n",
       " 'line',\n",
       " 'less',\n",
       " 'left',\n",
       " 'land',\n",
       " 'job',\n",
       " 'im',\n",
       " 'governor',\n",
       " 'four',\n",
       " 'evening',\n",
       " 'election',\n",
       " 'elected',\n",
       " 'dithering',\n",
       " 'defeated',\n",
       " 'death',\n",
       " 'carey',\n",
       " 'candidate',\n",
       " 'budget',\n",
       " 'brooklyn',\n",
       " 'became',\n",
       " 'baseball',\n",
       " 'back',\n",
       " 'asked',\n",
       " 'argument',\n",
       " 'amid',\n",
       " 'american',\n",
       " 'abortion',\n",
       " '1984',\n",
       " '1977',\n",
       " 'city',\n",
       " 'time',\n",
       " 'view',\n",
       " 'turned',\n",
       " 'saying',\n",
       " 'people',\n",
       " 'mario',\n",
       " 'campaign',\n",
       " 'waiting',\n",
       " 'university',\n",
       " 'run',\n",
       " 'reporter',\n",
       " 'put',\n",
       " 'nominee',\n",
       " 'much',\n",
       " 'man',\n",
       " 'legislators',\n",
       " 'koch',\n",
       " 'home',\n",
       " 'family',\n",
       " 'clinton',\n",
       " 'challenge',\n",
       " 'announced',\n",
       " 'albany',\n",
       " 'woman',\n",
       " 'well',\n",
       " 'week',\n",
       " 'veto',\n",
       " 'unaware',\n",
       " 'though',\n",
       " 'thats',\n",
       " 'sworn',\n",
       " 'struggling',\n",
       " 'store',\n",
       " 'st',\n",
       " 'speech',\n",
       " 'speaker',\n",
       " 'south',\n",
       " 'source',\n",
       " 'sometimes',\n",
       " 'sleep',\n",
       " 'settled',\n",
       " 'set',\n",
       " 'seems',\n",
       " 'second',\n",
       " 'runoff',\n",
       " 'rockefeller',\n",
       " 'returned',\n",
       " 'recession',\n",
       " 'queens',\n",
       " 'pressed',\n",
       " 'presidency',\n",
       " 'popularity',\n",
       " 'perceived',\n",
       " 'noticed',\n",
       " 'mondale',\n",
       " 'moment',\n",
       " 'might',\n",
       " 'mafia',\n",
       " 'low',\n",
       " 'love',\n",
       " 'lost',\n",
       " 'long',\n",
       " 'liked',\n",
       " 'lawyer',\n",
       " 'kept',\n",
       " 'keep',\n",
       " 'italian',\n",
       " 'interest',\n",
       " 'humor',\n",
       " 'hours',\n",
       " 'held',\n",
       " 'handily',\n",
       " 'gov',\n",
       " 'good',\n",
       " 'give',\n",
       " 'game',\n",
       " 'families',\n",
       " 'english',\n",
       " 'employees',\n",
       " 'embraced',\n",
       " 'defeat',\n",
       " 'declined',\n",
       " 'decided',\n",
       " 'december',\n",
       " 'child',\n",
       " 'candidacy',\n",
       " 'call',\n",
       " 'burke',\n",
       " 'behind',\n",
       " 'become',\n",
       " 'audience',\n",
       " 'ambitions',\n",
       " 'airport',\n",
       " '2',\n",
       " '1988',\n",
       " '1974',\n",
       " 'yet',\n",
       " 'work',\n",
       " 'words',\n",
       " 'word',\n",
       " 'withdrew',\n",
       " 'withdrawn',\n",
       " 'winner',\n",
       " 'win',\n",
       " 'wife',\n",
       " 'whether',\n",
       " 'wherever',\n",
       " 'whats',\n",
       " 'weisbrod',\n",
       " 'way',\n",
       " 'want',\n",
       " 'walked',\n",
       " 'vote',\n",
       " 'voice',\n",
       " 'virtue',\n",
       " 'viewing',\n",
       " 'verge',\n",
       " 'veranda',\n",
       " 'use',\n",
       " 'urging',\n",
       " 'uproar',\n",
       " 'unsportsmanlike',\n",
       " 'undermined',\n",
       " 'unable',\n",
       " 'ultimately',\n",
       " 'trying',\n",
       " 'trouble',\n",
       " 'triumph',\n",
       " 'trip',\n",
       " 'tried',\n",
       " 'trepidation',\n",
       " 'took',\n",
       " 'told',\n",
       " 'tinged',\n",
       " 'thwarted',\n",
       " 'thursday',\n",
       " 'think',\n",
       " 'things',\n",
       " 'testimony',\n",
       " 'teacher',\n",
       " 'taxes',\n",
       " 'tarmac',\n",
       " 'talk',\n",
       " 'tale',\n",
       " 'syracuse',\n",
       " 'symbols',\n",
       " 'swore',\n",
       " 'survives',\n",
       " 'survived',\n",
       " 'supported',\n",
       " 'summer',\n",
       " 'sum',\n",
       " 'suggestions',\n",
       " 'succeeded',\n",
       " 'suburbs',\n",
       " 'stunning',\n",
       " 'stunned',\n",
       " 'studied',\n",
       " 'struggled',\n",
       " 'street',\n",
       " 'story',\n",
       " 'storm',\n",
       " 'stood',\n",
       " 'stilling',\n",
       " 'still',\n",
       " 'sterile',\n",
       " 'start',\n",
       " 'staff',\n",
       " 'spent',\n",
       " 'sought',\n",
       " 'smoke',\n",
       " 'size',\n",
       " 'sizable',\n",
       " 'site',\n",
       " 'sin',\n",
       " 'shrinking',\n",
       " 'show',\n",
       " 'short',\n",
       " 'settling',\n",
       " 'serve',\n",
       " 'series',\n",
       " 'sept',\n",
       " 'self',\n",
       " 'seizing',\n",
       " 'seeking',\n",
       " 'seek',\n",
       " 'seat',\n",
       " 'sea',\n",
       " 'scholarship',\n",
       " 'scenes',\n",
       " 'say',\n",
       " 'saw',\n",
       " 'salerno',\n",
       " 'sails',\n",
       " 'sabbath',\n",
       " 'ruse',\n",
       " 'runway',\n",
       " 'role',\n",
       " 'rite',\n",
       " 'rinfret',\n",
       " 'right',\n",
       " 'ridicule',\n",
       " 'reveled',\n",
       " 'retreated',\n",
       " 'response',\n",
       " 'responded',\n",
       " 'request',\n",
       " 'reputation',\n",
       " 'republic',\n",
       " 'reprised',\n",
       " 'reporters',\n",
       " 'remembered',\n",
       " 'remarks',\n",
       " 'remarked',\n",
       " 'reinvigorate',\n",
       " 'regrets',\n",
       " 'refused',\n",
       " 'realized',\n",
       " 'rather',\n",
       " 'ranch',\n",
       " 'ran',\n",
       " 'raised',\n",
       " 'rage',\n",
       " 'raffa',\n",
       " 'race',\n",
       " 'puff',\n",
       " 'publication',\n",
       " 'proving',\n",
       " 'province',\n",
       " 'provided',\n",
       " 'proved',\n",
       " 'prospect',\n",
       " 'property',\n",
       " 'prominent',\n",
       " 'project',\n",
       " 'programs',\n",
       " 'profession',\n",
       " 'proclaim',\n",
       " 'problems',\n",
       " 'problem',\n",
       " 'principles',\n",
       " 'prevented',\n",
       " 'press',\n",
       " 'presidents',\n",
       " 'preparing',\n",
       " 'pray',\n",
       " 'pounded',\n",
       " 'positions',\n",
       " 'portraying',\n",
       " 'portray',\n",
       " 'portico',\n",
       " 'pop',\n",
       " 'poor',\n",
       " 'pomp',\n",
       " 'played',\n",
       " 'placards',\n",
       " 'pinned',\n",
       " 'pierre',\n",
       " 'phone',\n",
       " 'philosophy',\n",
       " 'personify',\n",
       " 'perhaps',\n",
       " 'penniless',\n",
       " 'peekskill',\n",
       " 'pay',\n",
       " 'pass',\n",
       " 'parkland',\n",
       " 'parents',\n",
       " 'overshadowing',\n",
       " 'overruled',\n",
       " 'ought',\n",
       " 'ossining',\n",
       " 'ornate',\n",
       " 'organization',\n",
       " 'opposition',\n",
       " 'opportunity',\n",
       " 'opened',\n",
       " 'office',\n",
       " 'offering',\n",
       " 'offer',\n",
       " 'occurred',\n",
       " 'obviously',\n",
       " 'obscenity',\n",
       " 'object',\n",
       " 'obituary',\n",
       " 'november',\n",
       " 'nov',\n",
       " 'noting',\n",
       " 'notice',\n",
       " 'non',\n",
       " 'night',\n",
       " 'nelson',\n",
       " 'negotiating',\n",
       " 'nation',\n",
       " 'naples',\n",
       " 'naming',\n",
       " 'name',\n",
       " 'moved',\n",
       " 'money',\n",
       " 'misplayed',\n",
       " 'middle',\n",
       " 'michael',\n",
       " 'message',\n",
       " 'mediator',\n",
       " 'mediated',\n",
       " 'mediate',\n",
       " 'mayors',\n",
       " 'mayor',\n",
       " 'may',\n",
       " 'matter',\n",
       " 'margaret',\n",
       " 'mankind',\n",
       " 'manhattan',\n",
       " 'making',\n",
       " 'majored',\n",
       " 'made',\n",
       " 'lot',\n",
       " 'looming',\n",
       " 'looking',\n",
       " 'living',\n",
       " 'lived',\n",
       " 'little',\n",
       " 'lights',\n",
       " 'liberalism',\n",
       " 'liar',\n",
       " 'lew',\n",
       " 'lesson',\n",
       " 'lehrman',\n",
       " 'legacy',\n",
       " 'lectern',\n",
       " 'learning',\n",
       " 'learned',\n",
       " 'lamented',\n",
       " 'know',\n",
       " 'knocked',\n",
       " 'kaye',\n",
       " 'journalist',\n",
       " 'joined',\n",
       " 'jew',\n",
       " 'jan',\n",
       " 'issue',\n",
       " 'irish',\n",
       " 'irate',\n",
       " 'invoked',\n",
       " 'invited',\n",
       " 'interview',\n",
       " 'instead',\n",
       " 'inherited',\n",
       " 'inflections',\n",
       " 'infirm',\n",
       " 'indignation',\n",
       " 'incompetent',\n",
       " 'inaugurated',\n",
       " 'idle',\n",
       " 'ideas',\n",
       " 'hurt',\n",
       " 'hudson',\n",
       " 'however',\n",
       " 'hostages',\n",
       " 'hope',\n",
       " 'homo',\n",
       " 'homes',\n",
       " 'homeless',\n",
       " 'hill',\n",
       " 'high',\n",
       " 'height',\n",
       " 'head',\n",
       " 'happy',\n",
       " 'hands',\n",
       " 'hand',\n",
       " 'hamlet',\n",
       " 'half',\n",
       " 'guessing',\n",
       " 'grain',\n",
       " 'graduating',\n",
       " 'graduated',\n",
       " 'grace',\n",
       " 'governorship',\n",
       " 'god',\n",
       " 'glanced',\n",
       " 'get',\n",
       " 'german',\n",
       " 'georgia',\n",
       " 'gaze',\n",
       " 'gallagher',\n",
       " 'full',\n",
       " 'frustration',\n",
       " 'froeb',\n",
       " 'freed',\n",
       " 'found',\n",
       " 'forget',\n",
       " ...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_initial_corpus[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating the Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYTimes_dictionary_LDA = corpora.Dictionary(NYTimes_initial_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45008\n"
     ]
    }
   ],
   "source": [
    "print(len(NYTimes_dictionary_LDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYTimes_corpus = [NYTimes_dictionary_LDA.doc2bow(doc_) for doc_ in NYTimes_initial_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (63, 1),\n",
       " (64, 1),\n",
       " (65, 1),\n",
       " (66, 1),\n",
       " (67, 1),\n",
       " (68, 1),\n",
       " (69, 1),\n",
       " (70, 1),\n",
       " (71, 1),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 1),\n",
       " (76, 1),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 1),\n",
       " (85, 1),\n",
       " (86, 1),\n",
       " (87, 1),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (90, 1),\n",
       " (91, 1),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 1),\n",
       " (100, 1),\n",
       " (101, 1),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 1),\n",
       " (108, 1),\n",
       " (109, 1),\n",
       " (110, 1),\n",
       " (111, 1),\n",
       " (112, 1),\n",
       " (113, 1),\n",
       " (114, 1),\n",
       " (115, 1),\n",
       " (116, 1),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 1),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 1),\n",
       " (126, 1),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (129, 1),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 1),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 1),\n",
       " (139, 1),\n",
       " (140, 1),\n",
       " (141, 1),\n",
       " (142, 1),\n",
       " (143, 1),\n",
       " (144, 1),\n",
       " (145, 1),\n",
       " (146, 1),\n",
       " (147, 1),\n",
       " (148, 1),\n",
       " (149, 1),\n",
       " (150, 1),\n",
       " (151, 1),\n",
       " (152, 1),\n",
       " (153, 1),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 1),\n",
       " (157, 1),\n",
       " (158, 1),\n",
       " (159, 1),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 1),\n",
       " (163, 1),\n",
       " (164, 1),\n",
       " (165, 1),\n",
       " (166, 1),\n",
       " (167, 1),\n",
       " (168, 1),\n",
       " (169, 1),\n",
       " (170, 1),\n",
       " (171, 1),\n",
       " (172, 1),\n",
       " (173, 1),\n",
       " (174, 1),\n",
       " (175, 1),\n",
       " (176, 1),\n",
       " (177, 1),\n",
       " (178, 1),\n",
       " (179, 1),\n",
       " (180, 1),\n",
       " (181, 1),\n",
       " (182, 1),\n",
       " (183, 1),\n",
       " (184, 1),\n",
       " (185, 1),\n",
       " (186, 1),\n",
       " (187, 1),\n",
       " (188, 1),\n",
       " (189, 1),\n",
       " (190, 1),\n",
       " (191, 1),\n",
       " (192, 1),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 1),\n",
       " (196, 1),\n",
       " (197, 1),\n",
       " (198, 1),\n",
       " (199, 1),\n",
       " (200, 1),\n",
       " (201, 1),\n",
       " (202, 1),\n",
       " (203, 1),\n",
       " (204, 1),\n",
       " (205, 1),\n",
       " (206, 1),\n",
       " (207, 1),\n",
       " (208, 1),\n",
       " (209, 1),\n",
       " (210, 1),\n",
       " (211, 1),\n",
       " (212, 1),\n",
       " (213, 1),\n",
       " (214, 1),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1),\n",
       " (222, 1),\n",
       " (223, 1),\n",
       " (224, 1),\n",
       " (225, 1),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 1),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 1),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 1),\n",
       " (238, 1),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 1),\n",
       " (245, 1),\n",
       " (246, 1),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (249, 1),\n",
       " (250, 1),\n",
       " (251, 1),\n",
       " (252, 1),\n",
       " (253, 1),\n",
       " (254, 1),\n",
       " (255, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 1),\n",
       " (259, 1),\n",
       " (260, 1),\n",
       " (261, 1),\n",
       " (262, 1),\n",
       " (263, 1),\n",
       " (264, 1),\n",
       " (265, 1),\n",
       " (266, 1),\n",
       " (267, 1),\n",
       " (268, 1),\n",
       " (269, 1),\n",
       " (270, 1),\n",
       " (271, 1),\n",
       " (272, 1),\n",
       " (273, 1),\n",
       " (274, 1),\n",
       " (275, 1),\n",
       " (276, 1),\n",
       " (277, 1),\n",
       " (278, 1),\n",
       " (279, 1),\n",
       " (280, 1),\n",
       " (281, 1),\n",
       " (282, 1),\n",
       " (283, 1),\n",
       " (284, 1),\n",
       " (285, 1),\n",
       " (286, 1),\n",
       " (287, 1),\n",
       " (288, 1),\n",
       " (289, 1),\n",
       " (290, 1),\n",
       " (291, 1),\n",
       " (292, 1),\n",
       " (293, 1),\n",
       " (294, 1),\n",
       " (295, 1),\n",
       " (296, 1),\n",
       " (297, 1),\n",
       " (298, 1),\n",
       " (299, 1),\n",
       " (300, 1),\n",
       " (301, 1),\n",
       " (302, 1),\n",
       " (303, 1),\n",
       " (304, 1),\n",
       " (305, 1),\n",
       " (306, 1),\n",
       " (307, 1),\n",
       " (308, 1),\n",
       " (309, 1),\n",
       " (310, 1),\n",
       " (311, 1),\n",
       " (312, 1),\n",
       " (313, 1),\n",
       " (314, 1),\n",
       " (315, 1),\n",
       " (316, 1),\n",
       " (317, 1),\n",
       " (318, 1),\n",
       " (319, 1),\n",
       " (320, 1),\n",
       " (321, 1),\n",
       " (322, 1),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (325, 1),\n",
       " (326, 1),\n",
       " (327, 1),\n",
       " (328, 1),\n",
       " (329, 1),\n",
       " (330, 1),\n",
       " (331, 1),\n",
       " (332, 1),\n",
       " (333, 1),\n",
       " (334, 1),\n",
       " (335, 1),\n",
       " (336, 1),\n",
       " (337, 1),\n",
       " (338, 1),\n",
       " (339, 1),\n",
       " (340, 1),\n",
       " (341, 1)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whether theyre working',\n",
       " 'specialty job boards',\n",
       " 'romantically involved .]',\n",
       " 'price point higher',\n",
       " 'personal growth thing',\n",
       " 'neither necessarily lasts',\n",
       " 'marriage counselors listed',\n",
       " 'individual contributors report',\n",
       " 'get carried away',\n",
       " 'favorite interview questions',\n",
       " 'companies like salesforce',\n",
       " 'changing anytime soon',\n",
       " 'bad hires added',\n",
       " 'limited free offerings',\n",
       " 'four wont send',\n",
       " 'chief technology officer',\n",
       " 'software handle especially',\n",
       " 'cheap software solution',\n",
       " 'business owners track',\n",
       " 'stop accounting solution',\n",
       " 'trained sales teams',\n",
       " 'p ./ director',\n",
       " 'founder marriage counseling',\n",
       " 'every single candidate',\n",
       " 'core company values',\n",
       " '500 customers range',\n",
       " 'get new business',\n",
       " 'provides accounting software',\n",
       " 'really didnt know',\n",
       " 'didnt actually solve',\n",
       " 'manage 20 people',\n",
       " 'helped found indinero',\n",
       " 'customer gives us',\n",
       " 'turned things around',\n",
       " '000 per month',\n",
       " 'could help small',\n",
       " '100 leadership books',\n",
       " 'big business problem',\n",
       " 'didnt file',\n",
       " 'weve found',\n",
       " 'senior leadership',\n",
       " 'right people',\n",
       " 'new york',\n",
       " 'free month',\n",
       " 'every referral',\n",
       " 'chief executive',\n",
       " 'candidate pool',\n",
       " 'business challenges',\n",
       " 'customer happiness',\n",
       " 'customer acquisition',\n",
       " 'small businesses',\n",
       " 'send 50',\n",
       " 'years ago',\n",
       " 'wunderkind attention',\n",
       " 'tax needs',\n",
       " 'strong v',\n",
       " 'strong managers',\n",
       " 'still roommates',\n",
       " 'stay humble',\n",
       " 'started asking',\n",
       " 'side projects',\n",
       " 'seasoned executives',\n",
       " 'san francisco',\n",
       " 'resolve disputes',\n",
       " 'recent conversation',\n",
       " 'plus company',\n",
       " 'petty debates',\n",
       " 'particular issue',\n",
       " 'network expanding',\n",
       " 'magical feature',\n",
       " 'lofty ambition',\n",
       " 'living together',\n",
       " 'lay low',\n",
       " 'indineros woes',\n",
       " 'im taking',\n",
       " 'im done',\n",
       " 'hundred dollars',\n",
       " 'help mediate',\n",
       " 'fix indinero',\n",
       " 'five customers',\n",
       " 'first version',\n",
       " 'first signs',\n",
       " 'external recruiters',\n",
       " 'executive coach',\n",
       " 'evaluate candidates',\n",
       " 'employee company',\n",
       " 'effective leader',\n",
       " 'early success',\n",
       " 'dysfunctional couples',\n",
       " 'dont spend',\n",
       " 'different shapes',\n",
       " 'defined criteria',\n",
       " 'current customers',\n",
       " 'company full',\n",
       " 'big problem',\n",
       " 'best way',\n",
       " 'apartment together',\n",
       " 'annual sales',\n",
       " 'almost crashed',\n",
       " '8 million',\n",
       " '3 million',\n",
       " '2 million',\n",
       " '10 scale',\n",
       " 'ups software',\n",
       " 'could charge',\n",
       " 'could build',\n",
       " 'jessica mah',\n",
       " 'operations 50',\n",
       " 'let go',\n",
       " 'last year',\n",
       " 'last boss',\n",
       " 'including taxes',\n",
       " 'go straight',\n",
       " 'filing taxes',\n",
       " 'dont see',\n",
       " 'businesses pay',\n",
       " 'also see',\n",
       " 'strong relationship',\n",
       " 'spent nearly',\n",
       " 'serious trouble',\n",
       " 'right product',\n",
       " 'realized indinero',\n",
       " 'moved home',\n",
       " 'level person',\n",
       " 'im responsible',\n",
       " 'im focused',\n",
       " 'got rid',\n",
       " 'good friends',\n",
       " 'going nowhere',\n",
       " 'founders often',\n",
       " 'first time',\n",
       " 'figure sales',\n",
       " 'employee start',\n",
       " 'dial back',\n",
       " 'andy su',\n",
       " 'also ask',\n",
       " '75 employees',\n",
       " '1 billion',\n",
       " 'mah said',\n",
       " 'mah talked',\n",
       " 'said ms',\n",
       " 'would work',\n",
       " 'software',\n",
       " 'business',\n",
       " 'accounting',\n",
       " 'us',\n",
       " 'turned',\n",
       " 'things',\n",
       " 'solve',\n",
       " 'sales',\n",
       " 'problem',\n",
       " 'p',\n",
       " 'month',\n",
       " 'know',\n",
       " 'indinero',\n",
       " 'help',\n",
       " 'founder',\n",
       " 'customers',\n",
       " 'company',\n",
       " 'books',\n",
       " 'big',\n",
       " '20',\n",
       " '100',\n",
       " '000',\n",
       " 'mah',\n",
       " 'taxes',\n",
       " 'see',\n",
       " 'said',\n",
       " 'last',\n",
       " 'go',\n",
       " 'businesses',\n",
       " '50',\n",
       " 'would',\n",
       " 'work',\n",
       " 'ups',\n",
       " 'trouble',\n",
       " 'time',\n",
       " 'talked',\n",
       " 'start',\n",
       " 'spent',\n",
       " 'responsible',\n",
       " 'relationship',\n",
       " 'realized',\n",
       " 'product',\n",
       " 'person',\n",
       " 'ms',\n",
       " 'moved',\n",
       " 'got',\n",
       " 'going',\n",
       " 'friends',\n",
       " 'founders',\n",
       " 'focused',\n",
       " 'figure',\n",
       " 'employees',\n",
       " 'charge',\n",
       " 'build',\n",
       " 'back',\n",
       " 'ask',\n",
       " 'andy',\n",
       " '1',\n",
       " 'yet',\n",
       " 'yes',\n",
       " 'yelp',\n",
       " 'whats',\n",
       " 'werent',\n",
       " 'well',\n",
       " 'wanted',\n",
       " 'want',\n",
       " 'usually',\n",
       " 'upgrades',\n",
       " 'two',\n",
       " 'true',\n",
       " 'tried',\n",
       " 'tracked',\n",
       " 'total',\n",
       " 'top',\n",
       " 'today',\n",
       " 'thought',\n",
       " 'team',\n",
       " 'talk',\n",
       " 'take',\n",
       " 'strongly',\n",
       " 'steps',\n",
       " 'staff',\n",
       " 'split',\n",
       " 'something',\n",
       " 'sizes',\n",
       " 'sign',\n",
       " 'services',\n",
       " 'service',\n",
       " 'seriously',\n",
       " 'series',\n",
       " 'self',\n",
       " 'running',\n",
       " 'rethink',\n",
       " 'results',\n",
       " 'rent',\n",
       " 'referrals',\n",
       " 'read',\n",
       " 'reach',\n",
       " 'raised',\n",
       " 'q',\n",
       " 'problems',\n",
       " 'proactive',\n",
       " 'payroll',\n",
       " 'past',\n",
       " 'parents',\n",
       " 'ones',\n",
       " 'one',\n",
       " 'office',\n",
       " 'offering',\n",
       " 'obvious',\n",
       " 'numbers',\n",
       " 'number',\n",
       " 'netsuite',\n",
       " 'needed',\n",
       " 'much',\n",
       " 'money',\n",
       " 'mistakes',\n",
       " 'mini',\n",
       " 'metrics',\n",
       " 'methods',\n",
       " 'marketing',\n",
       " 'many',\n",
       " 'make',\n",
       " 'made',\n",
       " 'lot',\n",
       " 'looking',\n",
       " 'linkedin',\n",
       " 'life',\n",
       " 'learned',\n",
       " 'labor',\n",
       " 'knew',\n",
       " 'key',\n",
       " 'justifies',\n",
       " 'joined',\n",
       " 'investors',\n",
       " 'incentivize',\n",
       " 'important',\n",
       " 'idea',\n",
       " 'hours',\n",
       " 'horrible',\n",
       " 'hiring',\n",
       " 'hired',\n",
       " 'hard',\n",
       " 'grow',\n",
       " 'give',\n",
       " 'food',\n",
       " 'finding',\n",
       " 'finances',\n",
       " 'finance',\n",
       " 'fierce',\n",
       " 'fields',\n",
       " 'feel',\n",
       " 'family',\n",
       " 'failure',\n",
       " 'fact',\n",
       " 'expenses',\n",
       " 'expects',\n",
       " 'engineering',\n",
       " 'eight',\n",
       " 'edited',\n",
       " 'e',\n",
       " 'double',\n",
       " 'division',\n",
       " 'disagreements',\n",
       " 'disagree',\n",
       " 'development',\n",
       " 'depending',\n",
       " 'decision',\n",
       " 'deal',\n",
       " 'day',\n",
       " 'cover',\n",
       " 'conferences',\n",
       " 'condensed',\n",
       " 'complicated',\n",
       " 'competition',\n",
       " 'comes',\n",
       " 'come',\n",
       " 'co',\n",
       " 'close',\n",
       " 'charged',\n",
       " 'change',\n",
       " 'cares',\n",
       " 'cancellations',\n",
       " 'california',\n",
       " 'c',\n",
       " 'burning',\n",
       " 'blogs',\n",
       " 'believed',\n",
       " 'beginning',\n",
       " 'always',\n",
       " 'age',\n",
       " 'accountants',\n",
       " '80',\n",
       " '5',\n",
       " '400',\n",
       " '250',\n",
       " '2015',\n",
       " '2012',\n",
       " '2009',\n",
       " '150']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTimes_initial_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jessica Mah was 20 when she helped found InDinero in 2009. Back then she believed she could help small-business owners track their finances with her start-ups software. But as it turned out, Ms. Mah could barely keep InDinero afloat, let alone help others run their businesses. In its first version, InDinero, in San Francisco, charged its few customers $20 a month for its software. Competition, which included companies like QuickBooks, was fierce, and a series of bad hires added to InDineros woes. The company was going nowhere, Ms. Mah said. But by the time she realized this, in 2012, InDinero had spent nearly all of the $1.2 million it had raised from investors. A few years ago, I really didnt know that much, said Ms. Mah, the chief executive. In fact, she said, I almost crashed the company. And yet, today, InDinero, which provides accounting software and services to small businesses, has 75 employees and just under $3 million in annual sales. It expects to double that in 2015, and has raised a total of $8 million from investors. In a recent conversation, which has been edited and condensed, Ms. Mah talked about how she turned things around. Q. What were the first signs of a problem? A. I tracked the metrics  the number of sign-ups, upgrades and cancellations. The numbers that should have been going up werent. Q. How close did you come to running out of money? A. We were down to the last $150,000 of the $1.2 million we had raised, and were burning $80,000 to $100,000 a month. Once we got down to about $250,000 we knew we had to dial back. Q. What steps did you take once you realized InDinero was in serious trouble? A. We got rid of our office and employees so we had no expenses. My co-founder, Andy Su, and I moved into an apartment together and got our parents to cover our rent and food. I would have moved home, but my family is in New York, and the company is in California. Then, for most of 2012, we tried to figure out what magical feature we could build to fix InDinero. Q. Did you figure it out? A. I started asking, What would InDinero look like if it were a $1 billion-plus company? Looking at companies like Salesforce and NetSuite, I learned a few things. They all solve a big business problem that justifies a price point higher than $20 a month. They have seasoned executives and well-trained sales teams. Theyre nearly 100 percent premium, with very limited free offerings. Q. How did this help you change your product? A. We knew we needed a product that we could charge a few hundred dollars a month for. I spent countless hours interviewing entrepreneurs of all different shapes and sizes to figure out their accounting and tax needs. We knew they wanted a one-stop accounting solution. It was a big problem for them that we didnt file their taxes. We had to go from offering a cheap software solution that didnt actually solve any problems to being an all-in-one accounting back office with accountants on staff. We had to do it all, including taxes and payroll. Q. How big a business can your software handle  especially when it comes to filing taxes? A. Our 500 customers range from a two-employee start-up with no sales to a 100-employee company with eight-figure sales. Q. What do you charge? A. Businesses pay between $400 and $5,000 per month, depending on how complicated their accounting is. Q. How are you marketing your service? A. Weve found the best way to get new business is to incentivize our current customers. For every referral a customer gives us, we give them a free month. Weve found that, out of five customers, four wont send any referrals, but one will send 50. Q. Once you had the right product, how did you go about hiring the right people? A. I thought about the mistakes I made the first time. I realized I had hired too many of my friends. I should have spent more time evaluating candidates outside my network  expanding the candidate pool through external recruiters, LinkedIn, specialty job boards and other methods. My original interview process wasnt thorough. I had no defined criteria to evaluate candidates against. Q. Do you have any favorite interview questions? A. Yes, I ask the same ones to every single candidate. Some are, Whats the hardest youve ever worked in your life, whats your most lofty ambition and what are you doing for self-development? I want to know what books and blogs they read, what conferences they go to, whether theyre working on side projects in their fields and whether theyve ever run a company. I want a company full of mini-C.E.O.s. I also ask about their relationship with their last boss. If they talk about how horrible their last boss was, Im done. Q. Has your management style changed since InDineros early days? A. Yes, Im focused on going from being a C.E.O. who did the work herself to an effective leader. Im taking the personal growth thing very seriously. Ive hired executive coaches and joined Y.P.O. [Young Presidents Organization]. Last year, I read more than 100 leadership books. Q. Is it hard to let go of the day-to-day? A. In the past, I didnt spend enough time recruiting for senior leadership. I tried to manage 20 people all by myself with no strong managers to grow the company. Now, I dont spend any time having individual contributors report to me. I go straight to finding a strong V.P./director-level person who can build the team out for me. Q. Did InDineros early problems test your relationship with your co-founder? A. Andy and I have always had a strong relationship. Were good friends  and still roommates. Living together is key because we can work on business challenges at all hours of the day. I dont see this changing anytime soon. Q. Whats the division of labor between you? A. Im responsible for customer happiness and customer acquisition. Andy, the chief technology officer, is responsible for product and engineering. We split all the other business functions  like legal, finance and operations  50-50. Q. How do you resolve disputes? A. If we disagree on how to deal with something, we ask the other person how strongly they feel on a 1-to-10 scale about that particular issue. The person who cares more will make the decision. We also see an executive coach to help mediate our disagreements. On top of that, we go to co-founder marriage counseling! [The co-founders are not romantically involved.] One of our core company values is rethink the obvious, so I got the idea to reach out to marriage counselors listed on Yelp to see if any would work with us. Even though marriage counseling is usually for dysfunctional couples, co-founders often have the same petty debates. We wanted to be proactive. Q. What have you learned about early success  and failure? A. In the beginning, because of my age, I got a lot of wunderkind attention. Its important to stay humble and not get carried away by early success  but the same is true of failure. Neither necessarily lasts. So, when InDinero was in trouble, I just talked to my parents and friends, lay low and focused on results.\n"
     ]
    }
   ],
   "source": [
    "print(NYTimes_df_cleaned.article.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Running the LDA\n",
    "\n",
    "Now that we've done heavy lifting (i.e., formatting our data), we can now run the LDA. This is the easy part! \n",
    "\n",
    "Recall that we need to pick out the proper hyperparameters. For our purposes, we'll focus on two here: `K` topics and `alpha`. \n",
    "\n",
    "`K` is more of a tuning parameter, in that it's a bit of a guess as to what the right value of `K` is. For the sake of argument, let's just use a `K` of 10, or that we expect there to be 20 distinct topics in our sociology paper corpus. \n",
    "\n",
    "For `alpha`, let's set it as 0.01, a standard value often used in NLP. For `alpha`, we need to pass it in as a list, whose length is the same as the number of topics. This is achieved by `[0.01]*number_of_topics`. \n",
    "\n",
    "We also pass in our \"dictionary\" that we created earlier: `dictionary_LDA` as our token ID to terms dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_topics = 10 # Number of topics that we set initially as K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(123456) # This initializes (re-seeds) the random generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's FINALLY run it! \n",
    "\n",
    "Pass in `corpus`, the number of topics, the `dictionary_LDA` and `alpha`. LDAs can take some time. To speed this up, we're going to use a special version of the LDA model called a `LdaMulticore` model. This may look familiar to you from an earlier lab!\n",
    "\n",
    "It's an LDA model that uses multicore processors (if available) to speed up the model! (You can use the regular `models.LDA()` as well to similar effect.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first need to see how many cores your machine has available. We can do this using the module `psutil`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function called `cpu_count()` to count the number of CPUs (cores) you have available on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to use ***n-1*** cores available on your machine. \n",
    "\n",
    "**N.B.**: We DON'T want to use all of the cores, because then your computer won't have any dedicated cores to run your OS and its basic functions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Cores = psutil.cpu_count()-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to run the model.\n",
    "\n",
    "**N.B.:** This will throw a lot of errors at you and will likely ***take some time to run.*** Don't worry and go grab a cup of coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lda_model = models.LdaMulticore(corpus = LDA_corpus,\n",
    "                            num_topics=num_topics,\n",
    "                            workers=N_Cores, # NOTE: the number of cores!!\n",
    "                            id2word=dictionary_LDA,\n",
    "                            alpha=[0.01]*num_topics,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully if your computer didn't blow up, the model should have completed successfully! Let's take a look at the top 20 words most associated to each of the `K` topics. \n",
    "\n",
    "We'll run a `for` loop and use the method `.show_topics()` to print out the top 20 terms for each of the `K` topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.002*\"san francisco\" + 0.002*\"one\" + 0.002*\"said\" + 0.002*\"mr\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"year\" + 0.001*\"get\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"1\" + 0.001*\"much\" + 0.001*\"people\" + 0.001*\"part\" + 0.001*\"two\" + 0.001*\"see\" + 0.001*\"end\" + 0.001*\"would\" + 0.001*\"way\" + 0.001*\"ms\"\n",
      "\n",
      "1: 0.001*\"san francisco\" + 0.001*\"one\" + 0.001*\"year\" + 0.001*\"mr\" + 0.001*\"said\" + 0.001*\"part\" + 0.001*\"way\" + 0.001*\"people\" + 0.001*\"trying\" + 0.001*\"time\" + 0.001*\"still\" + 0.001*\"get\" + 0.001*\"much\" + 0.001*\"would\" + 0.001*\"go\" + 0.001*\"well\" + 0.001*\"lot\" + 0.001*\"see\" + 0.001*\"new york\" + 0.001*\"many\"\n",
      "\n",
      "2: 0.002*\"said\" + 0.001*\"mr\" + 0.001*\"well\" + 0.001*\"san francisco\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"one\" + 0.001*\"see\" + 0.001*\"get\" + 0.001*\"would\" + 0.001*\"also\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"want\" + 0.001*\"take\" + 0.001*\"made\" + 0.001*\"even\" + 0.001*\"ms\" + 0.001*\"work\" + 0.001*\"still\"\n",
      "\n",
      "3: 0.002*\"san francisco\" + 0.001*\"said\" + 0.001*\"one\" + 0.001*\"mr\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"world\" + 0.001*\"would\" + 0.001*\"though\" + 0.001*\"lot\" + 0.001*\"year\" + 0.001*\"make\" + 0.001*\"part\" + 0.001*\"work\" + 0.001*\"people\" + 0.001*\"c\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"see\" + 0.001*\"united states\"\n",
      "\n",
      "4: 0.002*\"san francisco\" + 0.002*\"said\" + 0.001*\"one\" + 0.001*\"year\" + 0.001*\"mr\" + 0.001*\"time\" + 0.001*\"way\" + 0.001*\"well\" + 0.001*\"still\" + 0.001*\"much\" + 0.001*\"according\" + 0.001*\"also\" + 0.001*\"lot\" + 0.001*\"make\" + 0.001*\"years\" + 0.001*\"work\" + 0.001*\"get\" + 0.001*\"like\" + 0.001*\"united states\" + 0.001*\"made\"\n",
      "\n",
      "5: 0.002*\"said\" + 0.001*\"mr\" + 0.001*\"san francisco\" + 0.001*\"one\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"people\" + 0.001*\"made\" + 0.001*\"going\" + 0.001*\"work\" + 0.001*\"year\" + 0.001*\"way\" + 0.001*\"get\" + 0.001*\"part\" + 0.001*\"according\" + 0.001*\"ms\" + 0.001*\"would\" + 0.001*\"even\" + 0.001*\"think\" + 0.001*\"also\"\n",
      "\n",
      "6: 0.002*\"mr\" + 0.002*\"said\" + 0.002*\"san francisco\" + 0.001*\"one\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"new york\" + 0.001*\"1\" + 0.001*\"made\" + 0.001*\"way\" + 0.001*\"company\" + 0.001*\"much\" + 0.001*\"university\" + 0.001*\"people\" + 0.001*\"part\" + 0.001*\"going\" + 0.001*\"well\" + 0.001*\"work\" + 0.001*\"see\" + 0.001*\"according\"\n",
      "\n",
      "7: 0.002*\"one\" + 0.002*\"mr\" + 0.001*\"said\" + 0.001*\"time\" + 0.001*\"san francisco\" + 0.001*\"also\" + 0.001*\"people\" + 0.001*\"way\" + 0.001*\"year\" + 0.001*\"many\" + 0.001*\"would\" + 0.001*\"well\" + 0.001*\"according\" + 0.001*\"made\" + 0.001*\"make\" + 0.001*\"two\" + 0.001*\"ms\" + 0.001*\"world\" + 0.001*\"1\" + 0.001*\"going\"\n",
      "\n",
      "8: 0.002*\"said\" + 0.001*\"san francisco\" + 0.001*\"mr\" + 0.001*\"made\" + 0.001*\"one\" + 0.001*\"way\" + 0.001*\"according\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"well\" + 0.001*\"ms\" + 0.001*\"lot\" + 0.001*\"people\" + 0.001*\"united states\" + 0.001*\"new york\" + 0.001*\"go\" + 0.001*\"like\" + 0.001*\"would\" + 0.001*\"also\" + 0.001*\"world\"\n",
      "\n",
      "9: 0.001*\"said\" + 0.001*\"one\" + 0.001*\"san francisco\" + 0.001*\"mr\" + 0.001*\"way\" + 0.001*\"well\" + 0.001*\"work\" + 0.001*\"year\" + 0.001*\"united states\" + 0.001*\"time\" + 0.001*\"much\" + 0.001*\"want\" + 0.001*\"even\" + 0.001*\"people\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"still\" + 0.001*\"going\" + 0.001*\"see\" + 0.001*\"part\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=20):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## What Are the Topics?\n",
    "\n",
    "We might be able to see a pattern with some of these topics. \n",
    "\n",
    "If this were our actual research project, we'd need to go through the corpus one more time and more move punctuation and stop words. Indeed, the first time you run an LDA, you'll need to likely re-run the LDA and move terms that happened to slip through that you need to remove. \n",
    "\n",
    "Note that the LDA model just sorts terms into topics based on mathmatical procedures, but it's up to you as a researcher then to put on your thinking caps and go through the topics to check if they make sense and try to label/interpret the topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our \"bag of words\" assumption. Let's again look at the first article in the corpus and see what topics make up this article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underrepresentation of Black Americans as graduate students and faculty in Criminology and Criminal Justice programs is well-recognized. This essay discusses some of the dynamics of the academy that potentially contribute to the lack of Black representation at the highest levels of the academy. Through the sharing of various experiences, this essay sheds light on how the dearth of Black men in the academy creates challenges for the few Black men that do exist in the academy.\n"
     ]
    }
   ],
   "source": [
    "print(Text_df.articles.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Clearly, this article has to do with the dirth of Black graduate student and faulty representation in criminology and criminal justice programs. We can use the LDA model we just ran and see what topics make up this article. \n",
    "\n",
    "Let's use `lda_model` and pass in the text from `LDA_corpus`, namely the first document, to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.8589901), (3, 0.14076833)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[LDA_corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a list of tuples. The first value is the ID related to the topic and the second value is how much this topic dominates the document. The first document is 98% comprised of the sixth topic (remember, the count starts at zero, not one). \n",
    "\n",
    "Look at what the top terms for each topic is (as produced by the `for-loop`). Does this make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 5\n",
    "\n",
    "Now you try!\n",
    "\n",
    "Run the LDA model for your NY Times data. Choose some `K` number of topics. I would suggest pick a value of `K` that is less than 20 but greater than 5. (Let's keep `alpha` as 0.01.) Save your LDA model as `NYTimes_lda_model`. \n",
    "\n",
    "Print out the top twenty words for each topic. \n",
    "\n",
    "Which topics make up first article in your corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_topics = 10 # Number of topics that we set initially as K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(123456) # This initializes (re-seeds) the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_Cores = psutil.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYTimes_lda_model = models.LdaMulticore(corpus = NYTimes_corpus,\n",
    "                            num_topics=num_topics,\n",
    "                            workers=N_Cores, # NOTE: the number of cores!!\n",
    "                            id2word=NYTimes_dictionary_LDA,\n",
    "                            alpha=[0.01]*num_topics,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.002*\"san francisco\" + 0.002*\"one\" + 0.002*\"said\" + 0.002*\"mr\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"year\" + 0.001*\"get\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"1\" + 0.001*\"much\" + 0.001*\"people\" + 0.001*\"part\" + 0.001*\"two\" + 0.001*\"see\" + 0.001*\"end\" + 0.001*\"would\" + 0.001*\"way\" + 0.001*\"ms\"\n",
      "\n",
      "1: 0.001*\"san francisco\" + 0.001*\"one\" + 0.001*\"year\" + 0.001*\"mr\" + 0.001*\"said\" + 0.001*\"part\" + 0.001*\"way\" + 0.001*\"people\" + 0.001*\"trying\" + 0.001*\"time\" + 0.001*\"still\" + 0.001*\"get\" + 0.001*\"much\" + 0.001*\"would\" + 0.001*\"go\" + 0.001*\"well\" + 0.001*\"lot\" + 0.001*\"see\" + 0.001*\"new york\" + 0.001*\"many\"\n",
      "\n",
      "2: 0.002*\"said\" + 0.001*\"mr\" + 0.001*\"well\" + 0.001*\"san francisco\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"one\" + 0.001*\"see\" + 0.001*\"get\" + 0.001*\"would\" + 0.001*\"also\" + 0.001*\"like\" + 0.001*\"people\" + 0.001*\"want\" + 0.001*\"take\" + 0.001*\"made\" + 0.001*\"even\" + 0.001*\"ms\" + 0.001*\"work\" + 0.001*\"still\"\n",
      "\n",
      "3: 0.002*\"san francisco\" + 0.001*\"said\" + 0.001*\"one\" + 0.001*\"mr\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"world\" + 0.001*\"would\" + 0.001*\"though\" + 0.001*\"lot\" + 0.001*\"year\" + 0.001*\"make\" + 0.001*\"part\" + 0.001*\"work\" + 0.001*\"people\" + 0.001*\"c\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"see\" + 0.001*\"united states\"\n",
      "\n",
      "4: 0.002*\"san francisco\" + 0.002*\"said\" + 0.001*\"one\" + 0.001*\"year\" + 0.001*\"mr\" + 0.001*\"time\" + 0.001*\"way\" + 0.001*\"well\" + 0.001*\"still\" + 0.001*\"much\" + 0.001*\"according\" + 0.001*\"also\" + 0.001*\"lot\" + 0.001*\"make\" + 0.001*\"years\" + 0.001*\"work\" + 0.001*\"get\" + 0.001*\"like\" + 0.001*\"united states\" + 0.001*\"made\"\n",
      "\n",
      "5: 0.002*\"said\" + 0.001*\"mr\" + 0.001*\"san francisco\" + 0.001*\"one\" + 0.001*\"time\" + 0.001*\"well\" + 0.001*\"people\" + 0.001*\"made\" + 0.001*\"going\" + 0.001*\"work\" + 0.001*\"year\" + 0.001*\"way\" + 0.001*\"get\" + 0.001*\"part\" + 0.001*\"according\" + 0.001*\"ms\" + 0.001*\"would\" + 0.001*\"even\" + 0.001*\"think\" + 0.001*\"also\"\n",
      "\n",
      "6: 0.002*\"mr\" + 0.002*\"said\" + 0.002*\"san francisco\" + 0.001*\"one\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"new york\" + 0.001*\"1\" + 0.001*\"made\" + 0.001*\"way\" + 0.001*\"company\" + 0.001*\"much\" + 0.001*\"university\" + 0.001*\"people\" + 0.001*\"part\" + 0.001*\"going\" + 0.001*\"well\" + 0.001*\"work\" + 0.001*\"see\" + 0.001*\"according\"\n",
      "\n",
      "7: 0.002*\"one\" + 0.002*\"mr\" + 0.001*\"said\" + 0.001*\"time\" + 0.001*\"san francisco\" + 0.001*\"also\" + 0.001*\"people\" + 0.001*\"way\" + 0.001*\"year\" + 0.001*\"many\" + 0.001*\"would\" + 0.001*\"well\" + 0.001*\"according\" + 0.001*\"made\" + 0.001*\"make\" + 0.001*\"two\" + 0.001*\"ms\" + 0.001*\"world\" + 0.001*\"1\" + 0.001*\"going\"\n",
      "\n",
      "8: 0.002*\"said\" + 0.001*\"san francisco\" + 0.001*\"mr\" + 0.001*\"made\" + 0.001*\"one\" + 0.001*\"way\" + 0.001*\"according\" + 0.001*\"time\" + 0.001*\"year\" + 0.001*\"well\" + 0.001*\"ms\" + 0.001*\"lot\" + 0.001*\"people\" + 0.001*\"united states\" + 0.001*\"new york\" + 0.001*\"go\" + 0.001*\"like\" + 0.001*\"would\" + 0.001*\"also\" + 0.001*\"world\"\n",
      "\n",
      "9: 0.001*\"said\" + 0.001*\"one\" + 0.001*\"san francisco\" + 0.001*\"mr\" + 0.001*\"way\" + 0.001*\"well\" + 0.001*\"work\" + 0.001*\"year\" + 0.001*\"united states\" + 0.001*\"time\" + 0.001*\"much\" + 0.001*\"want\" + 0.001*\"even\" + 0.001*\"people\" + 0.001*\"also\" + 0.001*\"according\" + 0.001*\"still\" + 0.001*\"going\" + 0.001*\"see\" + 0.001*\"part\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in NYTimes_lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=20):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jessica Mah was 20 when she helped found InDinero in 2009. Back then she believed she could help small-business owners track their finances with her start-ups software. But as it turned out, Ms. Mah could barely keep InDinero afloat, let alone help others run their businesses. In its first version, InDinero, in San Francisco, charged its few customers $20 a month for its software. Competition, which included companies like QuickBooks, was fierce, and a series of bad hires added to InDineros woes. The company was going nowhere, Ms. Mah said. But by the time she realized this, in 2012, InDinero had spent nearly all of the $1.2 million it had raised from investors. A few years ago, I really didnt know that much, said Ms. Mah, the chief executive. In fact, she said, I almost crashed the company. And yet, today, InDinero, which provides accounting software and services to small businesses, has 75 employees and just under $3 million in annual sales. It expects to double that in 2015, and has raised a total of $8 million from investors. In a recent conversation, which has been edited and condensed, Ms. Mah talked about how she turned things around. Q. What were the first signs of a problem? A. I tracked the metrics  the number of sign-ups, upgrades and cancellations. The numbers that should have been going up werent. Q. How close did you come to running out of money? A. We were down to the last $150,000 of the $1.2 million we had raised, and were burning $80,000 to $100,000 a month. Once we got down to about $250,000 we knew we had to dial back. Q. What steps did you take once you realized InDinero was in serious trouble? A. We got rid of our office and employees so we had no expenses. My co-founder, Andy Su, and I moved into an apartment together and got our parents to cover our rent and food. I would have moved home, but my family is in New York, and the company is in California. Then, for most of 2012, we tried to figure out what magical feature we could build to fix InDinero. Q. Did you figure it out? A. I started asking, What would InDinero look like if it were a $1 billion-plus company? Looking at companies like Salesforce and NetSuite, I learned a few things. They all solve a big business problem that justifies a price point higher than $20 a month. They have seasoned executives and well-trained sales teams. Theyre nearly 100 percent premium, with very limited free offerings. Q. How did this help you change your product? A. We knew we needed a product that we could charge a few hundred dollars a month for. I spent countless hours interviewing entrepreneurs of all different shapes and sizes to figure out their accounting and tax needs. We knew they wanted a one-stop accounting solution. It was a big problem for them that we didnt file their taxes. We had to go from offering a cheap software solution that didnt actually solve any problems to being an all-in-one accounting back office with accountants on staff. We had to do it all, including taxes and payroll. Q. How big a business can your software handle  especially when it comes to filing taxes? A. Our 500 customers range from a two-employee start-up with no sales to a 100-employee company with eight-figure sales. Q. What do you charge? A. Businesses pay between $400 and $5,000 per month, depending on how complicated their accounting is. Q. How are you marketing your service? A. Weve found the best way to get new business is to incentivize our current customers. For every referral a customer gives us, we give them a free month. Weve found that, out of five customers, four wont send any referrals, but one will send 50. Q. Once you had the right product, how did you go about hiring the right people? A. I thought about the mistakes I made the first time. I realized I had hired too many of my friends. I should have spent more time evaluating candidates outside my network  expanding the candidate pool through external recruiters, LinkedIn, specialty job boards and other methods. My original interview process wasnt thorough. I had no defined criteria to evaluate candidates against. Q. Do you have any favorite interview questions? A. Yes, I ask the same ones to every single candidate. Some are, Whats the hardest youve ever worked in your life, whats your most lofty ambition and what are you doing for self-development? I want to know what books and blogs they read, what conferences they go to, whether theyre working on side projects in their fields and whether theyve ever run a company. I want a company full of mini-C.E.O.s. I also ask about their relationship with their last boss. If they talk about how horrible their last boss was, Im done. Q. Has your management style changed since InDineros early days? A. Yes, Im focused on going from being a C.E.O. who did the work herself to an effective leader. Im taking the personal growth thing very seriously. Ive hired executive coaches and joined Y.P.O. [Young Presidents Organization]. Last year, I read more than 100 leadership books. Q. Is it hard to let go of the day-to-day? A. In the past, I didnt spend enough time recruiting for senior leadership. I tried to manage 20 people all by myself with no strong managers to grow the company. Now, I dont spend any time having individual contributors report to me. I go straight to finding a strong V.P./director-level person who can build the team out for me. Q. Did InDineros early problems test your relationship with your co-founder? A. Andy and I have always had a strong relationship. Were good friends  and still roommates. Living together is key because we can work on business challenges at all hours of the day. I dont see this changing anytime soon. Q. Whats the division of labor between you? A. Im responsible for customer happiness and customer acquisition. Andy, the chief technology officer, is responsible for product and engineering. We split all the other business functions  like legal, finance and operations  50-50. Q. How do you resolve disputes? A. If we disagree on how to deal with something, we ask the other person how strongly they feel on a 1-to-10 scale about that particular issue. The person who cares more will make the decision. We also see an executive coach to help mediate our disagreements. On top of that, we go to co-founder marriage counseling! [The co-founders are not romantically involved.] One of our core company values is rethink the obvious, so I got the idea to reach out to marriage counselors listed on Yelp to see if any would work with us. Even though marriage counseling is usually for dysfunctional couples, co-founders often have the same petty debates. We wanted to be proactive. Q. What have you learned about early success  and failure? A. In the beginning, because of my age, I got a lot of wunderkind attention. Its important to stay humble and not get carried away by early success  but the same is true of failure. Neither necessarily lasts. So, when InDinero was in trouble, I just talked to my parents and friends, lay low and focused on results.\n"
     ]
    }
   ],
   "source": [
    "print(NYTimes_df_cleaned.article.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Predicting Topics on Unseen Documents\n",
    "\n",
    "Let's try and predict the topics on a document unseen by the LDA (i.e., not trained by the LDA). Here is a sample abstract, which comes from this paper (https://doi.org/10.1177/00031224221119803). Let's see what topics are found in this unseen article by the LDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document = '''\n",
    "A core sociological claim is that race is a social construction; an important illustration of this is how racial classifications are influenced by people’s socioeconomic status. \n",
    "In both Latin America and the United States, someone with higher SES is more likely to be classified as White than others of similar appearance, a pattern epitomized by the expression money whitens. \n",
    "However, recent studies of the effect of SES on racial classifications show inconsistent results, sometimes depending on the measures used. \n",
    "We develop a broad theorization of societies as having multiple racialized hierarchies with different socioeconomic escalators potentially bringing people to higher-status locations in each one. \n",
    "Yet racialized hierarchies differ across societies, and some non-White classifications may reflect a process of upward movement while others may not. \n",
    "We assess this process in Mexico using the 2019 Project on Ethnic-Racial Discrimination in Mexico, a nationally-representative survey including highly accurate digital skin-color ratings, perceived skin-color assessments, and ethnoracial classifications by respondents and interviewers. \n",
    "We find that having higher education increases respondents’ self-classification as Mestizo. Yet those with greater wealth are whitened by interviewers. \n",
    "Simultaneously, respondents and interviewers lighten respondents with greater wealth. We argue that SES can differentially affect mobility in different racialized hierarchies, showing how race is constructed partly by other social constructs like class.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the document into a list of tokens. \n",
    "\n",
    "Here, we're going to again use RAKE to extract keywords, but you could aalso use the `word_tokenize` function, as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokens = word_tokenize(document) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Extract_Phrases_Rake(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiple racialized hierarchies',\n",
       " 'expression money whitens',\n",
       " 'differentially affect mobility',\n",
       " 'different racialized hierarchies',\n",
       " 'core sociological claim',\n",
       " 'interviewers lighten respondents',\n",
       " 'upward movement',\n",
       " 'united states',\n",
       " 'status locations',\n",
       " 'sometimes depending',\n",
       " 'socioeconomic status',\n",
       " 'social construction',\n",
       " 'similar appearance',\n",
       " 'recent studies',\n",
       " 'racial discrimination',\n",
       " 'racial classifications',\n",
       " 'perceived skin',\n",
       " 'people ’',\n",
       " 'pattern epitomized',\n",
       " 'measures used',\n",
       " 'latin america',\n",
       " 'important illustration',\n",
       " 'greater wealth',\n",
       " 'ethnoracial classifications',\n",
       " 'constructed partly',\n",
       " 'color ratings',\n",
       " 'color assessments',\n",
       " 'broad theorization',\n",
       " '2019 project',\n",
       " 'others may',\n",
       " 'mexico using',\n",
       " 'higher ses',\n",
       " 'respondents',\n",
       " 'interviewers',\n",
       " 'ses',\n",
       " 'others',\n",
       " 'mexico',\n",
       " 'higher',\n",
       " 'yet',\n",
       " 'whitened',\n",
       " 'white',\n",
       " 'someone',\n",
       " 'societies',\n",
       " 'simultaneously',\n",
       " 'showing',\n",
       " 'race',\n",
       " 'process',\n",
       " 'one',\n",
       " 'non',\n",
       " 'nationally',\n",
       " 'mestizo',\n",
       " 'likely',\n",
       " 'influenced',\n",
       " 'however',\n",
       " 'find',\n",
       " 'ethnic',\n",
       " 'effect',\n",
       " 'develop',\n",
       " 'classified',\n",
       " 'classification',\n",
       " 'assess',\n",
       " 'argue']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass in this new article and see what topics comprise it according to the LDA. \n",
    "\n",
    "We can use the `lda_model` and `dictionary_LDA` object and its `.doc2bow()` method, to take each token from `document` to calculate the topic distribution. \n",
    "\n",
    "Here, I've saved the output as a `DataFrame` to make it easier to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic #  Weight\n",
       "0        3    0.38\n",
       "1        7    0.61"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(el[0], round(el[1],2)) for el in lda_model[dictionary_LDA.doc2bow(tokens)]], \n",
    "             columns=['Topic #', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here the distribution of topics across the documents. Note, that the weight sums to 100%\n",
    "\n",
    "Given the article, look back at the top terms for each of these topics from the earlier `for-loop` for `lda_model.show_topics` and see if you agree with this distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Visualizing Topics\n",
    "\n",
    "`pyLDAvis` is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The package extracts information from a fitted LDA topic model to inform an interactive web-based visualization.\n",
    "\n",
    "The visualization is intended to be used within a Jupyter notebook but can also be saved to a stand-alone HTML file for easy sharing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import these modules, and set `%matplotlib inline` to visualize the LDA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the pyLDAvis! Thankfully, we already have all the inputs that we need from our previous work. \n",
    "\n",
    "One somewhat confusing thing is that we need add in an extra line of code `with parallel_backend('threading'):` in order for it to work. This is because `pyLDAvis` is very CPU and memory intensive, and parallelizing it in the backend will ensure the visualization works and doesn't crash. \n",
    "\n",
    "**NOTE:** This may take a few minutes to run! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ual-laptop\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyLDAvis\\_prepare.py:248: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    vis = pyLDAvis.gensim.prepare(topic_model=lda_model, \n",
    "                                  corpus=LDA_corpus, \n",
    "                                  dictionary=dictionary_LDA, \n",
    "                                  sort_topics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a short vignette that explains more specifically what's happening: \n",
    "\n",
    "https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf\n",
    "\n",
    "In broad strokes, it visualizes the topics that were found in the LDA model. \n",
    "\n",
    "First in the box next to \"Select Topic\" put in a topic number (anywhere from 0 to 19, inclusive) to visualize the specific topic. \n",
    "\n",
    "For each topic, the visualization produces two plots. The plot to the left is the \"intertopic distance\" map, or how dissimilar or similar topics are to one another. (This procedure actually uses a PCA!) The size of each topic's \"bubble\" is proportional to the proportions of the topics across all of the tokens in the corpus. \n",
    "\n",
    "The bar chart on th right is the most relevant topics to each topic. The red bars estimate number of times a given term was generated by a given topic. The blue bars capture the overall frequency of each term in the corpus. Finally, the relevance of words is computed with a parameter lambda, where the optimal Lambda value is taken at around ~0.6 (https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el542823992413823529031866854\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el542823992413823529031866854_data = {\"mdsDat\": {\"x\": [-0.001195159628458718, -0.001078172542169535, 0.004157109432709636, 0.014746273126078919, 0.006017613605623176, 0.0009259023446654856, -0.013754031998873602, -0.011834610562730675, -0.0034623519869282273, 0.005477428210083517], \"y\": [-0.0032753960184736418, 0.003046258001797097, -0.006159872801465631, 0.005399255552529606, 0.0015000658040226888, 0.0018783465499637073, -0.010167649970161669, 0.010084774435182981, 0.008196498504064311, -0.010502280057459436], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.450248305250623, 5.540657958745836, 10.726321160427595, 9.21705764456927, 11.687654129416167, 6.761985772419789, 13.046104743220615, 12.619876346237529, 9.860306008362834, 8.089787931349742]}, \"tinfo\": {\"Term\": [\"san francisco\", \"way\", \"one\", \"still\", \"trying\", \"well\", \"said\", \"lot\", \"want\", \"part\", \"people\", \"mr\", \"made\", \"work\", \"get\", \"making\", \"united states\", \"high\", \"even\", \"p\", \"go\", \"day\", \"year\", \"think\", \"would\", \"going\", \"idea\", \"c\", \"many\", \"two\", \"hotels gardens\", \"profile chefs\", \"hotels il ristorante\", \"meal inspired\", \"enjoyable\", \"visiting chefs\", \"different well\", \"di pinto said\", \"peru\", \"di pinto\", \"ren redzepi\", \"certifiable trend\", \"120 euros\", \"dinners take place\", \"danny bowien\", \"lineup began\", \"noma\", \"bulgari hotel milan\", \"create one course\", \"lima\", \"known chef\", \"guest cooking stints\", \"upped\", \"mission chinese food\", \"try cuisine thats\", \"collaborate\", \"month food festival\", \"locals\", \"prolific chefs\", \"narisawa\", \"san francisco\", \"one\", \"mr\", \"name\", \"said\", \"well\", \"time\", \"get\", \"1\", \"year\", \"end\", \"two\", \"also\", \"according\", \"much\", \"say\", \"think\", \"told\", \"hope\", \"series\", \"part\", \"may\", \"l\", \"3\", \"people\", \"see\", \"ready\", \"n\", \"california\", \"would\", \"like\", \"ms\", \"world\", \"united states\", \"company\", \"way\", \"work\", \"new york\", \"go\", \"make\", \"certificates\", \"month issue\", \"florida board\", \"07 percent\", \"new three\", \"income issues\", \"william blair\", \"morgan stanley\", \"286 million\", \"month bills\", \"week bills\", \"385\", \"209\", \"236\", \"katy\", \"citigroup global markets\", \"bosc\", \"baird\", \"keybanc capital markets\", \"70 million\", \"monday elk river\", \"robert w\", \"revenue bonds\", \"pa .,\", \"treasurys schedule\", \"56 million\", \"temecula valley\", \"125 million\", \"02 percent\", \"rockford\", \"san francisco\", \"trying\", \"year\", \"part\", \"one\", \"still\", \"way\", \"people\", \"p\", \"go\", \"get\", \"much\", \"lot\", \"mr\", \"working\", \"would\", \"n\", \"said\", \"many\", \"2\", \"friday\", \"see\", \"asked\", \"born\", \"new york\", \"time\", \"instead\", \"since\", \"idea\", \"worked\", \"even\", \"well\", \"2013\", \"going\", \"company\", \"like\", \"university\", \"1\", \"ms\", \"paul eggermann said\", \"fans seeking autographs\", \"baseball cards\", \"expendable\", \"career record\", \"williamss cards\", \"san francisco giant\", \"immediate survivors include\", \"sharon williams\", \"charlie williams\", \"williams continued\", \"traded willie mays\", \"mets drafted\", \"great neck\", \"paul eggermann\", \"pitcher best known\", \"people would want\", \"giants offered\", \"barbara eggermann\", \"mets used\", \"trade bait\", \"last five innings\", \"nearby\", \"receive copies\", \"16 years\", \"fledgling mets took\", \"2 victory\", \"major leagues\", \"williams briefly drove\", \"regular thing\", \"settling\", \"well\", \"1971\", \"said\", \"see\", \"year\", \"mr\", \"take\", \"get\", \"back\", \"time\", \"want\", \"like\", \"would\", \"place\", \"28\", \"day\", \"share\", \"died\", \"led\", \"even\", \"san francisco\", \"number\", \"including\", \"also\", \"los angeles\", \"change\", \"still\", \"ms\", \"long\", \"7\", \"made\", \"people\", \"one\", \"work\", \"go\", \"going\", \"make\", \"world\", \"part\", \"much\", \"according\", \"think\", \"two conversations\", \"european edition\", \"next two months\", \"1915\", \"quickly collapse candlestick\", \"grayson completed 8\", \"would return\", \"rolfe\", \"senior bowl\", \"bryce petty\", \"colorado state\", \"15 passes\", \"possibly broadcasting\", \"telegraph company\", \"following concerns\", \"american telephone\", \"73 yards\", \"development company planning\", \"theodore vail\", \"interception\", \"build houses\", \"nebraska rushed\", \"top passers\", \"using explosives\", \"scrap\", \"cornhuskers\", \"123 yards\", \"petty\", \"13 passing\", \"president carried\", \"mozzarella\", \"baylor\", \"ap\", \"tonjes farm dairy\", \"gonzalez admits\", \"blender\", \"star anise\", \"pulse\", \"mesh sieve\", \"ricotta\", \"rich fluid\", \"salvaging\", \"fizz\", \"stalk\", \"several menu items\", \"san francisco\", \"quite dry\", \"tarragon\", \"simple syrup\", \"active medium appears\", \"stems\", \"strained yogurt\", \"c\", \"carroll gardens\", \"delicious ingredient\", \"cloudy liquid runoff\", \"jan\", \"stir\", \"one\", \"beverages\", \"said\", \"though\", \"mr\", \"says\", \"day\", \"world\", \"time\", \"never\", \"lot\", \"make\", \"f\", \"want\", \"would\", \"become\", \"united states\", \"think\", \"part\", \"long\", \"well\", \"left\", \"work\", \"still\", \"week\", \"see\", \"end\", \"like\", \"also\", \"people\", \"according\", \"get\", \"year\", \"new york\", \"even\", \"made\", \"ms\", \"janssen\", \"toronto blue jays\", \"going 29\", \"90 saves\", \"52 e\", \"washington nationals completed\", \"6 million contract\", \"guaranteed\", \"mutual option\", \"avoided salary arbitration\", \"since 2006\", \"sounds like fun\", \"striking facade\", \"never strengthen\", \"confront\", \"roommate conflicts\", \"full 28 hours\", \"psychologist\", \"research results\", \"developmental life transitions\", \"navigating relationship heartaches\", \"every subject\", \"abu dhabi\", \"solving\", \"catalan\", \"stronger olympic stadiums\", \"extra coaches\", \"disappointment often leads\", \"often outsourced\", \"architectural prowess\", \"catalan art\", \"28 hours\", \"san francisco\", \"still\", \"said\", \"year\", \"one\", \"way\", \"much\", \"lot\", \"years\", \"make\", \"first time\", \"according\", \"time\", \"also\", \"well\", \"united states\", \"maybe\", \"matter\", \"something\", \"work\", \"like\", \"week\", \"mr\", \"think\", \"end\", \"found\", \"3\", \"get\", \"say\", \"worked\", \"going\", \"trying\", \"world\", \"made\", \"though\", \"ms\", \"would\", \"see\", \"part\", \"even\", \"people\", \"historical average\", \"previously came\", \"violating restrictions\", \"recorded history\", \"december 2013 levels\", \"survey released tuesday\", \"state adapts\", \"22 percent statewide\", \"governor called\", \"washing cars\", \"lawn watering\", \"fine people\", \"supplies\", \"measurable rainfall\", \"californians\", \"20 percent reduction\", \"authorized cities\", \"californias water\", \"monthly water consumption\", \"drought emergency\", \"closest\", \"finally meet gov\", \"restrictions loom\", \"sierra nevada snowpack\", \"jerry browns call\", \"havana\", \"moulitsas\", \"masschusetts\", \"gentlewomans agreement\", \"associates noted\", \"downtown san francisco\", \"reaching\", \"drought\", \"goal\", \"said\", \"going\", \"mr\", \"san francisco\", \"people\", \"time\", \"one\", \"made\", \"work\", \"well\", \"high\", \"think\", \"ms\", \"added\", \"fact\", \"get\", \"part\", \"two\", \"even\", \"many\", \"according\", \"home\", \"want\", \"would\", \"way\", \"2013\", \"year\", \"kind\", \"day\", \"change\", \"years\", \"like\", \"also\", \"go\", \"much\", \"make\", \"said joe pentangelo\", \"passengers exited\", \"171 passengers\", \"another departing\", \"9 team searched\", \"one arriving\", \"tel aviv\", \"pentangelo said\", \"boeing 757 aircraft\", \"two aircraft\", \"kennedy international airport\", \"airline said\", \"215 passengers\", \"aircraft\", \"plane\", \"boeing 777 aircraft\", \"port authority\", \"designation\", \"flight 468\", \"unfounded\", \"denver last weekend\", \"national team beat\", \"collegiate bowl\", \"inactive\", \"stadium might\", \"created health problems\", \"implosion\", \"american team\", \"west shrine classic\", \"marvin kloss\", \"mr\", \"cincinnati\", \"15 p\", \"said\", \"san francisco\", \"1\", \"new york\", \"company\", \"university\", \"one\", \"made\", \"money\", \"time\", \"year\", \"much\", \"4\", \"way\", \"start\", \"game\", \"10\", \"going\", \"long\", \"f\", \"part\", \"30\", \"people\", \"thats\", \"likely\", \"kind\", \"see\", \"work\", \"expected\", \"go\", \"3\", \"according\", \"like\", \"well\", \"even\", \"end\", \"make\", \"united states\", \"get\", \"also\", \"minna seidman greene\", \"four sons\", \"suny syracuse\", \"paramus\", \"marlene levenson\", \"january 12\", \"greene -- marshall\", \"harry\", \"stuyvesant high school\", \"1949 ), earned\", \"psychoanalyst\", \"53 years\", \"psychiatrist\", \"september 26\", \"interment\", \"january 15\", \"jones said\", \"000 high\", \"major automakers tesla\", \"build 100 high\", \"would help open\", \"volkswagen announced\", \"charging connectors\", \"speed chargers\", \"new charging locations\", \"chargers\", \"infrastructure deployment\", \"april 2016\", \"vw\", \"passed away\", \"al\", \"ca\", \"subject\", \"many\", \"one\", \"also\", \"time\", \"two\", \"mr\", \"people\", \"2015\", \"called\", \"california\", \"make\", \"would\", \"way\", \"2\", \"world\", \"help\", \"ms\", \"become\", \"1\", \"said\", \"made\", \"according\", \"going\", \"country\", \"year\", \"play\", \"company\", \"3\", \"years\", \"san francisco\", \"well\", \"even\", \"part\", \"work\", \"still\", \"though\", \"see\", \"air plant\", \"entire plant\", \"little tricky\", \"pronged cradle\", \"flora grubb gardens\", \"29 depending\", \"root structure\", \"bowl\", \"minimalist appeal\", \"hold plants\", \"easily removed\", \"grubb said\", \"grubb\", \"said flora grubb\", \"spindly steel base\", \"floragrubb\", \"additional option\", \"plant come\", \"whole stand\", \"sitting around\", \"elevating\", \"stand really allows\", \"thigmotrope perch\", \"really lets\", \"626\", \"watering\", \"7256\", \"fore\", \"soil\", \"actually work\", \"online\", \"made\", \"said\", \"according\", \"way\", \"san francisco\", \"lot\", \"united states\", \"ms\", \"go\", \"say\", \"new york\", \"information\", \"put\", \"mr\", \"right\", \"asked\", \"week\", \"though\", \"like\", \"something\", \"used\", \"world\", \"working\", \"well\", \"time\", \"could\", \"year\", \"making\", \"even\", \"people\", \"would\", \"one\", \"see\", \"also\", \"get\", \"company\", \"work\", \"part\", \"much\", \"mike isaac reports\", \"lure daniel barenboim\", \"david robertson\", \"berlin philharmonic\", \"ludovic morlot\", \"simon rattle\", \"wunderkind young conductors\", \"lukes\", \"would step\", \"succeed alan gilbert\", \"seattle symphony\", \"detroit symphony orchestra\", \"conductors\", \"orchestra sees\", \"baton\", \"whose exciting tenure\", \"next season esa\", \"maestros named\", \"sguin\", \"keep subscribers\", \"marin alsop\", \"21st century\", \"contract elsewhere\", \"robert spano\", \"orchestras composer\", \"andris nelsons\", \"formula\", \"orchestra\", \"baltimore symphony orchestra\", \"yannick nzet\", \"major investment\", \"long toyed\", \"sharing app similar\", \"hugely popular ride\", \"match made\", \"also adding engineers\", \"longtime pet project\", \"way\", \"united states\", \"one\", \"work\", \"want\", \"said\", \"even\", \"plenty\", \"well\", \"may\", \"san francisco\", \"add\", \"mr\", \"much\", \"still\", \"high\", \"past\", \"begin\", \"course\", \"year\", \"going\", \"people\", \"also\", \"lot\", \"thats\", \"think\", \"according\", \"see\", \"know\", \"years\", \"time\", \"worked\", \"part\", \"week\", \"make\", \"new york\", \"get\", \"go\", \"ms\", \"would\", \"1\"], \"Freq\": [118.0, 62.0, 104.0, 46.0, 37.0, 69.0, 123.0, 45.0, 43.0, 51.0, 58.0, 113.0, 55.0, 52.0, 52.0, 23.0, 45.0, 29.0, 47.0, 16.0, 43.0, 36.0, 73.0, 41.0, 52.0, 47.0, 31.0, 33.0, 42.0, 42.0, 0.6278196801038096, 0.6076328959198724, 0.6013958814137154, 0.6003363799510573, 0.6013527720922134, 0.6002886945768938, 0.6001329998327669, 0.5987288417053632, 0.5989593149608401, 0.5970876367865164, 0.5979726308441057, 0.5913612516487813, 0.589129082214788, 0.5861613667922705, 0.5812941900185556, 0.5809833816163541, 0.5814501389878305, 0.5802289503311315, 0.57844708626976, 0.578586546922302, 0.5761502710124529, 0.5767532930631839, 0.5742390426686974, 0.5660592395825715, 0.5602284042269431, 0.559758959332475, 0.5571313971577981, 0.5577044569589595, 0.5563709371047835, 0.5544245167369881, 19.229896997790487, 16.48063593738803, 15.55454514983886, 4.448509793380242, 16.295976087357204, 10.544854697463538, 11.766634609220612, 8.40830123011108, 7.640886448679958, 10.50713175312304, 6.731224126000234, 6.909889492315963, 8.250709530566548, 8.073703746016069, 7.562553724491342, 6.313232077115387, 6.325183855038234, 4.677399589364752, 2.3165005642279555, 3.746660694483571, 7.00399114870471, 4.885118967750365, 4.391639773074809, 5.275400766061175, 7.462533125574293, 6.7687361361037635, 2.4398036832723475, 5.485911391298809, 5.45199920928902, 6.665839161228036, 6.278038600360368, 6.404233639415336, 6.087954312031714, 5.902358332370702, 5.744439481378749, 6.449116145005709, 5.980840395674749, 5.732569055503219, 5.505331287165279, 5.529598602879687, 0.3774918186949556, 0.37809089137928104, 0.3752232749629123, 0.37382727042948743, 0.37394664535115224, 0.37426559264388626, 0.37181515812272625, 0.3703710868390941, 0.36991026667032795, 0.36944107441796814, 0.3687427004178143, 0.36931242232259154, 0.36857920235288594, 0.3688523456207082, 0.3643674301370079, 0.3647388726565991, 0.36527720732906205, 0.36394672485526747, 0.3643781942444854, 0.3622013555362068, 0.36272016612183366, 0.3638629393700373, 0.36236472430254685, 0.3622605742896565, 0.36093342125451117, 0.3610573539514142, 0.35979152077177873, 0.35813817972295353, 0.3587868060912519, 0.35815043076419667, 6.3902336214400215, 3.1746449652315856, 4.285238122177358, 3.408332510231361, 4.690433003860318, 2.9895328310855565, 3.322002687380222, 3.2008985263952487, 1.5836549281581462, 2.7149059912609337, 2.988517319972905, 2.8673301492942316, 2.6541705653702117, 4.252129149861062, 2.207980014677897, 2.7847479167269085, 2.353736761705977, 4.227047292504738, 2.401693090918855, 2.2607185814783133, 1.3633462959874234, 2.573188532131915, 1.978575226818987, 1.6721018860944077, 2.4232430280366777, 3.1646062228345584, 1.7076944256951199, 1.531130738417162, 1.9182005439896728, 1.8145829826860336, 2.3041763542064233, 2.681127769451503, 1.9669933057703815, 2.246617277436327, 2.1238121935220278, 2.180741974062779, 2.058825817943167, 2.1017639396448264, 2.0564153043611504, 0.5346059725169959, 0.520849839141343, 0.5152377925438748, 0.5157206461357489, 0.5106643880525665, 0.5091438623170356, 0.5067216156338492, 0.5079159523663159, 0.49897117718636474, 0.5025027167928736, 0.5031575666389294, 0.49360024449370354, 0.49010831690425744, 0.48740950575123076, 0.4844875719333742, 0.48325606373465907, 0.48342114509486694, 0.47754595705703706, 0.4800795616934039, 0.48185775327452085, 0.48026197722221586, 0.4738186727595767, 0.4770638856929881, 0.47502636994329595, 0.4745671083426267, 0.47310468648994375, 0.47578031241023466, 0.46445359092464594, 0.4638262754980335, 0.4642423268336445, 1.2670061980437404, 10.62544435303213, 0.8110834586231187, 15.013774992487605, 7.201082724519251, 8.926748896167409, 12.159510014167859, 5.737437592674314, 6.934384337791325, 5.203599267255752, 9.229720626444147, 5.816476395250863, 6.09429267992419, 6.4159903185514215, 3.5851824127812417, 2.163970825053297, 4.962642058326667, 2.8638827510312947, 3.2660524839235516, 3.2533000427148333, 5.720994538008576, 10.383757231674892, 4.328801725244842, 4.345891588454594, 6.124910954345154, 3.438844983452964, 3.494359128995859, 5.285996768378577, 5.5090220614887535, 4.252875813942811, 2.970314796573284, 5.733098168170048, 5.893553245285624, 8.28417114085751, 5.445882633950389, 4.888047311048268, 4.964229542764025, 4.825594742118563, 4.746572460193679, 4.95324180752872, 4.841306382478725, 4.932308639990489, 4.427257800412815, 0.6316207880967717, 0.631431076739425, 0.6313038496783473, 0.6312773395595344, 0.6312493775680887, 0.63119033474769, 0.6311899583362667, 0.6311554360314434, 0.6310718189224088, 0.6310251976789791, 0.631011055364075, 0.6309912668778211, 0.6309713708454463, 0.630917382692732, 0.6309058214847304, 0.6308852264025695, 0.6307315429957393, 0.630604262161601, 0.6305414014539088, 0.6304959632178097, 0.6304741313552579, 0.6303678220147039, 0.6303537334728601, 0.6303519589618645, 0.6303260941197772, 0.630254575949349, 0.6302368846124535, 0.6302156980266274, 0.6302069867908309, 0.6302030075843559, 0.887414719826996, 0.8583428524131866, 1.0613043758178347, 0.8583682870707902, 0.8572272227275654, 0.8569927721839056, 0.8548798673187628, 0.8532649547666551, 0.8528151431158033, 0.8499046762177335, 0.8446454020382285, 0.8435792973413022, 0.8419261521431985, 0.840345976988156, 0.8387931185478334, 12.493083954760863, 0.8366650496796375, 0.8343330195930695, 0.8340909332748226, 0.8341207235503244, 0.8308404055423253, 0.830568098764093, 5.067902310050993, 0.8288293468537173, 0.8280392055031356, 0.82852574415429, 3.875270462202148, 0.8269556783346163, 9.655993193904868, 0.8259820095286422, 10.550920601783526, 5.384018215742453, 9.563679905530654, 3.6194810474090033, 4.795452710570041, 5.471190799535504, 7.511773049265333, 3.453618472566306, 5.31730864747382, 5.307170489744592, 4.10484013270894, 4.898958538843226, 5.441927500026412, 4.010399151877954, 4.904669237865398, 4.626641866367763, 5.210991133414653, 4.101269601493572, 6.04205593393833, 3.525059424879787, 5.132961690639849, 4.781191664748271, 4.181702484979251, 4.986489036126781, 4.402925716131755, 4.6654006279873155, 5.028389865215859, 5.122062966743299, 5.005954453833313, 4.81634505020927, 5.314405332392793, 4.564413960051143, 4.576854465137558, 4.72013601114995, 4.600380824370967, 0.8077855746537566, 0.8069278538981712, 0.8068940332848658, 0.8066491747720025, 0.8065339392145703, 0.8062414181841656, 0.8061808001897531, 0.8059731034394937, 0.8058650956744212, 0.8055520504411838, 0.8050919264520997, 0.6874358086333808, 0.6843187890849215, 0.6646771269741311, 0.6631778373665462, 0.661752462163847, 0.6767203337133179, 0.6555272191538565, 0.6510850588816476, 0.6500500526530898, 0.6497634638673576, 0.6498281730649926, 0.6701277006539519, 0.6469409427641938, 0.6669302207754512, 0.6662158285060921, 0.643133873605549, 0.6424956459028478, 0.642235036257578, 0.6624583310931592, 0.6585865527368794, 0.6574346744696004, 15.487677465670265, 7.625997897190921, 14.816520486472266, 10.096655339955353, 12.040081605418536, 8.329310097236036, 7.433374776084307, 6.813347472785356, 6.440998339610561, 6.809662116922579, 3.272816931120125, 7.271219118122112, 9.077192956173977, 6.996470274515692, 7.880777850615474, 5.962563215890277, 2.7128926761214482, 3.9936820294708126, 4.546523320703914, 6.379115890655405, 5.979664445360091, 5.100644340304996, 9.498952368906869, 5.42853300432709, 5.295823645184992, 3.8625082352715387, 4.805320562946026, 6.042595878821481, 5.215956812357738, 4.282175406676472, 5.671981415813001, 4.998629915206484, 5.560007911083535, 5.920067615271874, 5.149632953184297, 5.566681481779986, 5.626247218723712, 5.434020671582794, 5.433629552554728, 5.270477277487546, 5.2531747608191885, 0.5066432139741497, 0.5064951582276647, 0.5064862819838706, 0.5064418218649555, 0.5063674586669474, 0.5062884798221664, 0.5060293329533522, 0.5059752075911945, 0.505940807215246, 0.5057373242575136, 0.5057184277207254, 0.5056924696388743, 0.5056557417145531, 0.5051886934910956, 0.5051744915010251, 0.5051660097569552, 0.5051344497790208, 0.5050883327612641, 0.5050409533443899, 0.5049188162297836, 0.5048636651683431, 0.5048270555939391, 0.5047008945821462, 0.5045010015719039, 0.50346169204855, 0.3088044624205523, 0.3074939737867966, 0.30694078654856427, 0.3048858572102935, 0.3042123870061585, 0.6323786789146489, 0.6018649536986962, 0.5772163742320544, 1.2972194777330064, 8.141687201239, 4.12621431950638, 7.2950888995486425, 7.222971825170184, 4.520555612597802, 5.444014768949946, 6.196344678949212, 4.22901936962896, 4.120976309968598, 4.697995907738232, 2.941430655862487, 3.288238519387493, 3.6206600825708577, 2.9952820774116016, 2.503214523646699, 3.6998320744167836, 3.646807208689772, 3.237261265028869, 3.3750833730688425, 3.185894876142313, 3.639237863581973, 2.7936889311579356, 3.132844446833175, 3.432756707945819, 3.726143312420957, 2.7742340983600218, 4.017402774383313, 2.8068617503479967, 2.764001091114555, 2.2745605899129164, 2.9286807403767474, 3.078244422607455, 3.242625830078167, 2.9639603773105545, 2.940019609249038, 2.8300955749037815, 0.8784343738370576, 0.8783565112291098, 0.8781112021524574, 0.8777847576505146, 0.8777686980119251, 0.8775269662007406, 0.8774595309410712, 0.8773679681675023, 0.8772758726097147, 0.8772651408133113, 0.8771805803466155, 0.8770876475564844, 0.8769489714355844, 0.8769332162451199, 0.8768147098124957, 0.8767410333662656, 0.8762206554087502, 0.8759016698858677, 0.8758977881722749, 0.8727580907720306, 0.7811071033588548, 0.7792465447554519, 0.769796703294102, 0.77062183382466, 0.7655382351468164, 0.7622882514133206, 0.7624948194660772, 0.7603669554089966, 0.7598596687208525, 0.7588569688214363, 22.380347000445774, 1.033144864132081, 1.0256530046741077, 17.981369954548263, 16.545996904546556, 8.70668115284096, 8.71499806671746, 8.216484355741065, 7.725170234022723, 13.808343346832132, 8.691944036906197, 5.590620496118902, 10.676336915119387, 9.797207029540955, 7.759243459267256, 4.865165977210773, 8.494757857567038, 5.278549599049572, 4.5955768581480765, 5.113690330510418, 6.966194454320537, 5.6481283113308445, 5.354655541316483, 7.215877232735495, 4.508118654199235, 7.581703317429033, 5.36790329702415, 4.160647138060731, 5.743279310500105, 6.824931742151251, 6.892312810054274, 4.687083613262072, 5.989888380645893, 5.299325139093951, 6.704369675787615, 6.1044753481098954, 6.902408918772792, 5.768124713078384, 5.4969137988542505, 5.635717787966702, 5.559777465479745, 5.563964844989862, 5.49880259502124, 0.7725114309437625, 0.7717254800095322, 0.7699238669546737, 0.7666307509465939, 0.7645009159465552, 0.7623185124250139, 0.7581385050863733, 0.7549737917414595, 0.754072617087129, 0.7496419153287174, 0.7480214207092881, 0.748473038791777, 0.7469001061679928, 0.7460046742933222, 0.7380267753395683, 0.7364465538031388, 0.6778144668588002, 0.6706746456084977, 0.6577726812232383, 0.6502112810455911, 0.6405655463529034, 0.6304771022487378, 0.6294149088877878, 0.6284735347758377, 0.627905662217925, 0.6266270102390231, 0.6261840799514045, 0.6254593117081667, 0.6263459821625869, 0.9058400001758249, 0.8896574360971292, 1.0482091771002529, 3.7287756421474167, 8.397256750626902, 16.217067876898728, 9.414966834832345, 12.29088786520956, 7.645861446867393, 15.499222775417207, 9.34142391500247, 3.408293491441232, 5.312425176281565, 6.597474906226104, 7.676146216280277, 8.13927400721375, 9.07611279574018, 6.57503447932719, 7.384377080369278, 4.953964403925768, 7.611057257112889, 5.555407779222928, 7.053533482648939, 12.930183521003812, 7.752848548427689, 7.883005262652953, 6.9474157495787034, 5.373296873667903, 8.92193771546636, 4.275605771881498, 6.279174717289179, 5.4484342247325985, 5.954614015018347, 10.883571116787964, 7.887448112599107, 6.3142015501935775, 6.345931144068601, 6.2664104323649985, 5.7722451261309065, 5.621886785569545, 5.754589759945574, 0.607747209405156, 0.5937481276786055, 0.5902263392380227, 0.5837268991213573, 0.5814608418819879, 0.5812851580170144, 0.5789385070989194, 0.5781298665979594, 0.57712868716574, 0.5725608491506067, 0.5717332251278912, 0.5705424405814109, 0.5707495910718396, 0.5647354963280562, 0.5649830874724064, 0.5644234762613842, 0.5649921190266962, 0.5602656247903458, 0.5545443364881847, 0.5530238139213941, 0.5522260458010759, 0.5511064782240905, 0.5460064112899217, 0.547599991652559, 0.5463046826847767, 0.5332249786694264, 0.5267823740663806, 0.6736593775599518, 0.6735291390955445, 0.41250982805405456, 1.1622725623715853, 8.289658930848152, 13.853375258513589, 7.32217444438321, 7.3410539594498, 11.252557304132194, 5.847624674908659, 5.649543935916439, 5.981666286559291, 5.432579539998336, 5.121547076664296, 5.588280774713738, 2.862565743688796, 4.116084041523691, 9.342428441996828, 3.8409621885620826, 4.090811796743029, 4.566919442783681, 4.914994854799957, 5.3687171319865445, 3.9995371833163227, 4.301380701707534, 5.160254132368782, 4.1714436726153785, 6.495025354866547, 7.129201078104743, 4.171890533212338, 6.5138247939868235, 3.32047359979335, 5.020315893705956, 5.660834644346718, 5.260265307662302, 7.573796538237883, 5.145948610580438, 5.218451857488738, 5.02407854276954, 4.611411755506062, 4.891456668442924, 4.693495122957, 4.578741229616525, 0.46174494617548306, 0.4010869947045675, 0.39773108915724614, 0.3933769781064321, 0.3932342795560865, 0.38522647678186184, 0.38211523777497103, 0.38174151246625204, 0.3817120618641632, 0.37509082081023926, 0.3768226483632019, 0.37547882305346447, 0.37357326526606416, 0.36910312167480863, 0.3693659588591562, 0.3682565348559481, 0.36702298411637196, 0.36815390611517534, 0.3675391011983315, 0.36580852435202804, 0.3661157498236586, 0.3626598821365548, 0.3573567443120183, 0.36019440893588334, 0.3554555757970447, 0.3567761804397505, 0.3563158259962012, 0.3575216488051248, 0.3567949410396389, 0.35669571044526094, 0.5411729368302775, 0.5319541432328204, 0.5309411180353278, 0.5295842664977435, 0.5062555195321928, 0.5092196471180724, 0.5089163625523304, 6.775077784222384, 5.378553265049672, 9.511790086202748, 5.76169729164569, 4.709912836373297, 9.722277315050059, 4.6521269793567335, 1.242257545783483, 5.91146002198852, 3.3859108024162285, 8.381641354490108, 1.3675124667546994, 8.014927743285103, 4.763220691585067, 4.3462148913078265, 3.167249332416059, 2.494172246049361, 1.5349356470905293, 2.7605803159001874, 5.397766762338081, 4.067433981647373, 4.646494740493149, 4.49483320145923, 3.923973302579736, 3.160959741010979, 3.6393743887194456, 4.371137652111437, 4.064150994658108, 3.2450372454705523, 3.6125894436914474, 5.252681391721876, 2.8370876941215477, 4.011801416729691, 3.258480312608653, 3.771907761696649, 3.6961313625220074, 3.85460882808039, 3.541857404054077, 3.643416672642053, 3.6411738960214395, 3.4231846926497216], \"Total\": [118.0, 62.0, 104.0, 46.0, 37.0, 69.0, 123.0, 45.0, 43.0, 51.0, 58.0, 113.0, 55.0, 52.0, 52.0, 23.0, 45.0, 29.0, 47.0, 16.0, 43.0, 36.0, 73.0, 41.0, 52.0, 47.0, 31.0, 33.0, 42.0, 42.0, 1.332228692871841, 1.3257140758779005, 1.322389537130304, 1.3210469262597802, 1.3242235846784645, 1.321997021288549, 1.3220398473585104, 1.3192349372325622, 1.322780198565972, 1.3195610135752722, 1.3223975774657972, 1.3206460334243264, 1.3179051153166392, 1.3167682672194423, 1.3137731790086258, 1.3145555581674464, 1.3162129158830371, 1.3144141317754554, 1.3128575340224726, 1.3145007859560862, 1.311529654284449, 1.3144539254801473, 1.3131732997109862, 1.3113850839962853, 1.3063090357359952, 1.3093342821733585, 1.305976990950557, 1.3095158873242034, 1.3073530732774898, 1.306342244706503, 118.27138777646354, 104.45865740854995, 113.56083144899885, 21.10803028808486, 123.53313271096006, 69.66859892046618, 81.54304948304414, 52.936279947553466, 46.87640294728948, 73.7783185195315, 40.66242459524681, 42.66938633753722, 56.19520797706269, 57.20938934023404, 52.253146637746575, 40.5237439024217, 41.45389983268787, 27.13759512653623, 9.67792159445473, 20.03636654062739, 51.924098277614725, 30.46392527501399, 26.003989061405303, 34.6017039016317, 58.68323485468682, 51.08433933231186, 11.04353786008468, 38.452098921421424, 38.22134964917273, 52.41456700024551, 47.76021020710361, 50.15326867522425, 46.55738829261837, 45.69126787969284, 43.64439636907469, 62.03543279114569, 52.91752267120749, 47.059457663289976, 43.90680375591779, 47.9832928745843, 1.0502034016844313, 1.0519195654234175, 1.052967169037476, 1.052317907106769, 1.0537011841687192, 1.0551003048188259, 1.053669822115907, 1.0545517581560648, 1.0542526439023165, 1.0559506871626416, 1.0544556930918436, 1.0567089429065941, 1.0557087541143733, 1.0568626799898502, 1.0523175418101713, 1.055031766430377, 1.0580451986218997, 1.0578014816050456, 1.0605449536816969, 1.0553456656039515, 1.05728826925959, 1.0611516698859769, 1.0580127116600462, 1.0590247829388368, 1.0580087997488676, 1.0584088698993699, 1.0574389728127749, 1.05699168157365, 1.060002525715579, 1.0599549784120612, 118.27138777646354, 37.69288776602054, 73.7783185195315, 51.924098277614725, 104.45865740854995, 46.88968266738928, 62.03543279114569, 58.68323485468682, 16.16795087565762, 43.90680375591779, 52.936279947553466, 52.253146637746575, 45.81345398211283, 113.56083144899885, 33.189627761898365, 52.41456700024551, 38.452098921421424, 123.53313271096006, 42.472544642321246, 38.49534020391544, 14.173020374767647, 51.08433933231186, 30.54416596327944, 21.751567936753005, 47.059457663289976, 81.54304948304414, 23.199066227517207, 19.103133622903314, 31.308563476348485, 28.439960209783866, 47.648950490349065, 69.66859892046618, 34.1783500940882, 47.42661123245574, 43.64439636907469, 47.76021020710361, 40.46066255146626, 46.87640294728948, 50.15326867522425, 1.2947916165604907, 1.2910579340077257, 1.2835908561742029, 1.2881593556582875, 1.2890922200784702, 1.285461320165302, 1.2884181758875979, 1.2923585257307568, 1.2788904458143873, 1.2887348868268402, 1.2970385256121597, 1.2835251913292005, 1.2850150027400082, 1.2917964059481482, 1.28417887015648, 1.283103373484157, 1.2861316643132636, 1.2745866271739246, 1.2815906612405934, 1.2877903507331716, 1.2900880207595389, 1.2756902284825533, 1.2860068713095307, 1.2841367795428011, 1.2843214599457697, 1.2819847283638115, 1.2936434183957757, 1.2728152354250457, 1.2808072232554255, 1.2835018266488993, 4.515756337302654, 69.66859892046618, 2.6015717075791893, 123.53313271096006, 51.08433933231186, 73.7783185195315, 113.56083144899885, 40.53747677882044, 52.936279947553466, 35.8201410418112, 81.54304948304414, 43.010045014290384, 47.76021020710361, 52.41456700024551, 22.6551601353753, 11.021776903555681, 36.75063979749712, 16.810221403344514, 20.397689565821853, 20.451728420234076, 47.648950490349065, 118.27138777646354, 32.1621681230151, 33.37592672439402, 56.19520797706269, 23.635945572678335, 24.60569233451534, 46.88968266738928, 50.15326867522425, 33.517643051569415, 19.356767543749847, 55.22357674225935, 58.68323485468682, 104.45865740854995, 52.91752267120749, 43.90680375591779, 47.42661123245574, 47.9832928745843, 46.55738829261837, 51.924098277614725, 52.253146637746575, 57.20938934023404, 41.45389983268787, 1.2123023031397397, 1.2121125917823932, 1.2119853647213152, 1.2119588546025026, 1.2119308926110568, 1.2118718497906582, 1.2118714733792348, 1.2118369510744116, 1.211753333965377, 1.2117067127219472, 1.2116925704070431, 1.211672781920789, 1.2116528858884146, 1.2115988977357, 1.2115873365276983, 1.2115667414455378, 1.2114130580387075, 1.2112857772045693, 1.2112229164968769, 1.2111774782607778, 1.2111556463982258, 1.211049337057672, 1.2110352485158282, 1.2110334740048327, 1.2110076091627455, 1.210936090992317, 1.2109183996554216, 1.2108972130695954, 1.2108885018337991, 1.2108845226273242, 1.8516973315103233, 1.8343672456895452, 2.458011015351126, 1.8579644016479668, 1.8624106909409097, 1.863103241209231, 1.8644362122910074, 1.8633992760634992, 1.8629495855158589, 1.8633925115294585, 1.8696417847986948, 1.8681796079420012, 1.8654565909831031, 1.868427996249274, 1.8642707899077569, 118.27138777646354, 1.8687352075939783, 1.8621849838543687, 1.8673566709669873, 1.8687271769060212, 1.861627317849559, 1.8687659815931355, 33.31123534721726, 1.8685597850196076, 1.8677380607503682, 1.869983296452598, 22.54466089086088, 1.8699055516950585, 104.45865740854995, 1.8693771215738482, 123.53313271096006, 41.24134412218552, 113.56083144899885, 22.657316432472136, 36.75063979749712, 46.55738829261837, 81.54304948304414, 21.518985138441472, 45.81345398211283, 47.9832928745843, 31.01117642639789, 43.010045014290384, 52.41456700024551, 30.776351879281567, 45.69126787969284, 41.45389983268787, 51.924098277614725, 33.517643051569415, 69.66859892046618, 26.0346970561446, 52.91752267120749, 46.88968266738928, 36.494419693705154, 51.08433933231186, 40.66242459524681, 47.76021020710361, 56.19520797706269, 58.68323485468682, 57.20938934023404, 52.936279947553466, 73.7783185195315, 47.059457663289976, 47.648950490349065, 55.22357674225935, 50.15326867522425, 1.3723605482774444, 1.371502827521859, 1.3714690069085536, 1.3712241483956906, 1.3711089128382583, 1.3708163918078538, 1.3707557738134413, 1.3705480770631815, 1.3704400692981094, 1.370127024064872, 1.3696669000757877, 1.3738420134229536, 1.3739444555055824, 1.3366322617858393, 1.3368373239617626, 1.3364724015639606, 1.373843552658951, 1.3348645924367242, 1.3338192413208618, 1.333033213705139, 1.332745941551316, 1.3333616318202401, 1.375662097238402, 1.3319024048552595, 1.3752189819336773, 1.3739293883569101, 1.3305203873883804, 1.3312311374311265, 1.3317252012073646, 1.374723133767584, 1.375107143491384, 1.3737782395426033, 118.27138777646354, 46.88968266738928, 123.53313271096006, 73.7783185195315, 104.45865740854995, 62.03543279114569, 52.253146637746575, 45.81345398211283, 42.46844533151644, 47.9832928745843, 16.00157605373043, 57.20938934023404, 81.54304948304414, 56.19520797706269, 69.66859892046618, 45.69126787969284, 12.877165971962155, 24.12094570919917, 29.99863638869988, 52.91752267120749, 47.76021020710361, 36.494419693705154, 113.56083144899885, 41.45389983268787, 40.66242459524681, 23.000608610590973, 34.6017039016317, 52.936279947553466, 40.5237439024217, 28.439960209783866, 47.42661123245574, 37.69288776602054, 46.55738829261837, 55.22357674225935, 41.24134412218552, 50.15326867522425, 52.41456700024551, 51.08433933231186, 51.924098277614725, 47.648950490349065, 58.68323485468682, 1.0987537691114202, 1.0986057133649352, 1.0985968371211414, 1.098552377002226, 1.0984780138042183, 1.0983990349594372, 1.098139888090623, 1.098085762728465, 1.0980513623525168, 1.0978478793947843, 1.0978289828579961, 1.097803024776145, 1.0977662968518236, 1.0972992486283664, 1.0972850466382957, 1.097276564894226, 1.0972450049162914, 1.0971988878985348, 1.0971515084816605, 1.0970293713670545, 1.0969742203056136, 1.0969376107312097, 1.096811449719417, 1.0966115567091745, 1.0955722471858205, 1.1546406570530734, 1.154796051039091, 1.1576317670984215, 1.1568392520643058, 1.15759396975206, 2.4440511539798377, 2.342091236165801, 2.328140111610262, 8.6435275784382, 123.53313271096006, 47.42661123245574, 113.56083144899885, 118.27138777646354, 58.68323485468682, 81.54304948304414, 104.45865740854995, 55.22357674225935, 52.91752267120749, 69.66859892046618, 29.231674706752166, 41.45389983268787, 50.15326867522425, 34.939154226341984, 24.577689568376446, 52.936279947553466, 51.924098277614725, 42.66938633753722, 47.648950490349065, 42.472544642321246, 57.20938934023404, 33.84682794163153, 43.010045014290384, 52.41456700024551, 62.03543279114569, 34.1783500940882, 73.7783185195315, 37.410126363983636, 36.75063979749712, 24.60569233451534, 42.46844533151644, 47.76021020710361, 56.19520797706269, 43.90680375591779, 52.253146637746575, 47.9832928745843, 1.436524401649646, 1.4364465390416985, 1.4362012299650457, 1.435874785463103, 1.4358587258245135, 1.435616994013329, 1.4355495587536597, 1.4354579959800908, 1.4353659004223034, 1.4353551686258998, 1.435270608159204, 1.435177675369073, 1.4350389992481727, 1.4350232440577084, 1.434904737625084, 1.434831061178854, 1.4343106832213386, 1.4339916976984561, 1.4339878159848634, 1.4308481185846191, 1.3931480098937086, 1.392821851045679, 1.3859711983958687, 1.3878227485989152, 1.388389249172329, 1.3826639083510162, 1.3839297431257904, 1.3822129764497362, 1.3825233299090085, 1.3811190324520948, 113.56083144899885, 2.072510396712087, 2.090970571677034, 123.53313271096006, 118.27138777646354, 46.87640294728948, 47.059457663289976, 43.64439636907469, 40.46066255146626, 104.45865740854995, 55.22357674225935, 28.827096477340678, 81.54304948304414, 73.7783185195315, 52.253146637746575, 24.12406958603051, 62.03543279114569, 28.477973291763476, 23.094128773195152, 27.724353095746658, 47.42661123245574, 33.517643051569415, 31.01117642639789, 51.924098277614725, 23.25466283641006, 58.68323485468682, 32.40429348344451, 21.107090321245124, 37.410126363983636, 51.08433933231186, 52.91752267120749, 26.93817902436622, 43.90680375591779, 34.6017039016317, 57.20938934023404, 47.76021020710361, 69.66859892046618, 47.648950490349065, 40.66242459524681, 47.9832928745843, 45.69126787969284, 52.936279947553466, 56.19520797706269, 1.3943956109530449, 1.3943759559492324, 1.394477457637238, 1.3940411876933463, 1.3942739081986844, 1.3943422991786631, 1.3948145255808733, 1.3933631035729372, 1.3941386008545598, 1.3940441537393498, 1.3931664935167118, 1.3941636255550298, 1.395234368223968, 1.3942794357688837, 1.3935117627295464, 1.3950172371072043, 1.399324879069221, 1.400709798976031, 1.3979996530442143, 1.3994401566682808, 1.4010198758548205, 1.4017199116493266, 1.4017979603407853, 1.400799245995421, 1.4017581223469446, 1.400652802419303, 1.3999063592282455, 1.3992961095507614, 1.4016217962403044, 2.0292382920114664, 2.006358524422063, 2.6577896148131197, 14.361851559751882, 42.472544642321246, 104.45865740854995, 56.19520797706269, 81.54304948304414, 42.66938633753722, 113.56083144899885, 58.68323485468682, 14.52670106178181, 27.429973399163586, 38.22134964917273, 47.9832928745843, 52.41456700024551, 62.03543279114569, 38.49534020391544, 46.55738829261837, 25.468698346677712, 50.15326867522425, 30.776351879281567, 46.87640294728948, 123.53313271096006, 55.22357674225935, 57.20938934023404, 47.42661123245574, 32.06419905971268, 73.7783185195315, 22.67026102024455, 43.64439636907469, 34.6017039016317, 42.46844533151644, 118.27138777646354, 69.66859892046618, 47.648950490349065, 51.924098277614725, 52.91752267120749, 46.88968266738928, 41.24134412218552, 51.08433933231186, 1.2833826645069544, 1.281815531597825, 1.2848231063526176, 1.286990488642064, 1.2876639685037088, 1.2879746269931562, 1.2841235079180657, 1.2844987257207285, 1.2839605590367302, 1.2851540779431865, 1.2876220190581968, 1.2889010590847088, 1.2902827692598602, 1.2806401136189418, 1.2887000771571386, 1.2895561443195578, 1.29130570446496, 1.2911202187116244, 1.287222398225579, 1.2861007071958865, 1.2876770485024134, 1.2901472062945536, 1.2848883016857058, 1.2906951913111326, 1.2944864728293486, 1.2957382192452829, 1.2896496603480578, 1.9272285520515227, 1.9613580704394906, 1.316940021197631, 4.595289224779322, 55.22357674225935, 123.53313271096006, 57.20938934023404, 62.03543279114569, 118.27138777646354, 45.81345398211283, 45.69126787969284, 50.15326867522425, 43.90680375591779, 40.5237439024217, 47.059457663289976, 16.77963050272743, 30.3155601624246, 113.56083144899885, 27.215999248700754, 30.54416596327944, 36.494419693705154, 41.24134412218552, 47.76021020710361, 29.99863638869988, 34.5398993140868, 46.55738829261837, 33.189627761898365, 69.66859892046618, 81.54304948304414, 33.80920079897104, 73.7783185195315, 23.604784017222496, 47.648950490349065, 58.68323485468682, 52.41456700024551, 104.45865740854995, 51.08433933231186, 56.19520797706269, 52.936279947553466, 43.64439636907469, 52.91752267120749, 51.924098277614725, 52.253146637746575, 1.2103358229269543, 1.1744106380748534, 1.1672286847833029, 1.1766058126487855, 1.1783214804389774, 1.168297978892383, 1.1670900315728945, 1.1672645174292602, 1.1753423482410212, 1.1689577906821966, 1.181310703497521, 1.177374367402331, 1.175432594868066, 1.1656208901080605, 1.1682894502594827, 1.174702667422864, 1.1709850457613302, 1.1752371648337623, 1.176713569837881, 1.1735895241901755, 1.1838564831109104, 1.1738051642106364, 1.1613775210931276, 1.1722679910790026, 1.1628108034903621, 1.1682573308563344, 1.1667754354128737, 1.1723496024768223, 1.170707026261293, 1.170395068297669, 1.843575221181316, 1.8413498097523533, 1.8512472674884677, 1.854188861294175, 1.83454118712593, 1.850391877919975, 1.8582261804249702, 62.03543279114569, 45.69126787969284, 104.45865740854995, 52.91752267120749, 43.010045014290384, 123.53313271096006, 47.648950490349065, 6.931759567556468, 69.66859892046618, 30.46392527501399, 118.27138777646354, 8.098022874100263, 113.56083144899885, 52.253146637746575, 46.88968266738928, 29.231674706752166, 20.74545769840843, 9.893673643798774, 25.351222676954606, 73.7783185195315, 47.42661123245574, 58.68323485468682, 56.19520797706269, 45.81345398211283, 32.40429348344451, 41.45389983268787, 57.20938934023404, 51.08433933231186, 35.48978648890426, 42.46844533151644, 81.54304948304414, 28.439960209783866, 51.924098277614725, 36.494419693705154, 47.9832928745843, 47.059457663289976, 52.936279947553466, 43.90680375591779, 50.15326867522425, 52.41456700024551, 46.87640294728948], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.6741, -9.7068, -9.7171, -9.7189, -9.7172, -9.719, -9.7192, -9.7216, -9.7212, -9.7243, -9.7228, -9.734, -9.7377, -9.7428, -9.7511, -9.7517, -9.7509, -9.753, -9.756, -9.7558, -9.76, -9.759, -9.7633, -9.7777, -9.788, -9.7889, -9.7936, -9.7926, -9.795, -9.7985, -6.2522, -6.4065, -6.4643, -7.7161, -6.4177, -6.853, -6.7434, -7.0794, -7.1751, -6.8566, -7.3019, -7.2757, -7.0983, -7.12, -7.1854, -7.366, -7.3641, -7.6659, -8.3686, -7.8878, -7.2622, -7.6224, -7.7289, -7.5456, -7.1987, -7.2963, -8.3167, -7.5065, -7.5127, -7.3116, -7.3716, -7.3517, -7.4023, -7.4333, -7.4604, -7.3447, -7.4201, -7.4625, -7.5029, -7.4985, -9.3732, -9.3716, -9.3792, -9.383, -9.3827, -9.3818, -9.3884, -9.3923, -9.3935, -9.3948, -9.3967, -9.3951, -9.3971, -9.3964, -9.4086, -9.4076, -9.4061, -9.4098, -9.4086, -9.4146, -9.4131, -9.41, -9.4141, -9.4144, -9.4181, -9.4177, -9.4212, -9.4258, -9.424, -9.4258, -6.5442, -7.2438, -6.9438, -7.1728, -6.8535, -7.3039, -7.1984, -7.2356, -7.9393, -7.4003, -7.3042, -7.3456, -7.4229, -6.9516, -7.6069, -7.3749, -7.543, -6.9575, -7.5228, -7.5833, -8.0891, -7.4539, -7.7166, -7.8849, -7.5139, -7.247, -7.8639, -7.973, -7.7476, -7.8032, -7.5643, -7.4128, -7.7225, -7.5896, -7.6458, -7.6193, -7.6769, -7.6562, -7.678, -9.6858, -9.7119, -9.7227, -9.7218, -9.7316, -9.7346, -9.7394, -9.737, -9.7548, -9.7478, -9.7464, -9.7656, -9.7727, -9.7782, -9.7843, -9.7868, -9.7865, -9.7987, -9.7934, -9.7897, -9.793, -9.8065, -9.7997, -9.804, -9.8049, -9.808, -9.8024, -9.8265, -9.8278, -9.8269, -8.8229, -6.6963, -9.269, -6.3506, -7.0854, -6.8705, -6.5615, -7.3126, -7.1231, -7.4102, -6.8372, -7.2989, -7.2522, -7.2008, -7.7828, -8.2877, -7.4577, -8.0074, -7.876, -7.8799, -7.3155, -6.7194, -7.5943, -7.5904, -7.2472, -7.8245, -7.8084, -7.3945, -7.3532, -7.612, -7.9709, -7.3133, -7.2857, -6.9453, -7.3647, -7.4728, -7.4573, -7.4857, -7.5022, -7.4596, -7.4824, -7.4638, -7.5718, -9.3674, -9.3677, -9.3679, -9.368, -9.368, -9.3681, -9.3681, -9.3682, -9.3683, -9.3684, -9.3684, -9.3684, -9.3684, -9.3685, -9.3686, -9.3686, -9.3688, -9.369, -9.3691, -9.3692, -9.3692, -9.3694, -9.3694, -9.3694, -9.3695, -9.3696, -9.3696, -9.3696, -9.3697, -9.3697, -9.0274, -9.0607, -8.8485, -9.0607, -9.062, -9.0623, -9.0647, -9.0666, -9.0672, -9.0706, -9.0768, -9.0781, -9.08, -9.0819, -9.0837, -6.3828, -9.0863, -9.0891, -9.0894, -9.0893, -9.0933, -9.0936, -7.285, -9.0957, -9.0966, -9.0961, -7.5533, -9.098, -6.6404, -9.0991, -6.5517, -7.2245, -6.65, -7.6216, -7.3403, -7.2085, -6.8915, -7.6685, -7.237, -7.2389, -7.4958, -7.3189, -7.2138, -7.5191, -7.3178, -7.3761, -7.2572, -7.4967, -7.1092, -7.6481, -7.2723, -7.3433, -7.4772, -7.3012, -7.4257, -7.3678, -7.2929, -7.2744, -7.2973, -7.3359, -7.2375, -7.3897, -7.3869, -7.3561, -7.3818, -9.3589, -9.36, -9.36, -9.3603, -9.3604, -9.3608, -9.3609, -9.3611, -9.3613, -9.3617, -9.3622, -9.5202, -9.5248, -9.5539, -9.5561, -9.5583, -9.5359, -9.5677, -9.5745, -9.5761, -9.5766, -9.5765, -9.5457, -9.5809, -9.5505, -9.5516, -9.5868, -9.5878, -9.5882, -9.5572, -9.5631, -9.5648, -6.4054, -7.1139, -6.4497, -6.8332, -6.6572, -7.0256, -7.1394, -7.2265, -7.2827, -7.2271, -7.9598, -7.1615, -6.9397, -7.2, -7.081, -7.3599, -8.1474, -7.7607, -7.6311, -7.2924, -7.3571, -7.5161, -6.8942, -7.4538, -7.4785, -7.7941, -7.5757, -7.3466, -7.4937, -7.691, -7.4099, -7.5363, -7.4298, -7.3671, -7.5065, -7.4286, -7.418, -7.4528, -7.4528, -7.4833, -7.4866, -9.2782, -9.2785, -9.2785, -9.2786, -9.2787, -9.2789, -9.2794, -9.2795, -9.2795, -9.28, -9.28, -9.28, -9.2801, -9.281, -9.2811, -9.2811, -9.2811, -9.2812, -9.2813, -9.2816, -9.2817, -9.2818, -9.282, -9.2824, -9.2845, -9.7733, -9.7775, -9.7793, -9.786, -9.7882, -9.0565, -9.1059, -9.1478, -8.338, -6.5012, -7.1809, -6.611, -6.6209, -7.0896, -6.9037, -6.7743, -7.1562, -7.1821, -7.0511, -7.5193, -7.4079, -7.3116, -7.5012, -7.6806, -7.2899, -7.3044, -7.4235, -7.3818, -7.4395, -7.3064, -7.5709, -7.4563, -7.3648, -7.2828, -7.5778, -7.2076, -7.5661, -7.5815, -7.7764, -7.5237, -7.4739, -7.4218, -7.5117, -7.5198, -7.5579, -9.385, -9.3851, -9.3854, -9.3857, -9.3858, -9.386, -9.3861, -9.3862, -9.3863, -9.3863, -9.3864, -9.3865, -9.3867, -9.3867, -9.3868, -9.3869, -9.3875, -9.3879, -9.3879, -9.3915, -9.5024, -9.5048, -9.517, -9.5159, -9.5226, -9.5268, -9.5265, -9.5293, -9.53, -9.5313, -6.1472, -9.2228, -9.2301, -6.366, -6.4492, -7.0913, -7.0903, -7.1492, -7.2109, -6.6301, -7.093, -7.5343, -6.8874, -6.9733, -7.2065, -7.6733, -7.1159, -7.5917, -7.7303, -7.6235, -7.3143, -7.5241, -7.5774, -7.2791, -7.7495, -7.2296, -7.5749, -7.8297, -7.5074, -7.3348, -7.325, -7.7106, -7.4653, -7.5878, -7.3526, -7.4464, -7.3235, -7.503, -7.5512, -7.5263, -7.5398, -7.5391, -7.5509, -9.4803, -9.4813, -9.4836, -9.4879, -9.4907, -9.4936, -9.4991, -9.5032, -9.5044, -9.5103, -9.5125, -9.5119, -9.514, -9.5152, -9.5259, -9.5281, -9.6111, -9.6216, -9.6411, -9.6526, -9.6676, -9.6834, -9.6851, -9.6866, -9.6875, -9.6896, -9.6903, -9.6914, -9.69, -9.3211, -9.3391, -9.1751, -7.9061, -7.0943, -6.4361, -6.9799, -6.7133, -7.188, -6.4814, -6.9877, -7.996, -7.5521, -7.3355, -7.1841, -7.1255, -7.0165, -7.3389, -7.2228, -7.622, -7.1926, -7.5074, -7.2686, -6.6626, -7.1741, -7.1575, -7.2838, -7.5407, -7.0337, -7.7692, -7.3849, -7.5268, -7.438, -6.8349, -7.1569, -7.3794, -7.3744, -7.387, -7.4691, -7.4955, -7.4722, -9.4734, -9.4967, -9.5027, -9.5137, -9.5176, -9.5179, -9.522, -9.5234, -9.5251, -9.5331, -9.5345, -9.5366, -9.5362, -9.5468, -9.5464, -9.5474, -9.5464, -9.5548, -9.565, -9.5678, -9.5692, -9.5712, -9.5805, -9.5776, -9.58, -9.6042, -9.6164, -9.3704, -9.3706, -9.8609, -8.825, -6.8604, -6.3469, -6.9845, -6.9819, -6.5548, -7.2094, -7.2438, -7.1867, -7.283, -7.342, -7.2547, -7.9237, -7.5605, -6.7408, -7.6297, -7.5667, -7.4566, -7.3831, -7.2948, -7.5892, -7.5165, -7.3344, -7.5472, -7.1044, -7.0112, -7.547, -7.1015, -7.7753, -7.3619, -7.2418, -7.3152, -6.9507, -7.3372, -7.3232, -7.3612, -7.4469, -7.3879, -7.4292, -7.454, -9.5502, -9.6911, -9.6995, -9.7105, -9.7108, -9.7314, -9.7395, -9.7405, -9.7406, -9.7581, -9.7535, -9.7571, -9.7621, -9.7742, -9.7735, -9.7765, -9.7798, -9.7768, -9.7784, -9.7831, -9.7823, -9.7918, -9.8065, -9.7986, -9.8119, -9.8081, -9.8094, -9.8061, -9.8081, -9.8084, -9.3915, -9.4087, -9.4106, -9.4132, -9.4582, -9.4524, -9.453, -6.8642, -7.0951, -6.525, -7.0263, -7.2278, -6.5031, -7.2402, -8.5606, -7.0006, -7.5579, -6.6515, -8.4645, -6.6962, -7.2166, -7.3082, -7.6246, -7.8635, -8.349, -7.7621, -7.0915, -7.3745, -7.2414, -7.2746, -7.4104, -7.6266, -7.4857, -7.3025, -7.3753, -7.6004, -7.4931, -7.1188, -7.7347, -7.3883, -7.5962, -7.4499, -7.4702, -7.4282, -7.5128, -7.4846, -7.4852, -7.5469], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3311, 1.3033, 1.2955, 1.2947, 1.294, 1.2939, 1.2936, 1.2934, 1.2911, 1.2904, 1.2898, 1.28, 1.2783, 1.2741, 1.268, 1.2669, 1.2664, 1.2657, 1.2638, 1.2628, 1.2608, 1.2597, 1.2563, 1.2433, 1.2368, 1.2337, 1.2315, 1.2298, 1.2291, 1.2264, 0.2669, 0.2368, 0.0954, 0.5263, 0.0578, 0.1953, 0.1476, 0.2436, 0.2694, 0.1344, 0.2849, 0.2629, 0.1649, 0.1253, 0.1505, 0.2242, 0.2034, 0.3253, 0.6536, 0.4067, 0.0801, 0.2531, 0.3049, 0.2026, 0.0212, 0.0623, 0.5735, 0.1362, 0.136, 0.0212, 0.0543, 0.0253, 0.0491, 0.0369, 0.0556, -0.1803, -0.0967, -0.0218, 0.0071, -0.0773, 1.8699, 1.8698, 1.8612, 1.8581, 1.8571, 1.8566, 1.8514, 1.8467, 1.8457, 1.8429, 1.8424, 1.8418, 1.8407, 1.8404, 1.8325, 1.8309, 1.8295, 1.8261, 1.8247, 1.8236, 1.8232, 1.8227, 1.8216, 1.8203, 1.8176, 1.8176, 1.815, 1.8108, 1.8098, 1.808, -0.0252, 0.4188, 0.0472, 0.1695, -0.2102, 0.1404, -0.0341, -0.0157, 0.5698, 0.1097, 0.0187, -0.0097, 0.0446, -0.3919, 0.1829, -0.042, 0.0996, -0.4819, 0.0204, 0.0582, 0.5517, -0.0953, 0.1563, 0.3275, -0.0732, -0.356, 0.2841, 0.3692, 0.1006, 0.1411, -0.1361, -0.3645, 0.038, -0.1567, -0.1298, -0.1935, -0.0851, -0.2117, -0.3011, 1.3479, 1.3247, 1.3197, 1.3171, 1.3065, 1.3063, 1.2993, 1.2986, 1.2913, 1.2907, 1.2855, 1.2768, 1.2686, 1.2578, 1.2577, 1.256, 1.254, 1.2508, 1.2506, 1.2494, 1.2443, 1.2421, 1.2408, 1.238, 1.2369, 1.2356, 1.2322, 1.2243, 1.2167, 1.2155, 0.9616, 0.352, 1.067, 0.1249, 0.2732, 0.1205, -0.0018, 0.2773, 0.1999, 0.3033, 0.0538, 0.2317, 0.1736, 0.1321, 0.3889, 0.6045, 0.2303, 0.4627, 0.4006, 0.3941, 0.1128, -0.2003, 0.227, 0.1939, 0.016, 0.3048, 0.2806, 0.0497, 0.0238, 0.168, 0.3581, -0.0327, -0.0658, -0.302, -0.0414, 0.0372, -0.0245, -0.0644, -0.0508, -0.1173, -0.1464, -0.2184, -0.0043, 1.7321, 1.732, 1.7319, 1.7319, 1.7318, 1.7318, 1.7318, 1.7318, 1.7317, 1.7317, 1.7317, 1.7316, 1.7316, 1.7316, 1.7316, 1.7316, 1.7315, 1.7314, 1.7313, 1.7313, 1.7313, 1.7312, 1.7312, 1.7312, 1.7311, 1.7311, 1.7311, 1.7311, 1.7311, 1.731, 1.6486, 1.6247, 1.5443, 1.6119, 1.6082, 1.6075, 1.6044, 1.603, 1.6027, 1.5991, 1.5895, 1.589, 1.5885, 1.5851, 1.5855, 0.1363, 1.5805, 1.5812, 1.5782, 1.5775, 1.5773, 1.5732, 0.5011, 1.5712, 1.5707, 1.5701, 0.6232, 1.5682, 0.0029, 1.5673, -0.0762, 0.3481, -0.0903, 0.55, 0.3476, 0.2429, -0.0005, 0.5546, 0.2305, 0.1823, 0.3619, 0.2117, 0.1191, 0.3463, 0.1524, 0.1914, 0.0851, 0.2833, -0.0609, 0.3846, 0.0511, 0.101, 0.2177, 0.0574, 0.1611, 0.0581, -0.0296, -0.0545, -0.052, -0.013, -0.2465, 0.051, 0.0413, -0.0754, -0.0048, 1.6166, 1.6162, 1.6162, 1.6161, 1.616, 1.6159, 1.6158, 1.6157, 1.6157, 1.6155, 1.6153, 1.4542, 1.4496, 1.448, 1.4456, 1.4437, 1.4385, 1.4355, 1.4295, 1.4285, 1.4282, 1.4279, 1.4274, 1.4245, 1.423, 1.4228, 1.4197, 1.4181, 1.4174, 1.4166, 1.4104, 1.4097, 0.1137, 0.3304, 0.0259, 0.1578, -0.0139, 0.1387, 0.1965, 0.2409, 0.2606, 0.1941, 0.5596, 0.0838, -0.0487, 0.0632, -0.0327, 0.1102, 0.5892, 0.3483, 0.2598, 0.0309, 0.0688, 0.1788, -0.3345, 0.1137, 0.1083, 0.3624, 0.1725, -0.0236, 0.0965, 0.2533, 0.023, 0.1263, 0.0216, -0.0864, 0.0661, -0.0516, -0.0851, -0.0942, -0.1105, -0.0551, -0.2667, 1.9197, 1.9196, 1.9196, 1.9195, 1.9194, 1.9194, 1.9191, 1.919, 1.919, 1.9188, 1.9187, 1.9187, 1.9187, 1.9182, 1.9182, 1.9182, 1.9181, 1.9181, 1.918, 1.9179, 1.9178, 1.9178, 1.9177, 1.9174, 1.9163, 1.375, 1.3706, 1.3664, 1.3603, 1.3575, 1.3419, 1.3351, 1.2992, 0.7973, -0.0257, 0.252, -0.0513, -0.1019, 0.1303, -0.0128, -0.131, 0.1244, 0.1412, -0.0028, 0.3975, 0.1596, 0.0654, 0.2373, 0.4096, 0.0331, 0.0379, 0.1151, 0.0464, 0.1037, -0.0611, 0.1994, 0.0744, -0.032, -0.1185, 0.1826, -0.2166, 0.104, 0.1064, 0.3127, 0.0196, -0.048, -0.1586, -0.0017, -0.1838, -0.1367, 1.5448, 1.5448, 1.5447, 1.5446, 1.5445, 1.5444, 1.5444, 1.5444, 1.5443, 1.5443, 1.5443, 1.5442, 1.5442, 1.5442, 1.5441, 1.5441, 1.5439, 1.5437, 1.5437, 1.5423, 1.4581, 1.4559, 1.4487, 1.4484, 1.4414, 1.4412, 1.4406, 1.439, 1.4381, 1.4378, 0.4125, 1.3405, 1.3244, 0.1095, 0.0698, 0.3533, 0.3503, 0.3667, 0.3808, 0.0132, 0.1877, 0.3965, 0.0036, 0.0177, 0.1295, 0.4356, 0.0484, 0.3512, 0.4222, 0.3463, 0.1186, 0.2559, 0.2803, 0.0632, 0.3961, -0.0097, 0.2388, 0.4127, 0.1628, 0.0238, -0.0016, 0.2879, 0.0447, 0.1604, -0.1073, -0.0205, -0.2752, -0.0748, 0.0356, -0.105, -0.0697, -0.2161, -0.2876, 1.4793, 1.4783, 1.4759, 1.4719, 1.469, 1.4661, 1.4602, 1.4571, 1.4554, 1.4495, 1.448, 1.4479, 1.445, 1.4445, 1.4343, 1.4311, 1.345, 1.3334, 1.316, 1.3034, 1.2873, 1.2709, 1.2692, 1.2684, 1.2668, 1.2656, 1.2654, 1.2647, 1.2644, 1.2633, 1.2567, 1.1395, 0.7214, 0.4489, 0.2072, 0.2834, 0.1776, 0.3506, 0.0783, 0.2322, 0.6201, 0.4283, 0.3132, 0.2372, 0.2074, 0.1478, 0.3026, 0.2286, 0.4326, 0.1844, 0.3579, 0.1759, -0.187, 0.1066, 0.0879, 0.1491, 0.2836, -0.0427, 0.4018, 0.1311, 0.2213, 0.1053, -0.3158, -0.1086, 0.0488, -0.0321, -0.0636, -0.0248, 0.0771, -0.1136, 1.5692, 1.5471, 1.5388, 1.526, 1.5216, 1.5211, 1.52, 1.5183, 1.517, 1.5081, 1.5048, 1.5017, 1.501, 1.4979, 1.4921, 1.4904, 1.4901, 1.4818, 1.4746, 1.4727, 1.47, 1.4661, 1.4609, 1.4593, 1.454, 1.4288, 1.4213, 1.2655, 1.2478, 1.1558, 0.942, 0.4203, 0.1287, 0.2608, 0.1824, -0.0357, 0.2581, 0.2263, 0.1903, 0.227, 0.2482, 0.1859, 0.5482, 0.3199, -0.1811, 0.3586, 0.3062, 0.2383, 0.1895, 0.131, 0.3017, 0.2335, 0.117, 0.2427, -0.0561, -0.1203, 0.2243, -0.1105, 0.3553, 0.0663, -0.0219, 0.0176, -0.3074, 0.0214, -0.06, -0.0382, 0.0691, -0.0646, -0.087, -0.118, 1.5509, 1.4402, 1.438, 1.4189, 1.4171, 1.4051, 1.398, 1.3969, 1.3899, 1.3779, 1.372, 1.3717, 1.3683, 1.3646, 1.3631, 1.3546, 1.3544, 1.3538, 1.3509, 1.3489, 1.341, 1.34, 1.3359, 1.3345, 1.3294, 1.3284, 1.3284, 1.327, 1.3264, 1.3264, 1.2888, 1.2729, 1.2656, 1.2615, 1.2271, 1.2243, 1.2195, 0.3001, 0.3751, 0.1183, 0.2971, 0.3028, -0.0275, 0.188, 0.7954, 0.0477, 0.3176, -0.1324, 0.7359, -0.1365, 0.1194, 0.1361, 0.2922, 0.3962, 0.6512, 0.2972, -0.1005, 0.0584, -0.0215, -0.0113, 0.0571, 0.1872, 0.0818, -0.0571, -0.0167, 0.1224, 0.0502, -0.2278, 0.2096, -0.046, 0.0987, -0.0287, -0.0296, -0.1053, -0.0029, -0.1076, -0.1523, -0.1024]}, \"token.table\": {\"Topic\": [8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 4, 7, 4, 7, 4, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 7, 6, 1, 3, 4, 5, 7, 8, 9, 10, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 4, 7, 5, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 9, 7, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 7, 4, 7, 4, 8, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 4, 8, 4, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 8, 3, 7, 6, 4, 1, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 4, 7, 7, 4, 5, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 5, 6, 7, 6, 6, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 9, 9, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 6, 4, 8, 9, 9, 5, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 8, 6, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 4, 9, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 3, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 8, 9, 10, 7, 4, 4, 6, 1, 1, 9, 8, 8, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 6, 1, 5, 6, 4, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 9, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 9, 7, 4, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 5, 5, 8, 1, 3, 4, 5, 6, 7, 8, 9, 10, 8, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 1, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"Freq\": [0.7139237554638624, 0.1706615588443435, 0.042665389711085876, 0.08533077942217175, 0.08533077942217175, 0.10666347427771468, 0.06399808456662881, 0.19199425369988643, 0.14932886398880055, 0.06399808456662881, 0.06399808456662881, 0.14427748723968103, 0.03606937180992026, 0.10820811542976078, 0.10820811542976078, 0.10820811542976078, 0.07213874361984052, 0.1803468590496013, 0.14427748723968103, 0.07213874361984052, 0.07213874361984052, 0.7587799670689801, 0.8258194774185936, 0.8258398675729232, 0.4782468072699673, 0.8253053257619294, 0.6962812585979599, 0.825110519389686, 0.7173373937386592, 0.38438302395689816, 0.1298858504305786, 0.05195434017223144, 0.07793151025834716, 0.10390868034446288, 0.10390868034446288, 0.05195434017223144, 0.10390868034446288, 0.18184019060281004, 0.10390868034446288, 0.07793151025834716, 0.9113472683127949, 0.08777486308559135, 0.05851657539039423, 0.11703315078078846, 0.08777486308559135, 0.11703315078078846, 0.08777486308559135, 0.11703315078078846, 0.14629143847598558, 0.11703315078078846, 0.08777486308559135, 0.06883875394330875, 0.1376775078866175, 0.06883875394330875, 0.1376775078866175, 0.06883875394330875, 0.1376775078866175, 0.20651626182992625, 0.06883875394330875, 0.06883875394330875, 0.6968451732140432, 0.9106756812102301, 0.18145894418846292, 0.18145894418846292, 0.09072947209423146, 0.09072947209423146, 0.18145894418846292, 0.09072947209423146, 0.09072947209423146, 0.09072947209423146, 0.7279195223917275, 0.7764128105027597, 0.1445015544383124, 0.05780062177532496, 0.08670093266298744, 0.11560124355064992, 0.1445015544383124, 0.05780062177532496, 0.1445015544383124, 0.1445015544383124, 0.05780062177532496, 0.05780062177532496, 0.08600425704167079, 0.043002128520835396, 0.08600425704167079, 0.08600425704167079, 0.12900638556250618, 0.043002128520835396, 0.215010642604177, 0.12900638556250618, 0.12900638556250618, 0.08600425704167079, 0.16580950348096632, 0.04145237587024158, 0.08290475174048316, 0.08290475174048316, 0.12435712761072475, 0.08290475174048316, 0.2072618793512079, 0.08290475174048316, 0.08290475174048316, 0.08290475174048316, 0.7293366636571227, 0.7172759220438637, 0.7295245579874531, 0.7725071068640124, 0.1033230365286783, 0.05166151826433915, 0.15498455479301745, 0.1033230365286783, 0.1033230365286783, 0.05166151826433915, 0.15498455479301745, 0.15498455479301745, 0.1033230365286783, 0.05166151826433915, 0.7754043836448686, 0.825482269127107, 0.6964473468138516, 0.7292753713315093, 0.7269226956295941, 0.13983718568332604, 0.03495929642083151, 0.08739824105207876, 0.08739824105207876, 0.12235753747291027, 0.06991859284166302, 0.12235753747291027, 0.13983718568332604, 0.12235753747291027, 0.06991859284166302, 0.5351235923350037, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.12348693200142458, 0.14310592544997286, 0.05724237017998914, 0.11448474035997828, 0.08586355526998371, 0.11448474035997828, 0.08586355526998371, 0.11448474035997828, 0.11448474035997828, 0.11448474035997828, 0.05724237017998914, 0.7744099608189529, 0.779190827222352, 0.6968528239113218, 0.6967778395402076, 0.4984154067319811, 0.14236089317910125, 0.03559022329477531, 0.10677066988432594, 0.08897555823693828, 0.1245657815317136, 0.05338533494216297, 0.08897555823693828, 0.16015600482648892, 0.08897555823693828, 0.07118044658955062, 0.5404260643016331, 0.7234775081974241, 0.8253775593137243, 0.6964395573514279, 0.4068330018680369, 0.714645022718634, 0.7274191984093459, 0.09821842913002227, 0.06547895275334818, 0.09821842913002227, 0.06547895275334818, 0.13095790550669636, 0.06547895275334818, 0.13095790550669636, 0.09821842913002227, 0.13095790550669636, 0.06547895275334818, 0.9113734813277093, 0.729859335985663, 0.11166901870461605, 0.05583450935230803, 0.13958627338077007, 0.08375176402846204, 0.11166901870461605, 0.08375176402846204, 0.13958627338077007, 0.13958627338077007, 0.11166901870461605, 0.05583450935230803, 0.7790644465796076, 0.5451471085464658, 0.12996992027156973, 0.06498496013578486, 0.09747744020367728, 0.12996992027156973, 0.09747744020367728, 0.06498496013578486, 0.09747744020367728, 0.19495488040735456, 0.09747744020367728, 0.06498496013578486, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.10107469035293953, 0.20214938070587907, 0.5349375406702793, 0.5367389084412513, 0.6966864683811891, 0.6969461611587934, 0.13792109188280563, 0.09194739458853708, 0.13792109188280563, 0.09194739458853708, 0.09194739458853708, 0.04597369729426854, 0.13792109188280563, 0.18389478917707416, 0.04597369729426854, 0.09194739458853708, 0.7785138124126226, 0.8252822151604866, 0.7145714629061034, 0.8256577120982201, 0.7607952287071366, 0.1500995069045882, 0.06003980276183528, 0.12007960552367056, 0.1500995069045882, 0.09005970414275292, 0.06003980276183528, 0.12007960552367056, 0.12007960552367056, 0.09005970414275292, 0.06003980276183528, 0.3762525048734206, 0.13081693990123713, 0.052326775960494856, 0.10465355192098971, 0.07849016394074228, 0.10465355192098971, 0.07849016394074228, 0.13081693990123713, 0.18314371586173198, 0.07849016394074228, 0.07849016394074228, 0.9113402238221111, 0.911411787807496, 0.10936940974545306, 0.036456469915151016, 0.10936940974545306, 0.07291293983030203, 0.14582587966060406, 0.07291293983030203, 0.10936940974545306, 0.1822823495757551, 0.07291293983030203, 0.07291293983030203, 0.7757396906321624, 0.535171530510867, 0.7271569205610536, 0.7272160607507351, 0.7572051667827164, 0.08128200470077909, 0.040641002350389546, 0.12192300705116864, 0.08128200470077909, 0.08128200470077909, 0.08128200470077909, 0.12192300705116864, 0.16256400940155818, 0.08128200470077909, 0.08128200470077909, 0.7139528070573463, 0.7133695641538058, 0.775954783425029, 0.48250662654645293, 0.9115984509840196, 0.5347641350043197, 0.7637469007075139, 0.7215157148701257, 0.825291847472557, 0.13747469318309663, 0.04582489772769888, 0.06873734659154832, 0.09164979545539775, 0.09164979545539775, 0.06873734659154832, 0.1832995909107955, 0.13747469318309663, 0.11456224431924719, 0.06873734659154832, 0.7480341714551073, 0.8258074124956811, 0.1183109894783948, 0.0295777473695987, 0.0887332421087961, 0.0591554947391974, 0.1183109894783948, 0.0591554947391974, 0.1183109894783948, 0.1478887368479935, 0.1183109894783948, 0.0887332421087961, 0.12474972453080334, 0.06237486226540167, 0.12474972453080334, 0.0935622933981025, 0.12474972453080334, 0.06237486226540167, 0.0935622933981025, 0.15593715566350416, 0.0935622933981025, 0.0935622933981025, 0.11833748763238681, 0.039445829210795605, 0.07889165842159121, 0.11833748763238681, 0.11833748763238681, 0.07889165842159121, 0.11833748763238681, 0.11833748763238681, 0.07889165842159121, 0.11833748763238681, 0.7616972703322147, 0.7232415585307449, 0.7611663991759984, 0.13605205317651425, 0.054420821270605706, 0.13605205317651425, 0.13605205317651425, 0.10884164254121141, 0.08163123190590856, 0.10884164254121141, 0.10884164254121141, 0.08163123190590856, 0.054420821270605706, 0.9103504917106424, 0.5354069829247082, 0.717798821732011, 0.6973541071437102, 0.8255690100711172, 0.7501688552984513, 0.7578277849317171, 0.7580150978246222, 0.1470754807949802, 0.0490251602649934, 0.1470754807949802, 0.0490251602649934, 0.1470754807949802, 0.0980503205299868, 0.0980503205299868, 0.0980503205299868, 0.0980503205299868, 0.0980503205299868, 0.7564068526361295, 0.7594350690965944, 0.7511843525007217, 0.4091567389543474, 0.4091567389543474, 0.42952741332580213, 0.9115526221087936, 0.7766254267160081, 0.7765922372873029, 0.17214910497044628, 0.04918545856298465, 0.07377818784447698, 0.0983709171259693, 0.12296364640746163, 0.04918545856298465, 0.12296364640746163, 0.12296364640746163, 0.0983709171259693, 0.07377818784447698, 0.7551594848258276, 0.7801434569555162, 0.8250058672598353, 0.10493410554788006, 0.04197364221915202, 0.12592092665745608, 0.10493410554788006, 0.10493410554788006, 0.06296046332872804, 0.12592092665745608, 0.12592092665745608, 0.10493410554788006, 0.10493410554788006, 0.7499840824389471, 0.1113661022627561, 0.07424406817517074, 0.1113661022627561, 0.1113661022627561, 0.1113661022627561, 0.07424406817517074, 0.18561017043792685, 0.1113661022627561, 0.07424406817517074, 0.07424406817517074, 0.776301468919558, 0.7515856273069635, 0.12898575484530952, 0.06449287742265476, 0.09673931613398215, 0.12898575484530952, 0.09673931613398215, 0.03224643871132738, 0.1612321935566369, 0.12898575484530952, 0.09673931613398215, 0.06449287742265476, 0.12206192090000322, 0.04068730696666774, 0.12206192090000322, 0.08137461393333548, 0.12206192090000322, 0.12206192090000322, 0.12206192090000322, 0.16274922786667095, 0.08137461393333548, 0.08137461393333548, 0.7745585799513904, 0.9116288749853405, 0.9109102247226107, 0.12498768829297549, 0.062493844146487745, 0.062493844146487745, 0.062493844146487745, 0.18748153243946322, 0.062493844146487745, 0.12498768829297549, 0.12498768829297549, 0.062493844146487745, 0.062493844146487745, 0.5360617903593221, 0.6973559948368178, 0.7766001258558317, 0.7754606144175724, 0.8253635291913096, 0.5188798178272661, 0.08695422081479488, 0.04347711040739744, 0.08695422081479488, 0.13043133122219233, 0.17390844162958977, 0.04347711040739744, 0.13043133122219233, 0.13043133122219233, 0.08695422081479488, 0.08695422081479488, 0.7171666979292125, 0.07055659087178826, 0.07055659087178826, 0.07055659087178826, 0.07055659087178826, 0.1411131817435765, 0.07055659087178826, 0.07055659087178826, 0.07055659087178826, 0.1411131817435765, 0.07055659087178826, 0.7278849167829843, 0.12990314678950063, 0.043301048929833545, 0.08660209785966709, 0.08660209785966709, 0.12990314678950063, 0.043301048929833545, 0.21650524464916773, 0.12990314678950063, 0.08660209785966709, 0.043301048929833545, 0.15112508865235688, 0.056671908244633834, 0.1322344525708123, 0.09445318040772306, 0.11334381648926767, 0.07556254432617844, 0.11334381648926767, 0.11334381648926767, 0.09445318040772306, 0.07556254432617844, 0.13665308076977284, 0.06832654038488642, 0.11387756730814404, 0.06832654038488642, 0.09110205384651524, 0.06832654038488642, 0.13665308076977284, 0.11387756730814404, 0.11387756730814404, 0.09110205384651524, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.11569350487115472, 0.10542604394594231, 0.042170417578376924, 0.10542604394594231, 0.06325562636756539, 0.12651125273513078, 0.08434083515675385, 0.14759646152431924, 0.14759646152431924, 0.08434083515675385, 0.08434083515675385, 0.7291451684016639, 0.5369384985085053, 0.9107042113745509, 0.8251697571593419, 0.7169412001811123, 0.775023912451087, 0.7758547430398832, 0.7296351122120472, 0.7607721964348939, 0.7176880150161474, 0.11779164993688568, 0.039263883312295224, 0.11779164993688568, 0.07852776662459045, 0.07852776662459045, 0.07852776662459045, 0.1570555332491809, 0.1963194165614761, 0.07852776662459045, 0.07852776662459045, 0.13683786646257554, 0.034209466615643884, 0.10262839984693166, 0.10262839984693166, 0.13683786646257554, 0.10262839984693166, 0.10262839984693166, 0.10262839984693166, 0.06841893323128777, 0.10262839984693166, 0.9101220201580887, 0.7781168166236077, 0.11817946446556098, 0.029544866116390244, 0.08863459834917073, 0.08863459834917073, 0.11817946446556098, 0.08863459834917073, 0.11817946446556098, 0.11817946446556098, 0.08863459834917073, 0.08863459834917073, 0.20665594161725415, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.10332797080862707, 0.7506218754711951, 0.7562068300767743, 0.5393193869701204, 0.1277605726951264, 0.0638802863475632, 0.1277605726951264, 0.0958204295213448, 0.0958204295213448, 0.0638802863475632, 0.0958204295213448, 0.1277605726951264, 0.0958204295213448, 0.0958204295213448, 0.7737790869097688, 0.7225800333919887, 0.7205531117064885, 0.08988514460655679, 0.05992342973770453, 0.11984685947540906, 0.11984685947540906, 0.1498085743442613, 0.05992342973770453, 0.1498085743442613, 0.11984685947540906, 0.05992342973770453, 0.05992342973770453, 0.11919213594571776, 0.05959606797285888, 0.05959606797285888, 0.05959606797285888, 0.05959606797285888, 0.05959606797285888, 0.11919213594571776, 0.11919213594571776, 0.17878820391857664, 0.05959606797285888, 0.7143334933854363, 0.12931554962507918, 0.08621036641671946, 0.08621036641671946, 0.12931554962507918, 0.08621036641671946, 0.04310518320835973, 0.17242073283343892, 0.12931554962507918, 0.08621036641671946, 0.08621036641671946, 0.8256428293531154, 0.7176114524080129, 0.08871280032474373, 0.04435640016237186, 0.08871280032474373, 0.17742560064948745, 0.13306920048711557, 0.04435640016237186, 0.13306920048711557, 0.13306920048711557, 0.08871280032474373, 0.08871280032474373, 0.7286714859700515, 0.7171840089689954, 0.716837020647618, 0.9127649979895753, 0.7146303299239294, 0.6967327236517041, 0.10692292137914228, 0.05346146068957114, 0.10692292137914228, 0.08019219103435671, 0.13365365172392785, 0.08019219103435671, 0.16038438206871342, 0.13365365172392785, 0.08019219103435671, 0.08019219103435671, 0.11270848308007106, 0.028177120770017765, 0.11270848308007106, 0.11270848308007106, 0.11270848308007106, 0.05635424154003553, 0.14088560385008883, 0.11270848308007106, 0.08453136231005329, 0.08453136231005329, 0.7624684632430863, 0.15382255355339827, 0.03845563838834957, 0.1153669151650487, 0.07691127677669914, 0.1153669151650487, 0.03845563838834957, 0.15382255355339827, 0.1153669151650487, 0.07691127677669914, 0.07691127677669914, 0.9108886863204173, 0.14668686862827332, 0.04889562287609111, 0.14668686862827332, 0.09779124575218222, 0.09779124575218222, 0.04889562287609111, 0.14668686862827332, 0.09779124575218222, 0.04889562287609111, 0.09779124575218222, 0.07682055972024335, 0.038410279860121674, 0.11523083958036502, 0.1536411194404867, 0.1536411194404867, 0.07682055972024335, 0.11523083958036502, 0.11523083958036502, 0.07682055972024335, 0.07682055972024335, 0.12562758777614405, 0.041875862592048015, 0.12562758777614405, 0.10468965648012005, 0.12562758777614405, 0.06281379388807203, 0.12562758777614405, 0.10468965648012005, 0.10468965648012005, 0.06281379388807203, 0.14213233346428528, 0.04737744448809509, 0.04737744448809509, 0.04737744448809509, 0.09475488897619018, 0.04737744448809509, 0.18950977795238036, 0.14213233346428528, 0.09475488897619018, 0.04737744448809509, 0.7607450757609567, 0.7607133785916572, 0.7783172602171055, 0.7636409834197185, 0.11934013360801352, 0.02983503340200338, 0.11934013360801352, 0.11934013360801352, 0.11934013360801352, 0.05967006680400676, 0.1790102004120203, 0.08950510020601014, 0.08950510020601014, 0.08950510020601014, 0.5430798616882535, 0.5381476219279739, 0.12692532189056194, 0.042308440630187315, 0.12692532189056194, 0.08461688126037463, 0.12692532189056194, 0.042308440630187315, 0.12692532189056194, 0.12692532189056194, 0.08461688126037463, 0.08461688126037463, 0.10913824576405382, 0.06548294745843229, 0.06548294745843229, 0.10913824576405382, 0.15279354406967532, 0.04365529830562152, 0.10913824576405382, 0.10913824576405382, 0.13096589491686458, 0.08731059661124305, 0.09054103871859127, 0.03621641548743651, 0.10864924646230953, 0.09054103871859127, 0.10864924646230953, 0.07243283097487302, 0.16297386969346428, 0.14486566194974604, 0.14486566194974604, 0.054324623231154764, 0.7153077597855264, 0.5424243006256211, 0.12504352328804155, 0.041681174429347184, 0.10420293607336796, 0.10420293607336796, 0.14588411050271513, 0.06252176164402078, 0.12504352328804155, 0.16672469771738874, 0.08336234885869437, 0.08336234885869437, 0.0847285871601605, 0.0847285871601605, 0.12709288074024078, 0.12709288074024078, 0.0847285871601605, 0.0847285871601605, 0.0847285871601605, 0.12709288074024078, 0.12709288074024078, 0.04236429358008025, 0.11772310894266061, 0.04708924357706424, 0.09417848715412848, 0.07063386536559636, 0.11772310894266061, 0.07063386536559636, 0.11772310894266061, 0.18835697430825696, 0.09417848715412848, 0.07063386536559636, 0.7172191877935506, 0.7240505535750669, 0.5450954205975841, 0.16583097728521037, 0.04145774432130259, 0.12437323296390777, 0.08291548864260519, 0.16583097728521037, 0.04145774432130259, 0.12437323296390777, 0.12437323296390777, 0.08291548864260519, 0.08291548864260519, 0.16412855385057412, 0.03282571077011483, 0.09847713231034447, 0.09847713231034447, 0.1313028430804593, 0.06565142154022965, 0.09847713231034447, 0.09847713231034447, 0.09847713231034447, 0.09847713231034447, 0.07765683863804586, 0.07765683863804586, 0.07765683863804586, 0.07765683863804586, 0.23297051591413756, 0.07765683863804586, 0.15531367727609172, 0.07765683863804586, 0.07765683863804586, 0.07765683863804586, 0.7569753807544554, 0.9113284286396885, 0.5367831785545049, 0.7788401232123775, 0.7171565889514796, 0.7625525196249927, 0.13875833811928198, 0.06937916905964099, 0.10406875358946148, 0.06937916905964099, 0.10406875358946148, 0.06937916905964099, 0.20813750717892296, 0.13875833811928198, 0.10406875358946148, 0.034689584529820496, 0.7657102743227878, 0.9114511462358488, 0.5400450618915983, 0.14089364964878526, 0.035223412412196314, 0.10567023723658894, 0.08805853103049079, 0.07925267792744171, 0.06164097172134355, 0.19372876826707974, 0.13208779654573619, 0.07925267792744171, 0.07044682482439263, 0.11963327931533213, 0.03987775977177738, 0.11963327931533213, 0.09969439942944344, 0.11963327931533213, 0.07975551954355475, 0.09969439942944344, 0.1595110390871095, 0.11963327931533213, 0.07975551954355475, 0.15310082769677583, 0.05741281038629094, 0.0956880173104849, 0.07655041384838791, 0.13396322423467885, 0.05741281038629094, 0.15310082769677583, 0.0956880173104849, 0.0956880173104849, 0.0956880173104849, 0.7296926165564938, 0.13003191347805806, 0.05201276539122322, 0.10402553078244645, 0.07801914808683483, 0.10402553078244645, 0.05201276539122322, 0.13003191347805806, 0.13003191347805806, 0.07801914808683483, 0.07801914808683483, 0.18950133884628426, 0.047375334711571064, 0.047375334711571064, 0.09475066942314213, 0.14212600413471319, 0.047375334711571064, 0.14212600413471319, 0.14212600413471319, 0.09475066942314213, 0.047375334711571064, 0.7654961814579233, 0.7179669095866331, 0.7503305535006921, 0.8257301906704884, 0.09294118598684303, 0.04647059299342152, 0.09294118598684303, 0.13941177898026455, 0.09294118598684303, 0.04647059299342152, 0.13941177898026455, 0.13941177898026455, 0.13941177898026455, 0.04647059299342152, 0.7481489326495279, 0.7133898381310704, 0.12749828191667548, 0.042499427305558495, 0.08499885461111699, 0.10624856826389624, 0.10624856826389624, 0.06374914095833774, 0.19124742287501323, 0.10624856826389624, 0.12749828191667548, 0.08499885461111699, 0.8250924715002155, 0.7597554984704794, 0.1554621560609909, 0.03109243121219818, 0.12436972484879272, 0.09327729363659454, 0.12436972484879272, 0.06218486242439636, 0.1554621560609909, 0.09327729363659454, 0.09327729363659454, 0.06218486242439636, 0.7509056666445774, 0.15317064565957553, 0.04786582676861736, 0.07658532282978776, 0.09573165353723471, 0.11487798424468165, 0.057438992122340826, 0.1340243149521286, 0.15317064565957553, 0.07658532282978776, 0.09573165353723471, 0.6965646158899645, 0.2176141589973638, 0.2176141589973638, 0.2176141589973638, 0.2176141589973638, 0.06185075695062846, 0.12370151390125692, 0.06185075695062846, 0.06185075695062846, 0.12370151390125692, 0.06185075695062846, 0.18555227085188536, 0.12370151390125692, 0.12370151390125692, 0.06185075695062846, 0.7173389199889083, 0.13481216298787047, 0.05777664128051591, 0.09629440213419319, 0.09629440213419319, 0.09629440213419319, 0.07703552170735455, 0.13481216298787047, 0.11555328256103183, 0.09629440213419319, 0.07703552170735455, 0.49279574702326256, 0.6961623512053108, 0.09640664617167921, 0.048203323085839606, 0.09640664617167921, 0.09640664617167921, 0.09640664617167921, 0.048203323085839606, 0.09640664617167921, 0.14460996925751882, 0.09640664617167921, 0.09640664617167921, 0.7723250500002612, 0.6966417706407548, 0.1192844944102623, 0.0511219261758267, 0.1022438523516534, 0.08520321029304449, 0.08520321029304449, 0.08520321029304449, 0.1363251364688712, 0.1533657785274801, 0.1022438523516534, 0.08520321029304449, 0.7559834967926656, 0.8258339264527862, 0.1324201630919217, 0.0441400543639739, 0.1765602174558956, 0.0882801087279478, 0.1324201630919217, 0.0441400543639739, 0.0882801087279478, 0.1324201630919217, 0.0882801087279478, 0.0882801087279478, 0.6969103758449523, 0.7745212146068584, 0.13233195671284945, 0.04411065223761648, 0.13233195671284945, 0.08822130447523296, 0.13233195671284945, 0.04411065223761648, 0.08822130447523296, 0.17644260895046593, 0.04411065223761648, 0.08822130447523296, 0.14426351494942466, 0.14426351494942466, 0.14426351494942466, 0.14426351494942466, 0.14426351494942466, 0.14426351494942466, 0.14426351494942466, 0.6971990181053981, 0.8253188777467193, 0.825842581446366, 0.9102446745312162, 0.7543104642211711, 0.7649043096621434, 0.7770065193373147, 0.7167254640329189, 0.7177892984461188, 0.7491396548128925, 0.536653637706964, 0.164931803114012, 0.0329863606228024, 0.1319454424912096, 0.0659727212456048, 0.09895908186840721, 0.0659727212456048, 0.09895908186840721, 0.1319454424912096, 0.1319454424912096, 0.0659727212456048, 0.8251295565587407, 0.5351212926990943, 0.42696884927381545, 0.18110138484051563, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.09055069242025782, 0.7747762653273431, 0.9102888682730269, 0.7562022322487688, 0.7497267763281886, 0.9117337353250797, 0.5348618158465422, 0.5366555858804045, 0.11022927993882918, 0.03674309331294306, 0.11022927993882918, 0.11022927993882918, 0.11022927993882918, 0.03674309331294306, 0.14697237325177223, 0.14697237325177223, 0.14697237325177223, 0.07348618662588612, 0.8251935205585228, 0.7482384214068204, 0.7787412922774759, 0.12951990813214806, 0.032379977033037015, 0.12142491387388879, 0.08904493684085178, 0.12142491387388879, 0.06475995406607403, 0.14570989664866654, 0.1052349253573703, 0.11332991961562955, 0.08094994258259253, 0.7808595009366955, 0.6961246177591142, 0.5352804386413395, 0.16064747659772596, 0.05073078208349241, 0.08455130347248735, 0.10146156416698482, 0.12682695520873102, 0.059185912430741144, 0.1437372159032285, 0.09300643381973608, 0.09300643381973608, 0.06764104277798988, 0.7761455238017695, 0.14806134434290114, 0.049353781447633714, 0.09870756289526743, 0.07403067217145057, 0.12338445361908429, 0.07403067217145057, 0.07403067217145057, 0.12338445361908429, 0.12338445361908429, 0.07403067217145057, 0.08827170710886259, 0.044135853554431295, 0.08827170710886259, 0.17654341421772518, 0.1324075606632939, 0.08827170710886259, 0.1324075606632939, 0.1324075606632939, 0.08827170710886259, 0.044135853554431295, 0.8257586429959513, 0.13702829656783602, 0.05872641281478686, 0.13702829656783602, 0.09787735469131144, 0.09787735469131144, 0.03915094187652458, 0.13702829656783602, 0.11745282562957372, 0.09787735469131144, 0.07830188375304915, 0.8252504630852311, 0.7172163444041216, 0.19963699465615534, 0.049909248664038834, 0.09981849732807767, 0.049909248664038834, 0.09981849732807767, 0.09981849732807767, 0.09981849732807767, 0.09981849732807767, 0.09981849732807767, 0.09981849732807767, 0.22144684639856338, 0.22144684639856338, 0.22144684639856338, 0.5364027615588396, 0.11897523250955432, 0.05948761625477716, 0.17846284876433147, 0.05948761625477716, 0.11897523250955432, 0.05948761625477716, 0.11897523250955432, 0.11897523250955432, 0.11897523250955432, 0.11897523250955432, 0.5401763543757557, 0.9118999283583181, 0.5355163346925912, 0.10469486522368983, 0.10469486522368983, 0.10469486522368983, 0.052347432611844914, 0.10469486522368983, 0.052347432611844914, 0.20938973044737966, 0.10469486522368983, 0.10469486522368983, 0.052347432611844914, 0.730104523913564, 0.777544086870399, 0.5098508095341945, 0.7508057620097713, 0.10000454557761378, 0.06666969705174251, 0.10000454557761378, 0.06666969705174251, 0.1666742426293563, 0.06666969705174251, 0.13333939410348503, 0.10000454557761378, 0.13333939410348503, 0.10000454557761378, 0.727885732296453, 0.7138781683805024, 0.7759757430960906, 0.7202591064401698, 0.535209278606092, 0.7751053485377931, 0.5363551691431729, 0.14045943364786065, 0.03511485841196516, 0.1053445752358955, 0.03511485841196516, 0.1053445752358955, 0.03511485841196516, 0.17557429205982583, 0.14045943364786065, 0.07022971682393032, 0.07022971682393032, 0.9106307956254439, 0.5371644423198196, 0.0853066127227581, 0.06397995954206857, 0.10663326590344761, 0.10663326590344761, 0.1706132254455162, 0.06397995954206857, 0.10663326590344761, 0.12795991908413715, 0.0853066127227581, 0.0853066127227581, 0.5347863688053687, 0.5351124805619017, 0.727831460720893, 0.7278394424591977, 0.7172887971016898, 0.13925781029549594, 0.06962890514774797, 0.06962890514774797, 0.06962890514774797, 0.06962890514774797, 0.06962890514774797, 0.2785156205909919, 0.06962890514774797, 0.06962890514774797, 0.71711449656158, 0.9109407010105903, 0.910415949188201, 0.12334265468176211, 0.04933706187270485, 0.14801118561811455, 0.0986741237454097, 0.0986741237454097, 0.07400559280905727, 0.12334265468176211, 0.12334265468176211, 0.0986741237454097, 0.07400559280905727, 0.5370035784147449, 0.6965973371676539, 0.8253556534830568, 0.12344043242429022, 0.06172021621214511, 0.06172021621214511, 0.09258032431821767, 0.12344043242429022, 0.06172021621214511, 0.15430054053036277, 0.12344043242429022, 0.09258032431821767, 0.09258032431821767, 0.8256118559019837, 0.7782777683383472, 0.14473909630255793, 0.048246365434185985, 0.09649273086837197, 0.12061591358546496, 0.12061591358546496, 0.07236954815127897, 0.09649273086837197, 0.12061591358546496, 0.07236954815127897, 0.09649273086837197, 0.1212375616368498, 0.04849502465473992, 0.09699004930947984, 0.1212375616368498, 0.1212375616368498, 0.04849502465473992, 0.09699004930947984, 0.14548507396421978, 0.1212375616368498, 0.07274253698210989, 0.14716153094685586, 0.036790382736713964, 0.1103711482101419, 0.09810768729790391, 0.1103711482101419, 0.061317304561189945, 0.13489807003461787, 0.14716153094685586, 0.08584422638566593, 0.061317304561189945, 0.18424624498545927, 0.036849248997091855, 0.11054774699127556, 0.11054774699127556, 0.11054774699127556, 0.07369849799418371, 0.14739699598836742, 0.11054774699127556, 0.11054774699127556, 0.07369849799418371, 0.5382234444928146, 0.8257397967776245, 0.7291271880254742, 0.7655156418914183, 0.13265101976366506, 0.07959061185819905, 0.10612081581093205, 0.07959061185819905, 0.13265101976366506, 0.053060407905466025, 0.10612081581093205, 0.10612081581093205, 0.10612081581093205, 0.07959061185819905, 0.16405204294775486, 0.0468720122707871, 0.0937440245415742, 0.0937440245415742, 0.11718003067696775, 0.07030801840618064, 0.07030801840618064, 0.1874880490831484, 0.0937440245415742, 0.07030801840618064, 0.6966916773339968, 0.8248767633370832, 0.698886196942545, 0.13131611965328407, 0.04377203988442802, 0.06565805982664204, 0.10943009971107007, 0.13131611965328407, 0.04377203988442802, 0.13131611965328407, 0.10943009971107007, 0.13131611965328407, 0.10943009971107007, 0.09886145573894078, 0.04943072786947039, 0.09886145573894078, 0.07414609180420559, 0.12357681967367597, 0.04943072786947039, 0.19772291147788157, 0.12357681967367597, 0.09886145573894078, 0.07414609180420559, 0.7615141125852072, 0.11580809670654234, 0.05790404835327117, 0.11580809670654234, 0.08685607252990676, 0.11580809670654234, 0.08685607252990676, 0.11580809670654234, 0.14476012088317794, 0.11580809670654234, 0.05790404835327117, 0.8257410067229978, 0.910252028961313, 0.75643135642265, 0.7134092850427979, 0.7134592246513214, 0.11625191274128441, 0.04650076509651376, 0.13950229528954128, 0.11625191274128441, 0.09300153019302752, 0.06975114764477064, 0.11625191274128441, 0.09300153019302752, 0.09300153019302752, 0.11625191274128441, 0.9108730077898175, 0.7294922981488313, 0.7717608272622082, 0.09671891901198083, 0.04835945950599042, 0.06447927934132056, 0.06447927934132056, 0.1289585586826411, 0.06447927934132056, 0.1289585586826411, 0.14507837851797126, 0.11283873884731098, 0.11283873884731098, 0.08220434864230663, 0.05480289909487109, 0.08220434864230663, 0.10960579818974218, 0.13700724773717773, 0.05480289909487109, 0.10960579818974218, 0.13700724773717773, 0.13700724773717773, 0.08220434864230663, 0.15789035764243836, 0.04306100662975591, 0.15789035764243836, 0.08612201325951183, 0.11482935101268243, 0.07176834438292652, 0.10047568213609713, 0.11482935101268243, 0.08612201325951183, 0.08612201325951183, 0.7233150995475899, 0.7768665316719848, 0.7709871220116864, 0.7779308364341966, 0.11338399261960555, 0.03779466420653518, 0.09448666051633796, 0.09448666051633796, 0.11338399261960555, 0.07558932841307037, 0.13228132472287316, 0.11338399261960555, 0.09448666051633796, 0.11338399261960555, 0.14064717286854456, 0.07032358643427228, 0.10548537965140842, 0.07032358643427228, 0.14064717286854456, 0.07032358643427228, 0.10548537965140842, 0.10548537965140842, 0.07032358643427228, 0.10548537965140842, 0.09038968504021594, 0.060259790026810624, 0.09038968504021594, 0.09038968504021594, 0.12051958005362125, 0.060259790026810624, 0.12051958005362125, 0.15064947506702656, 0.12051958005362125, 0.09038968504021594, 0.12887320831420637, 0.04295773610473546, 0.10739434026183864, 0.10739434026183864, 0.12887320831420637, 0.04295773610473546, 0.10739434026183864, 0.1503520763665741, 0.10739434026183864, 0.06443660415710319, 0.1335506596852591, 0.057235997007968185, 0.11447199401593637, 0.09539332834661364, 0.11447199401593637, 0.057235997007968185, 0.09539332834661364, 0.15262932535458182, 0.09539332834661364, 0.07631466267729091, 0.7137657482481171, 0.82517001345989, 0.14909529277341751, 0.054216470099424555, 0.12198705772370524, 0.06777058762428069, 0.13554117524856138, 0.054216470099424555, 0.13554117524856138, 0.12198705772370524, 0.09487882267399296, 0.06777058762428069, 0.11773447228805026, 0.047093788915220106, 0.09418757783044021, 0.09418757783044021, 0.1412813667456603, 0.07064068337283015, 0.11773447228805026, 0.1412813667456603, 0.09418757783044021, 0.09418757783044021], \"Term\": [\"000 high\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"120 euros\", \"123 yards\", \"13 passing\", \"15 p\", \"15 passes\", \"171 passengers\", \"1915\", \"1949 ), earned\", \"1971\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"20 percent reduction\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"215 passengers\", \"22 percent statewide\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28 hours\", \"29 depending\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"52 e\", \"53 years\", \"6 million contract\", \"626\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7256\", \"73 yards\", \"9 team searched\", \"90 saves\", \"abu dhabi\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"active medium appears\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"additional option\", \"air plant\", \"aircraft\", \"airline said\", \"al\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also adding engineers\", \"american team\", \"american telephone\", \"another departing\", \"ap\", \"april 2016\", \"architectural prowess\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"authorized cities\", \"avoided salary arbitration\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"baseball cards\", \"baylor\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"beverages\", \"blender\", \"boeing 757 aircraft\", \"boeing 777 aircraft\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"bowl\", \"bryce petty\", \"build 100 high\", \"build houses\", \"bulgari hotel milan\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"ca\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"californians\", \"californias water\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"career record\", \"carroll gardens\", \"catalan\", \"catalan art\", \"certifiable trend\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"chargers\", \"charging connectors\", \"charlie williams\", \"cincinnati\", \"closest\", \"cloudy liquid runoff\", \"collaborate\", \"collegiate bowl\", \"colorado state\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"confront\", \"cornhuskers\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"create one course\", \"created health problems\", \"danny bowien\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"december 2013 levels\", \"delicious ingredient\", \"denver last weekend\", \"designation\", \"development company planning\", \"developmental life transitions\", \"di pinto\", \"di pinto said\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"different well\", \"dinners take place\", \"disappointment often leads\", \"downtown san francisco\", \"downtown san francisco\", \"drought\", \"drought emergency\", \"easily removed\", \"elevating\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enjoyable\", \"entire plant\", \"european edition\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"every subject\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expendable\", \"extra coaches\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fans seeking autographs\", \"finally meet gov\", \"fine people\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"fizz\", \"flight 468\", \"flora grubb gardens\", \"floragrubb\", \"following concerns\", \"fore\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"four sons\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"full 28 hours\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going 29\", \"gonzalez admits\", \"governor called\", \"grayson completed 8\", \"greene -- marshall\", \"grubb\", \"grubb said\", \"guaranteed\", \"guest cooking stints\", \"harry\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"historical average\", \"hold plants\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hotels gardens\", \"hotels il ristorante\", \"hugely popular ride\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"immediate survivors include\", \"implosion\", \"inactive\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infrastructure deployment\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"interception\", \"interment\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"janssen\", \"january 12\", \"january 15\", \"jerry browns call\", \"jones said\", \"kennedy international airport\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"known chef\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"lawn watering\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"lima\", \"lineup began\", \"little tricky\", \"locals\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long toyed\", \"longtime pet project\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"major automakers tesla\", \"major investment\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"marlene levenson\", \"marvin kloss\", \"match made\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"meal inspired\", \"measurable rainfall\", \"mesh sieve\", \"minimalist appeal\", \"minna seidman greene\", \"mission chinese food\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"month food festival\", \"monthly water consumption\", \"mozzarella\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"mutual option\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"narisawa\", \"national team beat\", \"navigating relationship heartaches\", \"nebraska rushed\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never strengthen\", \"new charging locations\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"next two months\", \"noma\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"often outsourced\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one arriving\", \"online\", \"online\", \"online\", \"online\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"paramus\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"passed away\", \"passengers exited\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"paul eggermann said\", \"pentangelo said\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peru\", \"petty\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plane\", \"plant come\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"port authority\", \"possibly broadcasting\", \"president carried\", \"previously came\", \"profile chefs\", \"prolific chefs\", \"pronged cradle\", \"psychiatrist\", \"psychoanalyst\", \"psychologist\", \"pulse\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"quickly collapse candlestick\", \"quite dry\", \"reaching\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"really lets\", \"recorded history\", \"ren redzepi\", \"research results\", \"restrictions loom\", \"rich fluid\", \"ricotta\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rolfe\", \"roommate conflicts\", \"root structure\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said flora grubb\", \"said joe pentangelo\", \"salvaging\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco giant\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"scrap\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"senior bowl\", \"september 26\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"settling\", \"settling\", \"settling\", \"several menu items\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"sharing app similar\", \"sierra nevada snowpack\", \"simple syrup\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since 2006\", \"sitting around\", \"soil\", \"solving\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"sounds like fun\", \"speed chargers\", \"spindly steel base\", \"stadium might\", \"stalk\", \"stand really allows\", \"star anise\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state adapts\", \"stems\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stir\", \"strained yogurt\", \"striking facade\", \"stronger olympic stadiums\", \"stuyvesant high school\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"suny syracuse\", \"supplies\", \"survey released tuesday\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tarragon\", \"tel aviv\", \"telegraph company\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"theodore vail\", \"thigmotrope perch\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"tonjes farm dairy\", \"top passers\", \"toronto blue jays\", \"try cuisine thats\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two aircraft\", \"two conversations\", \"unfounded\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"upped\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using explosives\", \"violating restrictions\", \"visiting chefs\", \"volkswagen announced\", \"vw\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"washing cars\", \"washington nationals completed\", \"watering\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"west shrine classic\", \"whole stand\", \"williams continued\", \"williamss cards\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would help open\", \"would return\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el542823992413823529031866854\", ldavis_el542823992413823529031866854_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el542823992413823529031866854\", ldavis_el542823992413823529031866854_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el542823992413823529031866854\", ldavis_el542823992413823529031866854_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the pyLDAvis chart, do we think this is a good model? \n",
    "Look at the size and overlap of the bubbles.\n",
    "1. Notice how some bubbles make up around or even less than 2% of the topic distribution. How relavent do you think these topics are across all of the tokens in the corpus?\n",
    "2. Notice the overlap of the bubbles. How unique and mutually exclusive do you think these topics are?\n",
    "\n",
    "Again, you will likely need to re-run these models multiple times with better data and slightly-tuned parameters. At the end of the day, you need to decide what makes sense, not the machine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 6\n",
    "    \n",
    "Now you try!\n",
    "\n",
    "Use `pyLDAvis` for the LDA model you ran on the New York Times data. Explore a few topics. Remember, everyone will pick a different value of `K`, so the results will vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ual-laptop\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyLDAvis\\_prepare.py:248: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    NY_vis = pyLDAvis.gensim.prepare(topic_model=NYTimes_lda_model, \n",
    "                                  corpus=NYTimes_corpus, \n",
    "                                  dictionary=NYTimes_dictionary_LDA, \n",
    "                                  sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el5428239924138649677659185\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el5428239924138649677659185_data = {\"mdsDat\": {\"x\": [-0.001195159628458718, -0.001078172542169535, 0.004157109432709636, 0.014746273126078919, 0.006017613605623176, 0.0009259023446654856, -0.013754031998873602, -0.011834610562730675, -0.0034623519869282273, 0.005477428210083517], \"y\": [-0.0032753960184736418, 0.003046258001797097, -0.006159872801465631, 0.005399255552529606, 0.0015000658040226888, 0.0018783465499637073, -0.010167649970161669, 0.010084774435182981, 0.008196498504064311, -0.010502280057459436], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.448373802775796, 5.530825808893827, 10.72814938030221, 9.229659473515476, 11.686498160549393, 6.753125634802662, 13.029109462783332, 12.629306227353645, 9.880088341778796, 8.084863707244851]}, \"tinfo\": {\"Term\": [\"san francisco\", \"way\", \"one\", \"still\", \"trying\", \"well\", \"said\", \"lot\", \"want\", \"part\", \"people\", \"mr\", \"made\", \"work\", \"get\", \"making\", \"united states\", \"high\", \"even\", \"p\", \"go\", \"year\", \"day\", \"think\", \"would\", \"going\", \"idea\", \"c\", \"many\", \"two\", \"hotels gardens\", \"profile chefs\", \"hotels il ristorante\", \"meal inspired\", \"enjoyable\", \"visiting chefs\", \"different well\", \"di pinto said\", \"peru\", \"di pinto\", \"ren redzepi\", \"certifiable trend\", \"120 euros\", \"dinners take place\", \"danny bowien\", \"lineup began\", \"noma\", \"bulgari hotel milan\", \"create one course\", \"lima\", \"known chef\", \"guest cooking stints\", \"upped\", \"mission chinese food\", \"try cuisine thats\", \"collaborate\", \"month food festival\", \"locals\", \"prolific chefs\", \"narisawa\", \"san francisco\", \"one\", \"mr\", \"name\", \"said\", \"well\", \"time\", \"get\", \"1\", \"year\", \"end\", \"two\", \"also\", \"according\", \"much\", \"say\", \"think\", \"told\", \"hope\", \"series\", \"part\", \"may\", \"l\", \"3\", \"people\", \"see\", \"ready\", \"n\", \"california\", \"would\", \"like\", \"ms\", \"world\", \"united states\", \"company\", \"way\", \"work\", \"new york\", \"go\", \"make\", \"certificates\", \"month issue\", \"florida board\", \"07 percent\", \"new three\", \"income issues\", \"william blair\", \"morgan stanley\", \"286 million\", \"month bills\", \"week bills\", \"385\", \"209\", \"236\", \"katy\", \"citigroup global markets\", \"bosc\", \"baird\", \"keybanc capital markets\", \"70 million\", \"monday elk river\", \"robert w\", \"revenue bonds\", \"pa .,\", \"treasurys schedule\", \"56 million\", \"temecula valley\", \"125 million\", \"02 percent\", \"rockford\", \"san francisco\", \"trying\", \"year\", \"part\", \"one\", \"still\", \"way\", \"people\", \"p\", \"go\", \"get\", \"much\", \"lot\", \"mr\", \"working\", \"would\", \"n\", \"said\", \"many\", \"2\", \"friday\", \"see\", \"asked\", \"born\", \"new york\", \"time\", \"instead\", \"since\", \"idea\", \"worked\", \"even\", \"well\", \"2013\", \"going\", \"company\", \"like\", \"university\", \"1\", \"ms\", \"paul eggermann said\", \"fans seeking autographs\", \"baseball cards\", \"expendable\", \"career record\", \"williamss cards\", \"san francisco giant\", \"immediate survivors include\", \"sharon williams\", \"charlie williams\", \"williams continued\", \"traded willie mays\", \"mets drafted\", \"great neck\", \"paul eggermann\", \"pitcher best known\", \"people would want\", \"giants offered\", \"barbara eggermann\", \"mets used\", \"trade bait\", \"last five innings\", \"nearby\", \"receive copies\", \"16 years\", \"fledgling mets took\", \"2 victory\", \"major leagues\", \"williams briefly drove\", \"regular thing\", \"settling\", \"well\", \"1971\", \"said\", \"see\", \"year\", \"mr\", \"take\", \"get\", \"back\", \"time\", \"want\", \"like\", \"would\", \"place\", \"28\", \"day\", \"share\", \"died\", \"led\", \"even\", \"san francisco\", \"number\", \"including\", \"also\", \"los angeles\", \"change\", \"still\", \"ms\", \"long\", \"7\", \"made\", \"people\", \"one\", \"work\", \"go\", \"going\", \"make\", \"world\", \"part\", \"much\", \"according\", \"think\", \"two conversations\", \"european edition\", \"next two months\", \"1915\", \"quickly collapse candlestick\", \"grayson completed 8\", \"would return\", \"rolfe\", \"senior bowl\", \"bryce petty\", \"colorado state\", \"15 passes\", \"possibly broadcasting\", \"telegraph company\", \"following concerns\", \"american telephone\", \"73 yards\", \"development company planning\", \"theodore vail\", \"interception\", \"build houses\", \"nebraska rushed\", \"top passers\", \"using explosives\", \"scrap\", \"cornhuskers\", \"123 yards\", \"petty\", \"13 passing\", \"president carried\", \"mozzarella\", \"baylor\", \"ap\", \"tonjes farm dairy\", \"gonzalez admits\", \"blender\", \"star anise\", \"pulse\", \"mesh sieve\", \"ricotta\", \"rich fluid\", \"salvaging\", \"fizz\", \"stalk\", \"several menu items\", \"san francisco\", \"quite dry\", \"tarragon\", \"simple syrup\", \"active medium appears\", \"stems\", \"strained yogurt\", \"c\", \"carroll gardens\", \"delicious ingredient\", \"cloudy liquid runoff\", \"jan\", \"stir\", \"beverages\", \"one\", \"said\", \"though\", \"mr\", \"says\", \"day\", \"world\", \"time\", \"never\", \"lot\", \"make\", \"f\", \"want\", \"would\", \"become\", \"united states\", \"think\", \"part\", \"long\", \"well\", \"left\", \"work\", \"still\", \"week\", \"see\", \"end\", \"like\", \"also\", \"people\", \"according\", \"get\", \"year\", \"new york\", \"even\", \"made\", \"ms\", \"janssen\", \"toronto blue jays\", \"going 29\", \"90 saves\", \"52 e\", \"washington nationals completed\", \"6 million contract\", \"guaranteed\", \"mutual option\", \"avoided salary arbitration\", \"since 2006\", \"sounds like fun\", \"striking facade\", \"never strengthen\", \"confront\", \"roommate conflicts\", \"full 28 hours\", \"psychologist\", \"research results\", \"developmental life transitions\", \"navigating relationship heartaches\", \"every subject\", \"abu dhabi\", \"solving\", \"catalan\", \"stronger olympic stadiums\", \"extra coaches\", \"disappointment often leads\", \"often outsourced\", \"architectural prowess\", \"catalan art\", \"28 hours\", \"san francisco\", \"still\", \"said\", \"year\", \"one\", \"way\", \"much\", \"lot\", \"years\", \"make\", \"first time\", \"according\", \"time\", \"also\", \"well\", \"united states\", \"maybe\", \"matter\", \"something\", \"work\", \"like\", \"week\", \"mr\", \"think\", \"end\", \"found\", \"3\", \"get\", \"say\", \"worked\", \"going\", \"trying\", \"world\", \"made\", \"though\", \"ms\", \"would\", \"see\", \"part\", \"even\", \"people\", \"historical average\", \"previously came\", \"violating restrictions\", \"recorded history\", \"december 2013 levels\", \"survey released tuesday\", \"state adapts\", \"22 percent statewide\", \"governor called\", \"washing cars\", \"lawn watering\", \"fine people\", \"supplies\", \"measurable rainfall\", \"californians\", \"20 percent reduction\", \"authorized cities\", \"californias water\", \"monthly water consumption\", \"drought emergency\", \"closest\", \"finally meet gov\", \"restrictions loom\", \"sierra nevada snowpack\", \"jerry browns call\", \"havana\", \"moulitsas\", \"masschusetts\", \"gentlewomans agreement\", \"associates noted\", \"downtown san francisco\", \"reaching\", \"drought\", \"goal\", \"said\", \"going\", \"mr\", \"san francisco\", \"people\", \"time\", \"one\", \"made\", \"work\", \"well\", \"high\", \"think\", \"ms\", \"added\", \"fact\", \"get\", \"part\", \"two\", \"even\", \"many\", \"according\", \"home\", \"want\", \"would\", \"way\", \"2013\", \"year\", \"kind\", \"day\", \"change\", \"years\", \"like\", \"also\", \"go\", \"much\", \"make\", \"said joe pentangelo\", \"passengers exited\", \"171 passengers\", \"another departing\", \"9 team searched\", \"one arriving\", \"tel aviv\", \"pentangelo said\", \"boeing 757 aircraft\", \"two aircraft\", \"kennedy international airport\", \"airline said\", \"215 passengers\", \"aircraft\", \"plane\", \"boeing 777 aircraft\", \"port authority\", \"designation\", \"flight 468\", \"unfounded\", \"denver last weekend\", \"national team beat\", \"collegiate bowl\", \"inactive\", \"stadium might\", \"created health problems\", \"implosion\", \"american team\", \"west shrine classic\", \"marvin kloss\", \"mr\", \"cincinnati\", \"15 p\", \"said\", \"san francisco\", \"1\", \"new york\", \"company\", \"university\", \"one\", \"made\", \"money\", \"time\", \"year\", \"much\", \"4\", \"way\", \"start\", \"game\", \"10\", \"going\", \"long\", \"f\", \"part\", \"30\", \"people\", \"thats\", \"likely\", \"kind\", \"see\", \"work\", \"expected\", \"go\", \"3\", \"according\", \"like\", \"well\", \"even\", \"end\", \"make\", \"united states\", \"get\", \"also\", \"minna seidman greene\", \"four sons\", \"suny syracuse\", \"paramus\", \"marlene levenson\", \"january 12\", \"greene -- marshall\", \"harry\", \"stuyvesant high school\", \"1949 ), earned\", \"psychoanalyst\", \"53 years\", \"psychiatrist\", \"september 26\", \"interment\", \"january 15\", \"jones said\", \"000 high\", \"major automakers tesla\", \"build 100 high\", \"would help open\", \"volkswagen announced\", \"charging connectors\", \"speed chargers\", \"new charging locations\", \"chargers\", \"infrastructure deployment\", \"april 2016\", \"vw\", \"passed away\", \"al\", \"ca\", \"subject\", \"many\", \"one\", \"also\", \"time\", \"two\", \"mr\", \"people\", \"2015\", \"called\", \"california\", \"make\", \"would\", \"way\", \"2\", \"world\", \"help\", \"ms\", \"become\", \"1\", \"said\", \"made\", \"according\", \"going\", \"country\", \"year\", \"play\", \"company\", \"3\", \"years\", \"san francisco\", \"well\", \"even\", \"part\", \"work\", \"still\", \"though\", \"see\", \"air plant\", \"entire plant\", \"little tricky\", \"pronged cradle\", \"flora grubb gardens\", \"29 depending\", \"root structure\", \"bowl\", \"minimalist appeal\", \"hold plants\", \"easily removed\", \"grubb said\", \"grubb\", \"said flora grubb\", \"spindly steel base\", \"floragrubb\", \"additional option\", \"plant come\", \"whole stand\", \"sitting around\", \"elevating\", \"stand really allows\", \"thigmotrope perch\", \"really lets\", \"626\", \"watering\", \"7256\", \"fore\", \"soil\", \"actually work\", \"online\", \"made\", \"said\", \"according\", \"way\", \"san francisco\", \"lot\", \"united states\", \"ms\", \"go\", \"say\", \"new york\", \"information\", \"put\", \"mr\", \"right\", \"asked\", \"week\", \"though\", \"like\", \"something\", \"used\", \"world\", \"working\", \"well\", \"time\", \"could\", \"year\", \"making\", \"even\", \"people\", \"would\", \"one\", \"see\", \"also\", \"get\", \"company\", \"work\", \"part\", \"much\", \"mike isaac reports\", \"lure daniel barenboim\", \"david robertson\", \"berlin philharmonic\", \"ludovic morlot\", \"simon rattle\", \"wunderkind young conductors\", \"lukes\", \"would step\", \"succeed alan gilbert\", \"seattle symphony\", \"detroit symphony orchestra\", \"conductors\", \"orchestra sees\", \"baton\", \"whose exciting tenure\", \"next season esa\", \"maestros named\", \"sguin\", \"keep subscribers\", \"marin alsop\", \"21st century\", \"contract elsewhere\", \"robert spano\", \"orchestras composer\", \"andris nelsons\", \"formula\", \"orchestra\", \"baltimore symphony orchestra\", \"yannick nzet\", \"major investment\", \"long toyed\", \"sharing app similar\", \"hugely popular ride\", \"match made\", \"also adding engineers\", \"longtime pet project\", \"way\", \"united states\", \"one\", \"work\", \"want\", \"said\", \"even\", \"plenty\", \"well\", \"may\", \"san francisco\", \"add\", \"mr\", \"much\", \"still\", \"high\", \"past\", \"begin\", \"course\", \"year\", \"going\", \"people\", \"also\", \"lot\", \"thats\", \"think\", \"according\", \"see\", \"know\", \"years\", \"time\", \"worked\", \"part\", \"week\", \"make\", \"new york\", \"get\", \"go\", \"ms\", \"would\", \"1\"], \"Freq\": [118.0, 62.0, 104.0, 46.0, 37.0, 69.0, 123.0, 45.0, 43.0, 51.0, 58.0, 113.0, 55.0, 52.0, 52.0, 23.0, 45.0, 29.0, 47.0, 16.0, 43.0, 73.0, 36.0, 41.0, 52.0, 47.0, 31.0, 33.0, 42.0, 42.0, 0.6277251556859843, 0.6075414108206336, 0.601305335358256, 0.6002459934139471, 0.6012622325272858, 0.600198315219285, 0.6000426439165307, 0.5986386971989215, 0.5988691357543866, 0.5969977393795913, 0.5978826001926348, 0.59127221640537, 0.589040383046404, 0.5860731144425854, 0.581206670470128, 0.5808959088631833, 0.581362595959754, 0.5801415911649991, 0.5783599953807593, 0.5784994350361307, 0.5760635259315432, 0.576666457191383, 0.5741525853419824, 0.5659740138055344, 0.5601440563394255, 0.5596746821244961, 0.5570475155551065, 0.5576204890764875, 0.5562871699968203, 0.5543410426817243, 19.227001747966117, 16.478154615813157, 15.552203260325966, 4.447840026547925, 16.293522568136055, 10.543267066041782, 11.764863026835657, 8.407035277794096, 7.639736038194083, 10.505549801260981, 6.730210674109628, 6.908849140600021, 8.24946730522743, 8.072488170635955, 7.561415107766295, 6.312281558032286, 6.324231536497604, 4.676695360926026, 2.3161517923207264, 3.7460965979250234, 7.002936629060351, 4.884383465119486, 4.3909785685824945, 5.2746065026731195, 7.4614095679325825, 6.76771703641168, 2.43943634686975, 5.485085433468979, 5.451178357271198, 6.6648355536859345, 6.277093380000782, 6.403269419153426, 6.087037710728302, 5.901469674364519, 5.743574599606295, 6.448145167241849, 5.979939921423267, 5.7317059609399434, 5.504502405479428, 5.528766067511158, 0.37682194213167497, 0.37741995173401804, 0.3745574240346351, 0.3731638967753467, 0.3732830598607324, 0.3736014411668523, 0.37115535505425185, 0.3697138463414112, 0.3692538439191912, 0.3687854842700243, 0.36808834956659675, 0.36865706047369745, 0.36792514163649087, 0.36819780019904413, 0.3637208434037764, 0.3640916267815633, 0.3646290061544345, 0.3633008846828734, 0.363731588409851, 0.36155861260180094, 0.3620765025342246, 0.3632172478788334, 0.3617216914627647, 0.3616177262688539, 0.3602929283277002, 0.3604166411003427, 0.35915305419980015, 0.3575026470805725, 0.3581501224316013, 0.35751487638178053, 6.378893858497106, 3.169011411989829, 4.277633770390219, 3.4022842677121856, 4.682109615152752, 2.984227767824515, 3.31610764109518, 3.1952183850038813, 1.580844659781034, 2.710088265935539, 2.983214058782956, 2.8622419403024693, 2.649460617846481, 4.244583551465363, 2.2040618527714, 2.7798062536982653, 2.349559947760049, 4.219546203016449, 2.397431176265018, 2.256706832563751, 1.3609269753926756, 2.5686222909441274, 1.9750641542407363, 1.6691346645297538, 2.418942872030047, 3.1589904838020733, 1.7046640435348575, 1.5284136766261802, 1.9147966090579618, 1.8113629218740361, 2.300087487478968, 2.6763699851314993, 1.9635027858427687, 2.242630551933192, 2.120043391278396, 2.1768721473098775, 2.0551723370065864, 2.098034263039956, 2.05276610099159, 0.5346970918392832, 0.5209386138404593, 0.5153256107144282, 0.5158085466048442, 0.5107514267228165, 0.5092306418258065, 0.5068079822900006, 0.5080025225876335, 0.49905622284212503, 0.502588364371381, 0.5032433258313678, 0.4936843747168421, 0.4901918519562012, 0.4874925808123478, 0.4845701489741867, 0.48333843087472556, 0.48350354037173404, 0.47762735095498243, 0.4801613874240434, 0.4819398820837268, 0.48034383404412667, 0.4738994313716543, 0.477145197425716, 0.47510733439772207, 0.4746479945195775, 0.47318532340875874, 0.4758614053681384, 0.46453275333325067, 0.4639053309857292, 0.46432145323397067, 1.2672221491405002, 10.627255375239551, 0.8112217013268433, 15.01633397063715, 7.202310091610761, 8.92827038928844, 12.161582505626603, 5.738415493131819, 6.935566248270858, 5.204486179230293, 9.231293758679131, 5.817467767241601, 6.0953314034838995, 6.417083872906745, 3.5857934785166106, 2.16433965661367, 4.963487901067592, 2.864370876994713, 3.2666091565089483, 3.2538545417483804, 5.721969635878615, 10.385527060240948, 4.329539534958532, 4.346632310999105, 6.125954896545429, 3.4394311071411594, 3.4949547146272035, 5.286897724349719, 5.509961030341541, 4.253600682690749, 2.970821063029622, 5.734075329007271, 5.894557754410439, 8.285583111727403, 5.446810841191556, 4.888880439709726, 4.965075656079006, 4.826417226237968, 4.747381475595666, 4.954086048071903, 4.842131544521863, 4.933149312642295, 4.4280123911789175, 0.6324843581483859, 0.6322943874122319, 0.6321669864026683, 0.6321404400384609, 0.6321124398165788, 0.6320533162711431, 0.6320529393450793, 0.6320183698403711, 0.6319346384076274, 0.6318879534222971, 0.6318737917716144, 0.6318539762299747, 0.631834052995174, 0.6317799910283094, 0.6317684140134927, 0.6317477907731449, 0.6315938972459545, 0.6314664423898104, 0.6314034957371562, 0.6313579953765978, 0.6313361336648975, 0.631229678975165, 0.6312155711710629, 0.6312137942339049, 0.631187894028664, 0.6311162780765425, 0.631098562551544, 0.6310773469988102, 0.6310686238527623, 0.6310646392058022, 0.8886280186763157, 0.8595164033718159, 1.062755421590671, 0.8595418728044125, 0.8583992483653006, 0.8581644772741353, 0.8560486835848786, 0.854431563078026, 0.853981136431788, 0.851066690259925, 0.8458002254499652, 0.8447326631441295, 0.8430772577185114, 0.8414949221026893, 0.8399399405497828, 12.51016485735139, 0.8378089621248132, 0.8354737436198458, 0.8352313263142435, 0.8352611573198641, 0.8319763543670297, 0.8317036752831624, 5.074831291398573, 0.8299625461013205, 0.829171324446829, 0.8296585283075775, 3.880568843091648, 0.8280863158488975, 0.8271113158150143, 9.669195144660753, 10.565346122951242, 5.391379399820118, 9.576755642911824, 3.6244297056764836, 4.802009191013408, 5.478671168469184, 7.522043360759378, 3.458340358765772, 5.32457862431702, 5.314426605407858, 4.110452387834287, 4.905656535422776, 5.449367859337952, 4.015882284586452, 4.91137504227639, 4.632967543784711, 5.218115749904245, 4.106876974886264, 6.050316806051879, 3.529878987197644, 5.139979623037983, 4.7877286470808915, 4.187419828516454, 4.993306706911932, 4.408945522413608, 4.671779297494461, 5.0352648240159406, 5.129065998093628, 5.0127987382956745, 4.822930095258426, 5.321671339740369, 4.5706545576903475, 4.5831120717920175, 4.726589516442354, 4.60667059693833, 0.8077056802196279, 0.8068480442973406, 0.8068142270290797, 0.8065693927340695, 0.8064541685740674, 0.8061616764756007, 0.8061010644766411, 0.8058933882687321, 0.8057853911862213, 0.8054723769148786, 0.8050122984345864, 0.6873678174527336, 0.6842511061946432, 0.6646113867522155, 0.6631122454326153, 0.6616870112073595, 0.6766534023520483, 0.655462383908126, 0.6510206629899887, 0.6499857591292368, 0.6496991986887111, 0.6497639014862506, 0.670061421340335, 0.6468769567484012, 0.6668642577101723, 0.6661499360981361, 0.6430702641298255, 0.6424320995513527, 0.6421715156818096, 0.6623928103223541, 0.6585214149062388, 0.6573696505660529, 15.486145649225513, 7.625243644075018, 14.815055051142439, 10.09565672523594, 12.038890775157496, 8.328486282677096, 7.432639574454027, 6.812673595263968, 6.44036128946543, 6.8089886039031455, 3.2724932315333497, 7.270499954577854, 9.076295171888809, 6.995778285142497, 7.879998398361528, 5.961973485609076, 2.7126243561216716, 3.9932870323628595, 4.546073644553017, 6.378484961024674, 5.979073023673282, 5.100139858538983, 9.49801287029716, 5.42799609256964, 5.29529985911273, 3.8621262119729587, 4.804845290325135, 6.041998232869937, 5.21544092555431, 4.281751875987522, 5.671420425669299, 4.998135523227938, 5.559457995735025, 5.919482088039194, 5.149123626175157, 5.566130906378645, 5.625690751943526, 5.433483217064884, 5.43309213672064, 5.269955998310391, 5.252655192956052, 0.5059793660998972, 0.5058315043488905, 0.5058226397355208, 0.505778237872109, 0.5057039721112115, 0.5056250967513619, 0.505366289439248, 0.5053122349968336, 0.5052778796952407, 0.5050746633585254, 0.5050557915816183, 0.5050298675122971, 0.5049931877120872, 0.5045267514557138, 0.5045125680743223, 0.504504097443769, 0.5044725788184545, 0.5044265222272136, 0.5043792048909602, 0.5042572278109929, 0.5042021490132558, 0.504165587407891, 0.5040395917031961, 0.5038399606101102, 0.5028020128802211, 0.30839984003485116, 0.3070910685169469, 0.30653860611260564, 0.3044863693209541, 0.3038137815558828, 0.6315500815306495, 0.6010763380435771, 0.5764600552832386, 1.295519748280446, 8.131019256633616, 4.120807795686139, 7.285530241453807, 7.213507661120079, 4.514632388618696, 5.43688154870326, 6.188225690813578, 4.223478141716958, 4.115576649442687, 4.69184018609709, 2.9375765383409314, 3.2839299841285134, 3.61591597975272, 2.9913573990876214, 2.499934594902987, 3.6949842335892584, 3.642028845639556, 3.2330195245892175, 3.3706610461515205, 3.1817204403997934, 3.6344694185441186, 2.790028397656018, 3.128739522363586, 3.4282588124238007, 3.7212609963277297, 2.7705990562671285, 4.01213882488546, 2.8031839566760497, 2.760379457195145, 2.271580263381692, 2.924843328900114, 3.074211039824435, 3.2383770605201816, 2.960076739394215, 2.9361673406031183, 2.8263873382601012, 0.8772900289837884, 0.8772122678082042, 0.8769672782980301, 0.8766412590584595, 0.8766252203409147, 0.8763838034360706, 0.8763164560249584, 0.8762250125310896, 0.8761330369470652, 0.8761223191310756, 0.8760378688221078, 0.8759450570964105, 0.8758065616302184, 0.8757908269641911, 0.8756724749110292, 0.8755988944438097, 0.8750791943876323, 0.8747606244102387, 0.8747567477533914, 0.8716211404669538, 0.780089547670914, 0.7782314128349834, 0.7687938817724096, 0.7696179373975404, 0.7645409611722742, 0.7612952112236454, 0.7615015101782256, 0.7593764181099865, 0.7588697922690588, 0.7578683985963834, 22.351191908537807, 1.0317989764446642, 1.0243168767036002, 17.957945452075375, 16.52444227626258, 8.695338876100594, 8.70364495545391, 8.205780663052687, 7.7151065809357915, 13.790355085999284, 8.680620958347589, 5.583337541373666, 10.66242874899513, 9.784444114319758, 7.7491354186641885, 4.858828078999888, 8.483691655328602, 5.271673182044152, 4.589590156258835, 5.107028677249549, 6.957119526234729, 5.640770440605178, 5.347679980372791, 7.206477040508233, 4.502245884948044, 7.571826560065343, 5.360910478102499, 4.155227023274112, 5.735797485658541, 6.816040838350516, 6.883334128292477, 4.680977704648489, 5.982085295812011, 5.292421657593981, 6.695635829342844, 6.096522989738485, 6.893417084713688, 5.760610521893454, 5.489752916719019, 5.628376084548418, 5.552534690245264, 5.556716614816079, 5.491639252333192, 0.7730886701415716, 0.772302131925822, 0.7704991726621789, 0.7672035959582871, 0.7650721694940996, 0.7628881352279407, 0.758705004486867, 0.7555379263917122, 0.754636078357916, 0.7502020658721466, 0.7485803603800016, 0.7490323159224286, 0.7474582079654007, 0.7465621070024082, 0.738578246769885, 0.7369968444537602, 0.6783209461980573, 0.6711757899008856, 0.6582641848562474, 0.6506971346177753, 0.641044192399175, 0.6309482099659328, 0.629885222908451, 0.6289431453790296, 0.6283748484930272, 0.6270952410744866, 0.6266519798186599, 0.6259266700110873, 0.6268140030070846, 0.9065168657005278, 0.8903222096191341, 1.0489924243122535, 3.731561873359366, 8.403531383669685, 16.229185661668126, 9.422001925428349, 12.300071913454653, 7.6515746191925675, 15.510804168990393, 9.34840405255267, 3.4108402506503404, 5.316394748671492, 6.602404698808956, 7.681882018116553, 8.14535586932022, 9.082894686414647, 6.5799475038811135, 7.3898948652608025, 4.957666125769552, 7.616744422906937, 5.559558914081946, 7.058804053214179, 12.939845266402283, 7.758641664098951, 7.888895634564446, 6.952607026410987, 5.377311930860205, 8.928604402797427, 4.278800607772656, 6.2838666682837205, 5.452505426368227, 5.959063446417818, 10.891703583971106, 7.8933418043153765, 6.318919674083583, 6.350672977077438, 6.271092845577579, 5.776558287092285, 5.626087595147613, 5.758889728390951, 0.6089665078395762, 0.5949393403264216, 0.5914104862653546, 0.5848980065871147, 0.5826274030495451, 0.5824513667172, 0.5801000078090948, 0.5792897449656845, 0.5782865569080113, 0.5737095546258039, 0.5728802701747728, 0.5716870966058327, 0.5718946626938402, 0.5658685021171048, 0.566116589993468, 0.5655558560573014, 0.5661256396673968, 0.5613896628584677, 0.5556568961689743, 0.5541333230397846, 0.5533339543898299, 0.5522121406700853, 0.5471018416796732, 0.5486986191775853, 0.5474007114842604, 0.5342947661923041, 0.527839236054456, 0.6750109128885882, 0.6748804131320625, 0.4133374296945812, 1.1646043824009296, 8.306290135401362, 13.88116872017452, 7.3368646242777835, 7.355782016545301, 11.275132850826319, 5.85935652575199, 5.660878385453431, 5.9936670596201225, 5.443478702718418, 5.131822227641126, 5.599492314469514, 2.86830879256782, 4.124341973028935, 9.361171775074668, 3.848668154316766, 4.0990190255745, 4.576081866963562, 4.924855608479938, 5.37948817016257, 4.007561291614238, 4.310010386343306, 5.1706069397324965, 4.179812669890199, 6.5080560592846854, 7.143504103406508, 4.180260427005345, 6.526893214952785, 3.327135330524658, 5.030387948689937, 5.6721917459714515, 5.270818763367256, 7.588991537274947, 5.1562727173593546, 5.228921424574303, 5.034158146602848, 4.620663442797984, 4.90127019841981, 4.702911490760615, 4.587927371365082, 0.46146388355523527, 0.4008428543785873, 0.3974889915598637, 0.3931375308420331, 0.3929949191518227, 0.384991990700639, 0.3818826454946327, 0.38150914767127203, 0.38147971499566713, 0.3748625042692548, 0.3765932776645188, 0.375250270336799, 0.37334587245611595, 0.3688784498264672, 0.3691411270226907, 0.3680323783222009, 0.3667995784408766, 0.3679298120512029, 0.36731538136407677, 0.36558585791417103, 0.365892896378674, 0.3624391322667916, 0.3571392224446942, 0.359975159791496, 0.3552392111647023, 0.35655901195973366, 0.35609893773241025, 0.35730402656098165, 0.3565777611401069, 0.3564785909470633, 0.5408435266550443, 0.5316303445067335, 0.5306179359343253, 0.5292619103077802, 0.5059473634732837, 0.5089096868045139, 0.508606586847083, 6.7709538168023, 5.375279357481569, 9.506000291063637, 5.758190165576898, 4.707045928020765, 9.716359397031514, 4.649295245064081, 1.2415013877275423, 5.907861735841521, 3.383849809718994, 8.376539477142922, 1.3666800664429881, 8.010049083299146, 4.7603213349175295, 4.343569364690526, 3.165321438231791, 2.492654051659514, 1.5340013368431593, 2.7588999598000976, 5.39448115957778, 4.06495814804695, 4.64366643452565, 4.492097211368503, 3.9215847930197714, 3.1590356752801787, 3.637159113576255, 4.368476955092135, 4.061677159400998, 3.2430620020411047, 3.610390472455631, 5.2494841019464005, 2.835360768233593, 4.009359446487376, 3.2564968864287382, 3.7696118139280457, 3.693881539596743, 3.8522625404464397, 3.5397014871766475, 3.64119893697402, 3.6389575255241113, 3.421101011458888], \"Total\": [118.0, 62.0, 104.0, 46.0, 37.0, 69.0, 123.0, 45.0, 43.0, 51.0, 58.0, 113.0, 55.0, 52.0, 52.0, 23.0, 45.0, 29.0, 47.0, 16.0, 43.0, 73.0, 36.0, 41.0, 52.0, 47.0, 31.0, 33.0, 42.0, 42.0, 1.3320187454522754, 1.3254977724037897, 1.3221657360740466, 1.3208190010830587, 1.3240097652555944, 1.3217742631655025, 1.3218181631431152, 1.3190035751230729, 1.3225614351182948, 1.319332806012214, 1.3221759913160276, 1.320424098015731, 1.3176757913915447, 1.3165391511724343, 1.313535351387258, 1.314323096311034, 1.3159839893582124, 1.3141796063947597, 1.3126184214693912, 1.3142687297634905, 1.3112889654507829, 1.314222802872409, 1.3129382120364261, 1.3111542792389665, 1.3060616897512032, 1.3091018783017903, 1.305730977615531, 1.3092815947457503, 1.3071138249169498, 1.3060988378310283, 118.26905902260408, 104.45669152933114, 113.55188500798273, 21.108363182158918, 123.53614200820064, 69.6717245010786, 81.54585621847102, 52.93670447280838, 46.87110134803547, 73.77534374244917, 40.66572086785267, 42.675300441293636, 56.20113313435379, 57.215996888448416, 52.24896202770623, 40.52855472479078, 41.45565099611742, 27.13690808254685, 9.678223396252744, 20.036245423205866, 51.92196463194254, 30.46496040611863, 26.002507397641075, 34.59932604853514, 58.68362808013039, 51.086466369085755, 11.043208082374832, 38.44995184750012, 38.22149844991857, 52.41999841492463, 47.76312789772734, 50.15933788180389, 46.56558814819854, 45.695971321686805, 43.643368838162544, 62.03589570456025, 52.9169173941317, 47.05867695853716, 43.9069813626226, 47.98619832730301, 1.0495609830601826, 1.0512877027214171, 1.0523343125892928, 1.0516818652449689, 1.0530687936595968, 1.054475168397216, 1.0530374428606442, 1.0539201294840161, 1.0536218082433333, 1.0553229958311416, 1.053826591678462, 1.05608715997721, 1.055081827683718, 1.0562394350717015, 1.0516816683414267, 1.0544015522313603, 1.0574239899392124, 1.0571815947395402, 1.0599360138404397, 1.054713525214071, 1.0566648363246094, 1.0605446618909395, 1.0573953408207568, 1.0584099830899063, 1.057384299625288, 1.057790035684541, 1.056818961728051, 1.0563700291231124, 1.059385014789823, 1.0593376736812687, 118.26905902260408, 37.691846432482166, 73.77534374244917, 51.92196463194254, 104.45669152933114, 46.88998243839169, 62.03589570456025, 58.68362808013039, 16.16562144420064, 43.9069813626226, 52.93670447280838, 52.24896202770623, 45.81867336365575, 113.55188500798273, 33.19112050447564, 52.41999841492463, 38.44995184750012, 123.53614200820064, 42.473318269352916, 38.49827821235634, 14.173221905333033, 51.086466369085755, 30.544263218370407, 21.750091644049693, 47.05867695853716, 81.54585621847102, 23.19801170431153, 19.101695204864082, 31.30854749812348, 28.437668707075538, 47.65089538489062, 69.6717245010786, 34.17880807157408, 47.422634500144476, 43.643368838162544, 47.76312789772734, 40.45778363818875, 46.87110134803547, 50.15933788180389, 1.2947867145317842, 1.291057680187236, 1.2835928808261283, 1.2881438520856399, 1.2891026724159524, 1.2854419592455688, 1.2884050268490577, 1.292378561047575, 1.2788921607172474, 1.2887498907840298, 1.2970430904935224, 1.2835284321508662, 1.2850181393159423, 1.2917814042130342, 1.284182382047199, 1.2830901122771436, 1.2861924140945054, 1.2745827011741897, 1.2815537565158068, 1.287767241596256, 1.2900699071079915, 1.2756926576715857, 1.2859960379189745, 1.2841155470273804, 1.2843047415921902, 1.2819715592589807, 1.2936359385150915, 1.2727766399339442, 1.2808007768828145, 1.2834912387973811, 4.5159554212179165, 69.6717245010786, 2.6016601394965884, 123.53614200820064, 51.086466369085755, 73.77534374244917, 113.55188500798273, 40.53998822786606, 52.93670447280838, 35.82149272658835, 81.54585621847102, 43.011165583271975, 47.76312789772734, 52.41999841492463, 22.656625150483848, 11.021303183323587, 36.75292892669951, 16.81138681780031, 20.395706239353622, 20.450034726746996, 47.65089538489062, 118.26905902260408, 32.163082006759254, 33.37524826420959, 56.20113313435379, 23.636831057994993, 24.60533216549943, 46.88998243839169, 50.15933788180389, 33.516757299507056, 19.35639120429699, 55.230113252389934, 58.68362808013039, 104.45669152933114, 52.9169173941317, 43.9069813626226, 47.422634500144476, 47.98619832730301, 46.56558814819854, 51.92196463194254, 52.24896202770623, 57.215996888448416, 41.45565099611742, 1.2130764382891581, 1.2128864675530042, 1.2127590665434407, 1.2127325201792332, 1.2127045199573512, 1.2126453964119155, 1.2126450194858516, 1.2126104499811434, 1.2125267185483997, 1.2124800335630694, 1.2124658719123866, 1.212446056370747, 1.2124261331359463, 1.2123720711690817, 1.212360494154265, 1.2123398709139173, 1.2121859773867267, 1.2120585225305827, 1.2119955758779284, 1.21195007551737, 1.2119282138056697, 1.2118217591159373, 1.2118076513118352, 1.2118058743746771, 1.2117799741694364, 1.2117083582173147, 1.2116906426923162, 1.2116694271395825, 1.2116607039935345, 1.2116567193465746, 1.8528625369315868, 1.8354640846446857, 2.4593949126652888, 1.85912012048998, 1.8635184322082623, 1.8642058080438983, 1.8655246376999823, 1.8645181551466687, 1.8640702712072554, 1.8644963086378246, 1.8707508501265164, 1.8692526072569835, 1.8665591207736343, 1.869542916020112, 1.8653732260863083, 118.26905902260408, 1.8698484449799873, 1.8633275802206017, 1.8684385330177626, 1.8698323559201326, 1.8627329314668395, 1.8698443847215787, 33.31401623011289, 1.8696511569189487, 1.8688054953943454, 1.8710461650160934, 22.548326754286418, 1.8709858663057024, 1.8704386258713424, 104.45669152933114, 123.53614200820064, 41.24889513858642, 113.55188500798273, 22.659960727055726, 36.75292892669951, 46.56558814819854, 81.54585621847102, 21.522880288005076, 45.81867336365575, 47.98619832730301, 31.012066504663633, 43.011165583271975, 52.41999841492463, 30.780414563240598, 45.695971321686805, 41.45565099611742, 51.92196463194254, 33.516757299507056, 69.6717245010786, 26.035779263960094, 52.9169173941317, 46.88998243839169, 36.49937062470521, 51.086466369085755, 40.66572086785267, 47.76312789772734, 56.20113313435379, 58.68362808013039, 57.215996888448416, 52.93670447280838, 73.77534374244917, 47.05867695853716, 47.65089538489062, 55.230113252389934, 50.15933788180389, 1.372277503706192, 1.371419867783905, 1.3713860505156439, 1.3711412162206338, 1.3710259920606316, 1.3707334999621648, 1.3706728879632053, 1.3704652117552965, 1.3703572146727854, 1.3700442004014428, 1.3695841219211506, 1.3737567068914376, 1.3738600946733632, 1.3365910314519223, 1.3368096453171847, 1.336449198838056, 1.3737590578532277, 1.3348457137095746, 1.3338034862095438, 1.3329983587977303, 1.332716650659472, 1.3333349879510341, 1.3755751060257007, 1.3318636519696905, 1.375132207449097, 1.3738433599307194, 1.3304874911314948, 1.3311974499500072, 1.3317051996248581, 1.3746360677976759, 1.3750216034784, 1.373692926399004, 118.26905902260408, 46.88998243839169, 123.53614200820064, 73.77534374244917, 104.45669152933114, 62.03589570456025, 52.24896202770623, 45.81867336365575, 42.470352455327685, 47.98619832730301, 16.000472231161012, 57.215996888448416, 81.54585621847102, 56.20113313435379, 69.6717245010786, 45.695971321686805, 12.877311208582034, 24.12197421190623, 29.999217743327268, 52.9169173941317, 47.76312789772734, 36.49937062470521, 113.55188500798273, 41.45565099611742, 40.66572086785267, 23.002113597997333, 34.59932604853514, 52.93670447280838, 40.52855472479078, 28.437668707075538, 47.422634500144476, 37.691846432482166, 46.56558814819854, 55.230113252389934, 41.24889513858642, 50.15933788180389, 52.41999841492463, 51.086466369085755, 51.92196463194254, 47.65089538489062, 58.68362808013039, 1.0981401786038425, 1.0979923168528356, 1.097983452239466, 1.0979390503760542, 1.0978647846151568, 1.097785909255307, 1.0975271019431931, 1.0974730475007788, 1.0974386921991859, 1.0972354758624705, 1.0972166040855635, 1.0971906800162423, 1.0971540002160325, 1.096687563959659, 1.0966733805782676, 1.0966649099477142, 1.0966333913223998, 1.0965873347311588, 1.0965400173949054, 1.0964180403149382, 1.096362961517201, 1.0963263999118362, 1.0962004042071414, 1.0960007731140553, 1.0949628253841663, 1.1543273590320207, 1.1544863233881695, 1.1573464225256567, 1.1565333028929046, 1.1572771112084435, 2.442686563847902, 2.341547107822039, 2.3274941117684556, 8.64305822745992, 123.53614200820064, 47.422634500144476, 113.55188500798273, 118.26905902260408, 58.68362808013039, 81.54585621847102, 104.45669152933114, 55.230113252389934, 52.9169173941317, 69.6717245010786, 29.228417105104114, 41.45565099611742, 50.15933788180389, 34.94003534444471, 24.577676076195104, 52.93670447280838, 51.92196463194254, 42.675300441293636, 47.65089538489062, 42.473318269352916, 57.215996888448416, 33.84762874551682, 43.011165583271975, 52.41999841492463, 62.03589570456025, 34.17880807157408, 73.77534374244917, 37.40769088357281, 36.75292892669951, 24.60533216549943, 42.470352455327685, 47.76312789772734, 56.20113313435379, 43.9069813626226, 52.24896202770623, 47.98619832730301, 1.4354742819314366, 1.4353965207558523, 1.4351515312456784, 1.4348255120061078, 1.434809473288563, 1.4345680563837189, 1.4345007089726067, 1.434409265478738, 1.4343172898947134, 1.4343065720787238, 1.434222121769756, 1.4341293100440586, 1.4339908145778666, 1.4339750799118394, 1.4338567278586773, 1.433783147391458, 1.4332634473352805, 1.432944877357887, 1.4329410007010397, 1.429805393414602, 1.3921678901133583, 1.3918432106440743, 1.384989057876419, 1.3868466759220637, 1.3874262828686215, 1.3816870728852348, 1.3829592171502734, 1.381242932403595, 1.3815525735874827, 1.380146323817765, 113.55188500798273, 2.0713159016966705, 2.0897936690510375, 123.53614200820064, 118.26905902260408, 46.87110134803547, 47.05867695853716, 43.643368838162544, 40.45778363818875, 104.45669152933114, 55.230113252389934, 28.824874330479705, 81.54585621847102, 73.77534374244917, 52.24896202770623, 24.120432144664562, 62.03589570456025, 28.474877853933684, 23.092807511446843, 27.722179026381106, 47.422634500144476, 33.516757299507056, 31.012066504663633, 51.92196463194254, 23.253901819976484, 58.68362808013039, 32.40178629609043, 21.105205064717204, 37.40769088357281, 51.086466369085755, 52.9169173941317, 26.935578154434396, 43.9069813626226, 34.59932604853514, 57.215996888448416, 47.76312789772734, 69.6717245010786, 47.65089538489062, 40.66572086785267, 47.98619832730301, 45.695971321686805, 52.93670447280838, 56.20113313435379, 1.394828474820716, 1.3948072342743527, 1.3949049105478117, 1.3944624582674399, 1.3946905095849949, 1.39475433768885, 1.3952173801792753, 1.3937613615001014, 1.3945340011857041, 1.3944305944627748, 1.393550755669954, 1.3945475145219666, 1.3956136379165938, 1.3946581138851624, 1.393875086736855, 1.3953753605692627, 1.3995834141539156, 1.4009449004360188, 1.3982341202847732, 1.3996475872639589, 1.401198635992901, 1.4018842320996974, 1.4019584706109205, 1.400961395240571, 1.4019065642651656, 1.4008137031169614, 1.4000713148173043, 1.3994653743391718, 1.4017770568177093, 2.029341953876017, 2.006814440868346, 2.657877834685428, 14.363376059405471, 42.473318269352916, 104.45669152933114, 56.20113313435379, 81.54585621847102, 42.675300441293636, 113.55188500798273, 58.68362808013039, 14.526786606907006, 27.430929398174477, 38.22149844991857, 47.98619832730301, 52.41999841492463, 62.03589570456025, 38.49827821235634, 46.56558814819854, 25.468629969880894, 50.15933788180389, 30.780414563240598, 46.87110134803547, 123.53614200820064, 55.230113252389934, 57.215996888448416, 47.422634500144476, 32.06631207432307, 73.77534374244917, 22.6716325331933, 43.643368838162544, 34.59932604853514, 42.470352455327685, 118.26905902260408, 69.6717245010786, 47.65089538489062, 51.92196463194254, 52.9169173941317, 46.88998243839169, 41.24889513858642, 51.086466369085755, 1.2844425183155406, 1.282840677252314, 1.2858404938254326, 1.287994635948078, 1.288667063514891, 1.2889769864095022, 1.2851166751032135, 1.285489654465629, 1.2849487074710932, 1.2861313151682454, 1.288600274195162, 1.2898761570820536, 1.291261492985571, 1.2815910935467612, 1.2896613671017985, 1.2905157604473358, 1.2922719844761754, 1.29207441731271, 1.28816466640072, 1.2870341127233105, 1.2886039466294832, 1.2910764847782197, 1.2858022160219633, 1.291619654984955, 1.295412231286893, 1.296631339927758, 1.290527450615725, 1.9284292077218677, 1.9624672056745098, 1.3176853846544576, 4.597182493413671, 55.230113252389934, 123.53614200820064, 57.215996888448416, 62.03589570456025, 118.26905902260408, 45.81867336365575, 45.695971321686805, 50.15933788180389, 43.9069813626226, 40.52855472479078, 47.05867695853716, 16.78252881831969, 30.31937883984179, 113.55188500798273, 27.22010967609889, 30.544263218370407, 36.49937062470521, 41.24889513858642, 47.76312789772734, 29.999217743327268, 34.54351821723516, 46.56558814819854, 33.19112050447564, 69.6717245010786, 81.54585621847102, 33.811518702370556, 73.77534374244917, 23.60809291814283, 47.65089538489062, 58.68362808013039, 52.41999841492463, 104.45669152933114, 51.086466369085755, 56.20113313435379, 52.93670447280838, 43.643368838162544, 52.9169173941317, 51.92196463194254, 52.24896202770623, 1.2100885879041325, 1.1740482633986336, 1.1668561874964167, 1.1762446103014594, 1.1779621792061445, 1.1679267292175173, 1.1667324138902453, 1.1668990476070875, 1.174988448865486, 1.1685831472028716, 1.18096527854208, 1.1770200018299533, 1.1750726864858867, 1.165240685225509, 1.1679172542068197, 1.1743358436571047, 1.1706182740908586, 1.1748930688926071, 1.1763607455584606, 1.1732225800986635, 1.183516515723055, 1.1734477142843944, 1.161003759093986, 1.1718989125373847, 1.162431861350702, 1.1678916610033214, 1.166398802823622, 1.1719847436008737, 1.170340134364461, 1.1700280101721243, 1.8432973609738292, 1.8410241375256322, 1.850925969075917, 1.8539002565926992, 1.8342217853518208, 1.8501490918303425, 1.8580298010325753, 62.03589570456025, 45.695971321686805, 104.45669152933114, 52.9169173941317, 43.011165583271975, 123.53614200820064, 47.65089538489062, 6.9317691725894095, 69.6717245010786, 30.46496040611863, 118.26905902260408, 8.097302354726645, 113.55188500798273, 52.24896202770623, 46.88998243839169, 29.228417105104114, 20.746500347599266, 9.892694566008846, 25.35104010526226, 73.77534374244917, 47.422634500144476, 58.68362808013039, 56.20113313435379, 45.81867336365575, 32.40178629609043, 41.45565099611742, 57.215996888448416, 51.086466369085755, 35.49021094340338, 42.470352455327685, 81.54585621847102, 28.437668707075538, 51.92196463194254, 36.49937062470521, 47.98619832730301, 47.05867695853716, 52.93670447280838, 43.9069813626226, 50.15933788180389, 52.41999841492463, 46.87110134803547], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.6741, -9.7068, -9.7171, -9.7189, -9.7172, -9.719, -9.7192, -9.7216, -9.7212, -9.7243, -9.7228, -9.734, -9.7377, -9.7428, -9.7511, -9.7517, -9.7509, -9.753, -9.756, -9.7558, -9.76, -9.759, -9.7633, -9.7777, -9.788, -9.7889, -9.7936, -9.7926, -9.795, -9.7985, -6.2522, -6.4065, -6.4643, -7.7161, -6.4177, -6.853, -6.7434, -7.0794, -7.1751, -6.8566, -7.3019, -7.2757, -7.0983, -7.12, -7.1854, -7.366, -7.3641, -7.6659, -8.3686, -7.8878, -7.2622, -7.6224, -7.7289, -7.5456, -7.1987, -7.2963, -8.3167, -7.5065, -7.5127, -7.3116, -7.3716, -7.3517, -7.4023, -7.4333, -7.4604, -7.3447, -7.4201, -7.4625, -7.5029, -7.4985, -9.3732, -9.3716, -9.3792, -9.383, -9.3827, -9.3818, -9.3884, -9.3923, -9.3935, -9.3948, -9.3967, -9.3951, -9.3971, -9.3964, -9.4086, -9.4076, -9.4061, -9.4098, -9.4086, -9.4146, -9.4131, -9.41, -9.4141, -9.4144, -9.4181, -9.4177, -9.4212, -9.4258, -9.424, -9.4258, -6.5442, -7.2438, -6.9438, -7.1728, -6.8535, -7.3039, -7.1984, -7.2356, -7.9393, -7.4003, -7.3042, -7.3456, -7.4229, -6.9516, -7.6069, -7.3749, -7.543, -6.9575, -7.5228, -7.5833, -8.0891, -7.4539, -7.7166, -7.8849, -7.5139, -7.247, -7.8639, -7.973, -7.7476, -7.8032, -7.5643, -7.4128, -7.7225, -7.5896, -7.6458, -7.6193, -7.6769, -7.6562, -7.678, -9.6858, -9.7119, -9.7227, -9.7218, -9.7316, -9.7346, -9.7394, -9.737, -9.7548, -9.7478, -9.7464, -9.7656, -9.7727, -9.7782, -9.7843, -9.7868, -9.7865, -9.7987, -9.7934, -9.7897, -9.793, -9.8065, -9.7997, -9.804, -9.8049, -9.808, -9.8024, -9.8265, -9.8278, -9.8269, -8.8229, -6.6963, -9.269, -6.3506, -7.0854, -6.8705, -6.5615, -7.3126, -7.1231, -7.4102, -6.8372, -7.2989, -7.2522, -7.2008, -7.7828, -8.2877, -7.4577, -8.0074, -7.876, -7.8799, -7.3155, -6.7194, -7.5943, -7.5904, -7.2472, -7.8245, -7.8084, -7.3945, -7.3532, -7.612, -7.9709, -7.3133, -7.2857, -6.9453, -7.3647, -7.4728, -7.4573, -7.4857, -7.5022, -7.4596, -7.4824, -7.4638, -7.5718, -9.3674, -9.3677, -9.3679, -9.368, -9.368, -9.3681, -9.3681, -9.3682, -9.3683, -9.3684, -9.3684, -9.3684, -9.3684, -9.3685, -9.3686, -9.3686, -9.3688, -9.369, -9.3691, -9.3692, -9.3692, -9.3694, -9.3694, -9.3694, -9.3695, -9.3696, -9.3696, -9.3696, -9.3697, -9.3697, -9.0274, -9.0607, -8.8485, -9.0607, -9.062, -9.0623, -9.0647, -9.0666, -9.0672, -9.0706, -9.0768, -9.0781, -9.08, -9.0819, -9.0837, -6.3828, -9.0863, -9.0891, -9.0894, -9.0893, -9.0933, -9.0936, -7.285, -9.0957, -9.0966, -9.0961, -7.5533, -9.098, -9.0991, -6.6404, -6.5517, -7.2245, -6.65, -7.6216, -7.3403, -7.2085, -6.8915, -7.6685, -7.237, -7.2389, -7.4958, -7.3189, -7.2138, -7.5191, -7.3178, -7.3761, -7.2572, -7.4967, -7.1092, -7.6481, -7.2723, -7.3433, -7.4772, -7.3012, -7.4257, -7.3678, -7.2929, -7.2744, -7.2973, -7.3359, -7.2375, -7.3897, -7.3869, -7.3561, -7.3818, -9.3589, -9.36, -9.36, -9.3603, -9.3604, -9.3608, -9.3609, -9.3611, -9.3613, -9.3617, -9.3622, -9.5202, -9.5248, -9.5539, -9.5561, -9.5583, -9.5359, -9.5677, -9.5745, -9.5761, -9.5766, -9.5765, -9.5457, -9.5809, -9.5505, -9.5516, -9.5868, -9.5878, -9.5882, -9.5572, -9.5631, -9.5648, -6.4054, -7.1139, -6.4497, -6.8332, -6.6572, -7.0256, -7.1394, -7.2265, -7.2827, -7.2271, -7.9598, -7.1615, -6.9397, -7.2, -7.081, -7.3599, -8.1474, -7.7607, -7.6311, -7.2924, -7.3571, -7.5161, -6.8942, -7.4538, -7.4785, -7.7941, -7.5757, -7.3466, -7.4937, -7.691, -7.4099, -7.5363, -7.4298, -7.3671, -7.5065, -7.4286, -7.418, -7.4528, -7.4528, -7.4833, -7.4866, -9.2782, -9.2785, -9.2785, -9.2786, -9.2787, -9.2789, -9.2794, -9.2795, -9.2795, -9.28, -9.28, -9.28, -9.2801, -9.281, -9.2811, -9.2811, -9.2811, -9.2812, -9.2813, -9.2816, -9.2817, -9.2818, -9.282, -9.2824, -9.2845, -9.7733, -9.7775, -9.7793, -9.786, -9.7882, -9.0565, -9.1059, -9.1478, -8.338, -6.5012, -7.1809, -6.611, -6.6209, -7.0896, -6.9037, -6.7743, -7.1562, -7.1821, -7.0511, -7.5193, -7.4079, -7.3116, -7.5012, -7.6806, -7.2899, -7.3044, -7.4235, -7.3818, -7.4395, -7.3064, -7.5709, -7.4563, -7.3648, -7.2828, -7.5778, -7.2076, -7.5661, -7.5815, -7.7764, -7.5237, -7.4739, -7.4218, -7.5117, -7.5198, -7.5579, -9.385, -9.3851, -9.3854, -9.3857, -9.3858, -9.386, -9.3861, -9.3862, -9.3863, -9.3863, -9.3864, -9.3865, -9.3867, -9.3867, -9.3868, -9.3869, -9.3875, -9.3879, -9.3879, -9.3915, -9.5024, -9.5048, -9.517, -9.5159, -9.5226, -9.5268, -9.5265, -9.5293, -9.53, -9.5313, -6.1472, -9.2228, -9.2301, -6.366, -6.4492, -7.0913, -7.0903, -7.1492, -7.2109, -6.6301, -7.093, -7.5343, -6.8874, -6.9733, -7.2065, -7.6733, -7.1159, -7.5917, -7.7303, -7.6235, -7.3143, -7.5241, -7.5774, -7.2791, -7.7495, -7.2296, -7.5749, -7.8297, -7.5074, -7.3348, -7.325, -7.7106, -7.4653, -7.5878, -7.3526, -7.4464, -7.3235, -7.503, -7.5512, -7.5263, -7.5398, -7.5391, -7.5509, -9.4803, -9.4813, -9.4836, -9.4879, -9.4907, -9.4936, -9.4991, -9.5032, -9.5044, -9.5103, -9.5125, -9.5119, -9.514, -9.5152, -9.5259, -9.5281, -9.6111, -9.6216, -9.6411, -9.6526, -9.6676, -9.6834, -9.6851, -9.6866, -9.6875, -9.6896, -9.6903, -9.6914, -9.69, -9.3211, -9.3391, -9.1751, -7.9061, -7.0943, -6.4361, -6.9799, -6.7133, -7.188, -6.4814, -6.9877, -7.996, -7.5521, -7.3355, -7.1841, -7.1255, -7.0165, -7.3389, -7.2228, -7.622, -7.1926, -7.5074, -7.2686, -6.6626, -7.1741, -7.1575, -7.2838, -7.5407, -7.0337, -7.7692, -7.3849, -7.5268, -7.438, -6.8349, -7.1569, -7.3794, -7.3744, -7.387, -7.4691, -7.4955, -7.4722, -9.4734, -9.4967, -9.5027, -9.5137, -9.5176, -9.5179, -9.522, -9.5234, -9.5251, -9.5331, -9.5345, -9.5366, -9.5362, -9.5468, -9.5464, -9.5474, -9.5464, -9.5548, -9.565, -9.5678, -9.5692, -9.5712, -9.5805, -9.5776, -9.58, -9.6042, -9.6164, -9.3704, -9.3706, -9.8609, -8.825, -6.8604, -6.3469, -6.9845, -6.9819, -6.5548, -7.2094, -7.2438, -7.1867, -7.283, -7.342, -7.2547, -7.9237, -7.5605, -6.7408, -7.6297, -7.5667, -7.4566, -7.3831, -7.2948, -7.5892, -7.5165, -7.3344, -7.5472, -7.1044, -7.0112, -7.547, -7.1015, -7.7753, -7.3619, -7.2418, -7.3152, -6.9507, -7.3372, -7.3232, -7.3612, -7.4469, -7.3879, -7.4292, -7.454, -9.5502, -9.6911, -9.6995, -9.7105, -9.7108, -9.7314, -9.7395, -9.7405, -9.7406, -9.7581, -9.7535, -9.7571, -9.7621, -9.7742, -9.7735, -9.7765, -9.7798, -9.7768, -9.7784, -9.7831, -9.7823, -9.7918, -9.8065, -9.7986, -9.8119, -9.8081, -9.8094, -9.8061, -9.8081, -9.8084, -9.3915, -9.4087, -9.4106, -9.4132, -9.4582, -9.4524, -9.453, -6.8642, -7.0951, -6.525, -7.0263, -7.2278, -6.5031, -7.2402, -8.5606, -7.0006, -7.5579, -6.6515, -8.4645, -6.6962, -7.2166, -7.3082, -7.6246, -7.8635, -8.349, -7.7621, -7.0915, -7.3745, -7.2414, -7.2746, -7.4104, -7.6266, -7.4857, -7.3025, -7.3753, -7.6004, -7.4931, -7.1188, -7.7347, -7.3883, -7.5962, -7.4499, -7.4702, -7.4282, -7.5128, -7.4846, -7.4852, -7.5469], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3312, 1.3035, 1.2957, 1.2949, 1.2942, 1.2941, 1.2938, 1.2936, 1.2913, 1.2906, 1.2899, 1.2801, 1.2785, 1.2743, 1.2682, 1.2671, 1.2666, 1.2659, 1.264, 1.263, 1.261, 1.2598, 1.2565, 1.2435, 1.237, 1.2338, 1.2317, 1.23, 1.2293, 1.2266, 0.2669, 0.2368, 0.0955, 0.5263, 0.0578, 0.1953, 0.1475, 0.2436, 0.2695, 0.1345, 0.2848, 0.2628, 0.1648, 0.1252, 0.1506, 0.2241, 0.2033, 0.3253, 0.6536, 0.4068, 0.0802, 0.253, 0.3049, 0.2027, 0.0212, 0.0622, 0.5735, 0.1363, 0.136, 0.0211, 0.0542, 0.0252, 0.0489, 0.0368, 0.0556, -0.1803, -0.0967, -0.0218, 0.0071, -0.0774, 1.8705, 1.8704, 1.8618, 1.8587, 1.8577, 1.8572, 1.852, 1.8473, 1.8463, 1.8434, 1.843, 1.8424, 1.8413, 1.841, 1.8331, 1.8315, 1.8301, 1.8267, 1.8253, 1.8242, 1.8238, 1.8233, 1.8221, 1.8209, 1.8182, 1.8182, 1.8156, 1.8114, 1.8103, 1.8086, -0.0251, 0.4188, 0.0472, 0.1695, -0.2102, 0.1404, -0.0341, -0.0157, 0.5699, 0.1097, 0.0187, -0.0096, 0.0445, -0.3918, 0.1829, -0.0421, 0.0997, -0.482, 0.0204, 0.0581, 0.5516, -0.0953, 0.1563, 0.3275, -0.0732, -0.3561, 0.2841, 0.3693, 0.1006, 0.1412, -0.1361, -0.3645, 0.038, -0.1566, -0.1298, -0.1935, -0.0851, -0.2116, -0.3012, 1.3479, 1.3247, 1.3197, 1.3171, 1.3065, 1.3063, 1.2993, 1.2985, 1.2913, 1.2906, 1.2855, 1.2768, 1.2686, 1.2578, 1.2577, 1.256, 1.2539, 1.2508, 1.2506, 1.2495, 1.2443, 1.242, 1.2408, 1.238, 1.2369, 1.2356, 1.2322, 1.2244, 1.2167, 1.2155, 0.9615, 0.3519, 1.0669, 0.1249, 0.2732, 0.1205, -0.0017, 0.2772, 0.1999, 0.3033, 0.0537, 0.2317, 0.1736, 0.132, 0.3888, 0.6046, 0.2302, 0.4626, 0.4007, 0.3942, 0.1127, -0.2002, 0.2269, 0.1939, 0.0159, 0.3048, 0.2807, 0.0497, 0.0237, 0.168, 0.3581, -0.0328, -0.0658, -0.302, -0.0414, 0.0372, -0.0244, -0.0645, -0.051, -0.1172, -0.1464, -0.2186, -0.0044, 1.7315, 1.7313, 1.7312, 1.7312, 1.7312, 1.7312, 1.7312, 1.7311, 1.7311, 1.731, 1.731, 1.731, 1.731, 1.731, 1.7309, 1.7309, 1.7308, 1.7307, 1.7307, 1.7306, 1.7306, 1.7305, 1.7305, 1.7305, 1.7305, 1.7305, 1.7304, 1.7304, 1.7304, 1.7304, 1.6479, 1.6241, 1.5437, 1.6113, 1.6076, 1.607, 1.6038, 1.6024, 1.6021, 1.5985, 1.5889, 1.5885, 1.588, 1.5845, 1.5849, 0.1363, 1.5799, 1.5806, 1.5776, 1.5769, 1.5768, 1.5726, 0.5011, 1.5706, 1.5701, 1.5695, 0.6231, 1.5676, 1.5668, 0.0029, -0.0762, 0.3479, -0.0902, 0.5498, 0.3476, 0.2427, -0.0006, 0.5544, 0.2304, 0.1823, 0.3619, 0.2117, 0.119, 0.3461, 0.1523, 0.1913, 0.0851, 0.2834, -0.0609, 0.3845, 0.0511, 0.101, 0.2175, 0.0573, 0.161, 0.058, -0.0297, -0.0545, -0.0521, -0.013, -0.2465, 0.051, 0.0412, -0.0756, -0.005, 1.6167, 1.6163, 1.6163, 1.6161, 1.6161, 1.6159, 1.6159, 1.6158, 1.6157, 1.6156, 1.6153, 1.4543, 1.4497, 1.4481, 1.4456, 1.4438, 1.4386, 1.4355, 1.4295, 1.4285, 1.4283, 1.4279, 1.4275, 1.4246, 1.423, 1.4229, 1.4197, 1.4182, 1.4174, 1.4167, 1.4105, 1.4097, 0.1137, 0.3304, 0.0258, 0.1578, -0.0139, 0.1387, 0.1966, 0.2408, 0.2605, 0.1941, 0.5597, 0.0837, -0.0488, 0.0631, -0.0327, 0.1101, 0.5892, 0.3482, 0.2598, 0.0309, 0.0687, 0.1787, -0.3344, 0.1137, 0.1082, 0.3624, 0.1725, -0.0236, 0.0964, 0.2534, 0.0231, 0.1264, 0.0214, -0.0865, 0.0659, -0.0518, -0.0852, -0.0942, -0.1105, -0.0551, -0.2667, 1.9203, 1.9201, 1.9201, 1.9201, 1.92, 1.9199, 1.9196, 1.9196, 1.9195, 1.9193, 1.9193, 1.9193, 1.9192, 1.9187, 1.9187, 1.9187, 1.9187, 1.9186, 1.9186, 1.9184, 1.9184, 1.9183, 1.9182, 1.918, 1.9169, 1.3753, 1.3709, 1.3666, 1.3606, 1.3578, 1.3425, 1.3353, 1.2995, 0.7973, -0.0257, 0.2521, -0.0512, -0.1018, 0.1303, -0.0128, -0.131, 0.1243, 0.1412, -0.0028, 0.3976, 0.1596, 0.0653, 0.2373, 0.4096, 0.033, 0.038, 0.115, 0.0464, 0.1037, -0.0612, 0.1993, 0.0743, -0.0321, -0.1185, 0.1826, -0.2165, 0.104, 0.1063, 0.3127, 0.0196, -0.048, -0.1587, -0.0017, -0.1838, -0.1367, 1.5456, 1.5455, 1.5454, 1.5453, 1.5453, 1.5452, 1.5451, 1.5451, 1.5451, 1.5451, 1.545, 1.545, 1.5449, 1.5449, 1.5449, 1.5448, 1.5446, 1.5444, 1.5444, 1.543, 1.4588, 1.4566, 1.4494, 1.4491, 1.4421, 1.4419, 1.4413, 1.4397, 1.4389, 1.4385, 0.4126, 1.3411, 1.3249, 0.1095, 0.0699, 0.3534, 0.3503, 0.3668, 0.3809, 0.0132, 0.1876, 0.3965, 0.0035, 0.0178, 0.1295, 0.4357, 0.0484, 0.3513, 0.4223, 0.3464, 0.1187, 0.256, 0.2803, 0.0632, 0.3961, -0.0097, 0.2389, 0.4128, 0.1628, 0.0237, -0.0016, 0.288, 0.0447, 0.1604, -0.1074, -0.0206, -0.2752, -0.0749, 0.0355, -0.1051, -0.0698, -0.2161, -0.2877, 1.479, 1.478, 1.4756, 1.4716, 1.4687, 1.4658, 1.46, 1.4568, 1.4551, 1.4493, 1.4477, 1.4476, 1.4447, 1.4442, 1.434, 1.4308, 1.3448, 1.3333, 1.3158, 1.3032, 1.2872, 1.2708, 1.2691, 1.2683, 1.2667, 1.2654, 1.2653, 1.2645, 1.2643, 1.2633, 1.2564, 1.1395, 0.7213, 0.4489, 0.2072, 0.2833, 0.1776, 0.3504, 0.0784, 0.2322, 0.6201, 0.4283, 0.3132, 0.2371, 0.2073, 0.1478, 0.3026, 0.2284, 0.4326, 0.1843, 0.3578, 0.176, -0.1871, 0.1064, 0.0878, 0.1492, 0.2835, -0.0426, 0.4017, 0.1311, 0.2214, 0.1053, -0.3158, -0.1086, 0.0488, -0.032, -0.0636, -0.0248, 0.0769, -0.1136, 1.5683, 1.5463, 1.538, 1.5252, 1.5208, 1.5203, 1.5192, 1.5176, 1.5162, 1.5074, 1.504, 1.5009, 1.5002, 1.4972, 1.4913, 1.4897, 1.4893, 1.4811, 1.4738, 1.472, 1.4693, 1.4653, 1.4601, 1.4585, 1.4532, 1.4281, 1.4206, 1.2649, 1.2472, 1.1553, 0.9416, 0.4202, 0.1286, 0.2607, 0.1824, -0.0357, 0.258, 0.2262, 0.1901, 0.227, 0.2481, 0.1859, 0.548, 0.3198, -0.181, 0.3584, 0.3062, 0.2382, 0.1893, 0.131, 0.3017, 0.2334, 0.1168, 0.2426, -0.0561, -0.1203, 0.2242, -0.1104, 0.3552, 0.0662, -0.0219, 0.0175, -0.3074, 0.0213, -0.0601, -0.0382, 0.0691, -0.0646, -0.0869, -0.1179, 1.5511, 1.4405, 1.4383, 1.4193, 1.4174, 1.4054, 1.3983, 1.3972, 1.3902, 1.3782, 1.3723, 1.372, 1.3686, 1.365, 1.3634, 1.3549, 1.3547, 1.3541, 1.3512, 1.3492, 1.3413, 1.3403, 1.3363, 1.3348, 1.3297, 1.3287, 1.3287, 1.3273, 1.3267, 1.3267, 1.289, 1.273, 1.2658, 1.2616, 1.2272, 1.2244, 1.2196, 0.3001, 0.375, 0.1183, 0.2971, 0.3028, -0.0275, 0.188, 0.7954, 0.0477, 0.3176, -0.1324, 0.736, -0.1364, 0.1195, 0.1361, 0.2923, 0.3961, 0.6513, 0.2972, -0.1005, 0.0585, -0.0215, -0.0114, 0.057, 0.1872, 0.0818, -0.0572, -0.0167, 0.1224, 0.0502, -0.2279, 0.2096, -0.0459, 0.0985, -0.0288, -0.0295, -0.1053, -0.0029, -0.1077, -0.1524, -0.1023]}, \"token.table\": {\"Topic\": [8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 4, 7, 4, 7, 4, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 7, 6, 1, 3, 4, 5, 7, 8, 9, 10, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 4, 7, 5, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 9, 7, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 7, 4, 7, 4, 8, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 4, 8, 4, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 8, 3, 7, 6, 4, 1, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 4, 7, 7, 4, 5, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 5, 6, 7, 6, 6, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 9, 9, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 4, 6, 4, 8, 9, 9, 5, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 8, 6, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 4, 9, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 3, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 8, 9, 10, 7, 4, 4, 6, 1, 1, 9, 8, 8, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 6, 1, 5, 6, 4, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 9, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 8, 9, 7, 4, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 5, 5, 8, 1, 3, 4, 5, 6, 7, 8, 9, 10, 8, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 4, 5, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 1, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"Freq\": [0.7138039473849171, 0.17068086240596325, 0.04267021560149081, 0.08534043120298163, 0.08534043120298163, 0.10667553900372703, 0.06400532340223622, 0.19201597020670866, 0.14934575460521785, 0.06400532340223622, 0.06400532340223622, 0.14428880198030256, 0.03607220049507564, 0.10821660148522691, 0.10821660148522691, 0.10821660148522691, 0.07214440099015128, 0.1803610024753782, 0.14428880198030256, 0.07214440099015128, 0.07214440099015128, 0.7589120226182041, 0.8252931604539339, 0.8253135524690054, 0.47851614004271237, 0.8247789621200398, 0.6967905327265499, 0.8245841381842446, 0.7171385969089877, 0.3843699585578831, 0.12987593815027315, 0.051950375260109254, 0.07792556289016389, 0.10390075052021851, 0.10390075052021851, 0.051950375260109254, 0.10390075052021851, 0.18182631341038238, 0.10390075052021851, 0.07792556289016389, 0.9118555640188005, 0.08777368695004457, 0.058515791300029714, 0.11703158260005943, 0.08777368695004457, 0.11703158260005943, 0.08777368695004457, 0.11703158260005943, 0.1462894782500743, 0.11703158260005943, 0.08777368695004457, 0.06883834856667703, 0.13767669713335406, 0.06883834856667703, 0.13767669713335406, 0.06883834856667703, 0.13767669713335406, 0.2065150457000311, 0.06883834856667703, 0.06883834856667703, 0.6973545366079466, 0.911184108144843, 0.18146674369925822, 0.18146674369925822, 0.09073337184962911, 0.09073337184962911, 0.18146674369925822, 0.09073337184962911, 0.09073337184962911, 0.09073337184962911, 0.727964729804206, 0.7758090412347397, 0.14451148536783967, 0.05780459414713587, 0.08670689122070381, 0.11560918829427173, 0.14451148536783967, 0.05780459414713587, 0.14451148536783967, 0.14451148536783967, 0.05780459414713587, 0.05780459414713587, 0.08600707165117043, 0.043003535825585214, 0.08600707165117043, 0.08600707165117043, 0.12901060747675566, 0.043003535825585214, 0.21501767912792608, 0.12901060747675566, 0.12901060747675566, 0.08600707165117043, 0.16583450810539477, 0.04145862702634869, 0.08291725405269738, 0.08291725405269738, 0.12437588107904608, 0.08291725405269738, 0.20729313513174347, 0.08291725405269738, 0.08291725405269738, 0.08291725405269738, 0.7293807745373339, 0.7170784713942052, 0.7295686730084678, 0.7719550393673345, 0.10332504540185225, 0.051662522700926125, 0.15498756810277836, 0.10332504540185225, 0.10332504540185225, 0.051662522700926125, 0.15498756810277836, 0.15498756810277836, 0.10332504540185225, 0.051662522700926125, 0.7748769695080014, 0.8249559214963328, 0.6969566472878201, 0.7293194808601593, 0.7269686661378971, 0.1398210366865976, 0.0349552591716494, 0.0873881479291235, 0.0873881479291235, 0.1223434071007729, 0.0699105183432988, 0.1223434071007729, 0.1398210366865976, 0.1223434071007729, 0.0699105183432988, 0.5348073033573677, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.12349792019514612, 0.14310231660355133, 0.057240926641420525, 0.11448185328284105, 0.08586138996213079, 0.11448185328284105, 0.08586138996213079, 0.11448185328284105, 0.11448185328284105, 0.11448185328284105, 0.057240926641420525, 0.7738309055777849, 0.7785478802986313, 0.697362188512704, 0.697287192302958, 0.49830217464814597, 0.1423458843948091, 0.03558647109870228, 0.10675941329610683, 0.08896617774675569, 0.12455264884545797, 0.053379706648053415, 0.08896617774675569, 0.16013911994416025, 0.08896617774675569, 0.07117294219740455, 0.5404969817922649, 0.7239856049506308, 0.8248512022013713, 0.6969488565908237, 0.40660407763317796, 0.71455858668329, 0.7274652713005809, 0.09821811639560823, 0.06547874426373883, 0.09821811639560823, 0.06547874426373883, 0.13095748852747766, 0.06547874426373883, 0.13095748852747766, 0.09821811639560823, 0.13095748852747766, 0.06547874426373883, 0.9118817718965567, 0.7299034583752739, 0.11166480499655496, 0.05583240249827748, 0.1395810062456937, 0.08374860374741622, 0.11166480499655496, 0.08374860374741622, 0.1395810062456937, 0.1395810062456937, 0.11166480499655496, 0.05583240249827748, 0.7790632177364476, 0.5448213388460733, 0.1299527656387379, 0.06497638281936895, 0.09746457422905341, 0.1299527656387379, 0.09746457422905341, 0.06497638281936895, 0.09746457422905341, 0.19492914845810683, 0.09746457422905341, 0.06497638281936895, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.10108469369265533, 0.20216938738531065, 0.534633954928166, 0.5364214593072719, 0.6971958067056455, 0.69745554048347, 0.13793045331010034, 0.0919536355400669, 0.13793045331010034, 0.0919536355400669, 0.0919536355400669, 0.04597681777003345, 0.13793045331010034, 0.1839072710801338, 0.04597681777003345, 0.0919536355400669, 0.7779136895626706, 0.8247558494314645, 0.7144655619739303, 0.8251313803973772, 0.7609309984221556, 0.15008697736901644, 0.06003479094760658, 0.12006958189521316, 0.15008697736901644, 0.09005218642140987, 0.06003479094760658, 0.12006958189521316, 0.12006958189521316, 0.09005218642140987, 0.06003479094760658, 0.37624001635814636, 0.1308164306156514, 0.052326572246260555, 0.10465314449252111, 0.07848985836939083, 0.10465314449252111, 0.07848985836939083, 0.1308164306156514, 0.18314300286191196, 0.07848985836939083, 0.07848985836939083, 0.9118485209084838, 0.9119200708670976, 0.10936559809743994, 0.03645519936581331, 0.10936559809743994, 0.07291039873162662, 0.14582079746325324, 0.07291039873162662, 0.10936559809743994, 0.18227599682906656, 0.07291039873162662, 0.07291039873162662, 0.7757334007584245, 0.5348591347104176, 0.7272028060887497, 0.727261300819052, 0.7573324369819904, 0.08128319449409085, 0.04064159724704543, 0.1219247917411363, 0.08128319449409085, 0.08128319449409085, 0.08128319449409085, 0.1219247917411363, 0.1625663889881817, 0.08128319449409085, 0.08128319449409085, 0.7138708007887788, 0.7132878904495922, 0.775945749560169, 0.4827848804621609, 0.9121066974172046, 0.5344603562955907, 0.7638824881202009, 0.7220273649910878, 0.8247654826133205, 0.13747792986029742, 0.045825976620099136, 0.06873896493014871, 0.09165195324019827, 0.09165195324019827, 0.06873896493014871, 0.18330390648039654, 0.13747792986029742, 0.11456494155024784, 0.06873896493014871, 0.7480496595031151, 0.8252810944303598, 0.1183028788268998, 0.02957571970672495, 0.08872715912017484, 0.0591514394134499, 0.1183028788268998, 0.0591514394134499, 0.1183028788268998, 0.14787859853362473, 0.1183028788268998, 0.08872715912017484, 0.12474150412834592, 0.06237075206417296, 0.12474150412834592, 0.09355612809625943, 0.12474150412834592, 0.06237075206417296, 0.09355612809625943, 0.1559268801604324, 0.09355612809625943, 0.09355612809625943, 0.11833833986863808, 0.03944611328954603, 0.07889222657909206, 0.11833833986863808, 0.11833833986863808, 0.07889222657909206, 0.11833833986863808, 0.11833833986863808, 0.07889222657909206, 0.11833833986863808, 0.7618360245779309, 0.7237528812597218, 0.7613042153329749, 0.13604357927424127, 0.054417431709696505, 0.13604357927424127, 0.13604357927424127, 0.10883486341939301, 0.08162614756454477, 0.10883486341939301, 0.10883486341939301, 0.08162614756454477, 0.054417431709696505, 0.9108589819196522, 0.535101166207233, 0.7183041694192317, 0.6978635506509046, 0.8250426703094842, 0.7501884705258969, 0.7579588678785133, 0.7581480587773938, 0.14708978276081877, 0.04902992758693959, 0.14708978276081877, 0.04902992758693959, 0.14708978276081877, 0.09805985517387918, 0.09805985517387918, 0.09805985517387918, 0.09805985517387918, 0.09805985517387918, 0.7565337108260999, 0.7595672328540001, 0.7512033620839303, 0.4093853115664277, 0.4093853115664277, 0.4296466293700692, 0.9120608775396993, 0.7760358429417401, 0.7760336312919376, 0.17213515094807247, 0.04918147169944928, 0.07377220754917392, 0.09836294339889856, 0.12295367924862319, 0.04918147169944928, 0.12295367924862319, 0.12295367924862319, 0.09836294339889856, 0.07377220754917392, 0.7552814384318036, 0.7795200274923276, 0.8244794766467284, 0.10492982261117018, 0.041971929044468066, 0.1259157871334042, 0.10492982261117018, 0.10492982261117018, 0.0629578935667021, 0.1259157871334042, 0.1259157871334042, 0.10492982261117018, 0.10492982261117018, 0.7499990692786983, 0.11137685565164343, 0.07425123710109563, 0.11137685565164343, 0.11137685565164343, 0.11137685565164343, 0.07425123710109563, 0.18562809275273906, 0.11137685565164343, 0.07425123710109563, 0.07425123710109563, 0.7763108121665878, 0.7516042102354257, 0.1289820528212293, 0.06449102641061465, 0.09673653961592196, 0.1289820528212293, 0.09673653961592196, 0.03224551320530732, 0.1612275660265366, 0.1289820528212293, 0.09673653961592196, 0.06449102641061465, 0.12206198790721605, 0.04068732930240535, 0.12206198790721605, 0.0813746586048107, 0.12206198790721605, 0.0813746586048107, 0.12206198790721605, 0.1627493172096214, 0.0813746586048107, 0.0813746586048107, 0.7745587322287373, 0.912137115443373, 0.911418605911961, 0.1249963108029392, 0.0624981554014696, 0.0624981554014696, 0.0624981554014696, 0.1874944662044088, 0.0624981554014696, 0.1249963108029392, 0.1249963108029392, 0.0624981554014696, 0.0624981554014696, 0.535745152066509, 0.6978654386403688, 0.7759956223855524, 0.7748839887498674, 0.8248371708099856, 0.518556759042942, 0.08694853155468847, 0.043474265777344236, 0.08694853155468847, 0.1304227973320327, 0.17389706310937694, 0.043474265777344236, 0.1304227973320327, 0.1304227973320327, 0.08694853155468847, 0.08694853155468847, 0.7169449479664114, 0.07055558762004034, 0.07055558762004034, 0.07055558762004034, 0.07055558762004034, 0.14111117524008068, 0.07055558762004034, 0.07055558762004034, 0.07055558762004034, 0.14111117524008068, 0.07055558762004034, 0.7279296862746072, 0.12991057923610777, 0.04330352641203593, 0.08660705282407186, 0.08660705282407186, 0.12991057923610777, 0.04330352641203593, 0.21651763206017963, 0.12991057923610777, 0.08660705282407186, 0.04330352641203593, 0.1511238767065544, 0.0566714537649579, 0.1322333921182351, 0.09445242294159649, 0.1133429075299158, 0.0755619383532772, 0.1133429075299158, 0.1133429075299158, 0.09445242294159649, 0.0755619383532772, 0.13665252799883246, 0.06832626399941623, 0.11387710666569371, 0.06832626399941623, 0.09110168533255497, 0.06832626399941623, 0.13665252799883246, 0.11387710666569371, 0.11387710666569371, 0.09110168533255497, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.11569978746908047, 0.10543488468538725, 0.0421739538741549, 0.10543488468538725, 0.06326093081123235, 0.1265218616224647, 0.0843479077483098, 0.14760883855954215, 0.14760883855954215, 0.0843479077483098, 0.0843479077483098, 0.7291892750578861, 0.5366193232738803, 0.9112126327495106, 0.8246433812876296, 0.7167341908194315, 0.7744364758278859, 0.7752682259529404, 0.7296792296677101, 0.7609059877932165, 0.7174829404968601, 0.11779196617752069, 0.03926398872584023, 0.11779196617752069, 0.07852797745168046, 0.07852797745168046, 0.07852797745168046, 0.1570559549033609, 0.19631994362920116, 0.07852797745168046, 0.07852797745168046, 0.1368531174854996, 0.0342132793713749, 0.10263983811412472, 0.10263983811412472, 0.1368531174854996, 0.10263983811412472, 0.10263983811412472, 0.10263983811412472, 0.0684265587427498, 0.10263983811412472, 0.9106305547178719, 0.777525582501803, 0.11817666844770645, 0.029544167111926613, 0.08863250133577985, 0.08863250133577985, 0.11817666844770645, 0.08863250133577985, 0.11817666844770645, 0.11817666844770645, 0.11817666844770645, 0.08863250133577985, 0.20664949734208127, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.10332474867104063, 0.7507401854622239, 0.756334832098535, 0.5394033451604939, 0.1277606378973584, 0.0638803189486792, 0.1277606378973584, 0.09582047842301879, 0.09582047842301879, 0.0638803189486792, 0.09582047842301879, 0.1277606378973584, 0.09582047842301879, 0.09582047842301879, 0.7737670912688469, 0.7230871218752211, 0.7210602421750311, 0.0898869718136926, 0.059924647875795066, 0.11984929575159013, 0.11984929575159013, 0.14981161968948767, 0.059924647875795066, 0.14981161968948767, 0.11984929575159013, 0.059924647875795066, 0.059924647875795066, 0.11917155165655453, 0.05958577582827727, 0.05958577582827727, 0.05958577582827727, 0.05958577582827727, 0.05958577582827727, 0.11917155165655453, 0.11917155165655453, 0.17875732748483178, 0.05958577582827727, 0.7142493310281771, 0.12932142798438312, 0.08621428532292208, 0.08621428532292208, 0.12932142798438312, 0.08621428532292208, 0.04310714266146104, 0.17242857064584416, 0.12932142798438312, 0.08621428532292208, 0.08621428532292208, 0.8251164962988343, 0.7174244015947367, 0.08869837756896093, 0.044349188784480464, 0.08869837756896093, 0.17739675513792186, 0.1330475663534414, 0.044349188784480464, 0.1330475663534414, 0.1330475663534414, 0.08869837756896093, 0.08869837756896093, 0.7287155821612175, 0.716972138374583, 0.7166530442332278, 0.9132730142223333, 0.7144983213483749, 0.6972420692870444, 0.10692988274655994, 0.05346494137327997, 0.10692988274655994, 0.08019741205991995, 0.13366235343319993, 0.08019741205991995, 0.1603948241198399, 0.13366235343319993, 0.08019741205991995, 0.08019741205991995, 0.11270713511336528, 0.02817678377834132, 0.11270713511336528, 0.11270713511336528, 0.11270713511336528, 0.05635356755668264, 0.1408839188917066, 0.11270713511336528, 0.08453035133502396, 0.08453035133502396, 0.7626084153436228, 0.153831318604408, 0.038457829651102, 0.115373488953306, 0.076915659302204, 0.115373488953306, 0.038457829651102, 0.153831318604408, 0.115373488953306, 0.076915659302204, 0.076915659302204, 0.9113970717143993, 0.1466990173897476, 0.0488996724632492, 0.1466990173897476, 0.0977993449264984, 0.0977993449264984, 0.0488996724632492, 0.1466990173897476, 0.0977993449264984, 0.0488996724632492, 0.0977993449264984, 0.07681736658324226, 0.03840868329162113, 0.1152260498748634, 0.15363473316648452, 0.15363473316648452, 0.07681736658324226, 0.1152260498748634, 0.1152260498748634, 0.07681736658324226, 0.07681736658324226, 0.12561991360464253, 0.04187330453488085, 0.12561991360464253, 0.10468326133720211, 0.12561991360464253, 0.06280995680232127, 0.12561991360464253, 0.10468326133720211, 0.10468326133720211, 0.06280995680232127, 0.14214502966451978, 0.04738167655483993, 0.04738167655483993, 0.04738167655483993, 0.09476335310967986, 0.04738167655483993, 0.18952670621935971, 0.14214502966451978, 0.09476335310967986, 0.04738167655483993, 0.7608793980664481, 0.7608479245375374, 0.7777014371548959, 0.763777635012268, 0.1193432874265205, 0.029835821856630126, 0.1193432874265205, 0.1193432874265205, 0.1193432874265205, 0.05967164371326025, 0.17901493113978076, 0.08950746556989038, 0.08950746556989038, 0.08950746556989038, 0.5431759310575999, 0.5382044999731777, 0.12692056700152582, 0.04230685566717528, 0.12692056700152582, 0.08461371133435056, 0.12692056700152582, 0.04230685566717528, 0.12692056700152582, 0.12692056700152582, 0.08461371133435056, 0.08461371133435056, 0.10912581340615803, 0.06547548804369481, 0.06547548804369481, 0.10912581340615803, 0.15277613876862123, 0.04365032536246321, 0.10912581340615803, 0.10912581340615803, 0.13095097608738962, 0.08730065072492642, 0.09053032314366363, 0.036212129257465454, 0.10863638777239636, 0.09053032314366363, 0.10863638777239636, 0.07242425851493091, 0.16295458165859453, 0.14484851702986182, 0.14484851702986182, 0.05431819388619818, 0.7151878111773825, 0.5425060661247254, 0.12503595219349023, 0.04167865073116341, 0.10419662682790853, 0.10419662682790853, 0.14587527755907195, 0.06251797609674511, 0.12503595219349023, 0.16671460292465365, 0.08335730146232682, 0.08335730146232682, 0.08471671163505964, 0.08471671163505964, 0.12707506745258948, 0.12707506745258948, 0.08471671163505964, 0.08471671163505964, 0.08471671163505964, 0.12707506745258948, 0.12707506745258948, 0.04235835581752982, 0.11772096468402857, 0.04708838587361143, 0.09417677174722286, 0.07063257881041714, 0.11772096468402857, 0.07063257881041714, 0.11772096468402857, 0.18835354349444572, 0.09417677174722286, 0.07063257881041714, 0.717004950652142, 0.7245608547025629, 0.5451903406589355, 0.16582390665294974, 0.041455976663237436, 0.12436792998971231, 0.08291195332647487, 0.16582390665294974, 0.041455976663237436, 0.12436792998971231, 0.12436792998971231, 0.08291195332647487, 0.08291195332647487, 0.16412297713000776, 0.03282459542600155, 0.09847378627800465, 0.09847378627800465, 0.1312983817040062, 0.0656491908520031, 0.09847378627800465, 0.09847378627800465, 0.09847378627800465, 0.09847378627800465, 0.0776559627862029, 0.0776559627862029, 0.0776559627862029, 0.0776559627862029, 0.2329678883586087, 0.0776559627862029, 0.1553119255724058, 0.0776559627862029, 0.0776559627862029, 0.0776559627862029, 0.7571060070910622, 0.9118367280371427, 0.5364604625942321, 0.7782411812904964, 0.7169340302781922, 0.7626867530649636, 0.13876903517911823, 0.06938451758955912, 0.10407677638433867, 0.06938451758955912, 0.10407677638433867, 0.06938451758955912, 0.20815355276867734, 0.13876903517911823, 0.10407677638433867, 0.03469225879477956, 0.7658545421248689, 0.9119594215774638, 0.5397054449900204, 0.14090475027231117, 0.03522618756807779, 0.10567856270423337, 0.08806546892019447, 0.07925892202817503, 0.06164582824413613, 0.19374403162442783, 0.14090475027231117, 0.07925892202817503, 0.07045237513615558, 0.11961880386336991, 0.039872934621123304, 0.11961880386336991, 0.09968233655280825, 0.11961880386336991, 0.07974586924224661, 0.09968233655280825, 0.15949173848449322, 0.11961880386336991, 0.07974586924224661, 0.15311308951473168, 0.05741740856802438, 0.0956956809467073, 0.07655654475736584, 0.13397395332539022, 0.05741740856802438, 0.15311308951473168, 0.0956956809467073, 0.0956956809467073, 0.0956956809467073, 0.7297367352780206, 0.13003917455686184, 0.052015669822744734, 0.10403133964548947, 0.07802350473411711, 0.10403133964548947, 0.052015669822744734, 0.13003917455686184, 0.13003917455686184, 0.07802350473411711, 0.07802350473411711, 0.18949835027383155, 0.04737458756845789, 0.04737458756845789, 0.09474917513691578, 0.14212376270537366, 0.04737458756845789, 0.14212376270537366, 0.14212376270537366, 0.09474917513691578, 0.04737458756845789, 0.7656388406720038, 0.7184717304021987, 0.7503470445163022, 0.8252038655664443, 0.09292436575575903, 0.04646218287787952, 0.09292436575575903, 0.13938654863363856, 0.09292436575575903, 0.04646218287787952, 0.13938654863363856, 0.13938654863363856, 0.13938654863363856, 0.04646218287787952, 0.7481720110853298, 0.7133143003179873, 0.12750039711670025, 0.042500132372233414, 0.08500026474446683, 0.10625033093058354, 0.10625033093058354, 0.06375019855835012, 0.19125059567505037, 0.10625033093058354, 0.12750039711670025, 0.08500026474446683, 0.8245660886709852, 0.75988766435349, 0.1554577387499501, 0.031091547749990015, 0.12436619099996006, 0.09327464324997005, 0.12436619099996006, 0.06218309549998003, 0.1554577387499501, 0.09327464324997005, 0.09327464324997005, 0.06218309549998003, 0.7509169448926838, 0.15317352833740905, 0.047866727605440335, 0.07658676416870452, 0.09573345521088067, 0.1148801462530568, 0.0574400731265284, 0.13402683729523293, 0.15317352833740905, 0.07658676416870452, 0.09573345521088067, 0.697073934938169, 0.217524538439074, 0.217524538439074, 0.217524538439074, 0.217524538439074, 0.061859669512349405, 0.12371933902469881, 0.061859669512349405, 0.061859669512349405, 0.12371933902469881, 0.061859669512349405, 0.1855790085370482, 0.12371933902469881, 0.12371933902469881, 0.061859669512349405, 0.7171222101184834, 0.13481770286661265, 0.057779015514262566, 0.09629835919043761, 0.09629835919043761, 0.09629835919043761, 0.07703868735235009, 0.13481770286661265, 0.11555803102852513, 0.09629835919043761, 0.07703868735235009, 0.49277057426916787, 0.6966716064446214, 0.09640180109853733, 0.04820090054926866, 0.09640180109853733, 0.09640180109853733, 0.09640180109853733, 0.04820090054926866, 0.09640180109853733, 0.144602701647806, 0.09640180109853733, 0.09640180109853733, 0.7723279740027423, 0.6971511018971613, 0.11928369511240428, 0.05112158361960183, 0.10224316723920367, 0.08520263936600306, 0.08520263936600306, 0.08520263936600306, 0.1363242229856049, 0.1533647508588055, 0.10224316723920367, 0.08520263936600306, 0.7561085432001549, 0.8253076108066243, 0.13241160058367885, 0.04413720019455962, 0.17654880077823848, 0.08827440038911924, 0.13241160058367885, 0.04413720019455962, 0.08827440038911924, 0.13241160058367885, 0.08827440038911924, 0.08827440038911924, 0.6974197495264403, 0.7739492297044515, 0.1323239513346792, 0.0441079837782264, 0.1323239513346792, 0.0882159675564528, 0.1323239513346792, 0.0441079837782264, 0.0882159675564528, 0.1764319351129056, 0.0441079837782264, 0.0882159675564528, 0.14426331505012352, 0.14426331505012352, 0.14426331505012352, 0.14426331505012352, 0.14426331505012352, 0.14426331505012352, 0.14426331505012352, 0.6977084372445256, 0.8247925153291565, 0.8253162665901631, 0.9107531852921248, 0.7544335575807875, 0.7650443143798414, 0.7764007489549143, 0.7165306878863871, 0.7175913729236556, 0.7491502498973992, 0.5363315971151469, 0.16491103021641226, 0.032982206043282454, 0.13192882417312982, 0.06596441208656491, 0.09894661812984736, 0.06596441208656491, 0.09894661812984736, 0.13192882417312982, 0.13192882417312982, 0.06596441208656491, 0.8246031770667173, 0.5348027016225386, 0.4270680682269671, 0.1811067929791197, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.09055339648955985, 0.7742217270699927, 0.9107973704528415, 0.7563289657110248, 0.7497356322270832, 0.9122419551772368, 0.534544725681868, 0.5363378813716109, 0.11021263454475366, 0.03673754484825122, 0.11021263454475366, 0.11021263454475366, 0.11021263454475366, 0.03673754484825122, 0.1469501793930049, 0.1469501793930049, 0.1469501793930049, 0.07347508969650245, 0.8246671468281923, 0.7482514119275362, 0.7781394634224053, 0.12951675307245616, 0.03237918826811404, 0.12142195600542764, 0.08904276773731361, 0.12142195600542764, 0.06475837653622808, 0.14570634720651318, 0.10523236187137062, 0.11332715893839913, 0.0809479706702851, 0.7802800792197556, 0.6966338669993417, 0.5349731738330649, 0.16065063979555835, 0.05073178098807106, 0.08455296831345177, 0.1099188588074873, 0.12682945247017766, 0.05918707781941624, 0.143740046132868, 0.09300826514479694, 0.09300826514479694, 0.06764237465076141, 0.7761534448880681, 0.14804376915838746, 0.049347923052795825, 0.09869584610559165, 0.07402188457919373, 0.12336980763198956, 0.07402188457919373, 0.07402188457919373, 0.12336980763198956, 0.12336980763198956, 0.07402188457919373, 0.08826140627913903, 0.044130703139569516, 0.08826140627913903, 0.17652281255827806, 0.13239210941870855, 0.08826140627913903, 0.13239210941870855, 0.13239210941870855, 0.08826140627913903, 0.044130703139569516, 0.8252323204840945, 0.1370225912559094, 0.058723967681104036, 0.1370225912559094, 0.09787327946850673, 0.09787327946850673, 0.03914931178740269, 0.1370225912559094, 0.11744793536220807, 0.09787327946850673, 0.07829862357480538, 0.8247240944901979, 0.7170216055419164, 0.19963820144502836, 0.04990955036125709, 0.09981910072251418, 0.04990955036125709, 0.09981910072251418, 0.09981910072251418, 0.09981910072251418, 0.09981910072251418, 0.09981910072251418, 0.09981910072251418, 0.22143708401140685, 0.22143708401140685, 0.22143708401140685, 0.5360857473536673, 0.11896698479880022, 0.05948349239940011, 0.1784504771982003, 0.05948349239940011, 0.11896698479880022, 0.05948349239940011, 0.11896698479880022, 0.11896698479880022, 0.11896698479880022, 0.11896698479880022, 0.5402701224724047, 0.9124081155150198, 0.5352062603766122, 0.1047027490780356, 0.1047027490780356, 0.1047027490780356, 0.0523513745390178, 0.1047027490780356, 0.0523513745390178, 0.2094054981560712, 0.1047027490780356, 0.1047027490780356, 0.0523513745390178, 0.7301486516923652, 0.7769801826651213, 0.509562655166151, 0.7508276080070975, 0.10000260759023594, 0.0666684050601573, 0.10000260759023594, 0.0666684050601573, 0.16667101265039322, 0.0666684050601573, 0.1333368101203146, 0.10000260759023594, 0.1333368101203146, 0.10000260759023594, 0.7279309320082001, 0.7137955431157912, 0.7753973450001513, 0.7207590142608624, 0.534890101441909, 0.7745474507436167, 0.5360422370153775, 0.14047470266663206, 0.035118675666658015, 0.10535602699997404, 0.035118675666658015, 0.10535602699997404, 0.035118675666658015, 0.17559337833329006, 0.14047470266663206, 0.07023735133331603, 0.07023735133331603, 0.9111392313041569, 0.5368456116854785, 0.085306067351498, 0.0639795505136235, 0.1066325841893725, 0.1066325841893725, 0.170612134702996, 0.0639795505136235, 0.1066325841893725, 0.127959101027247, 0.085306067351498, 0.085306067351498, 0.5344775810490323, 0.5348038629155232, 0.7278761526571241, 0.7278850188935865, 0.7170854200397759, 0.1392430297534648, 0.0696215148767324, 0.0696215148767324, 0.0696215148767324, 0.0696215148767324, 0.0696215148767324, 0.2784860595069296, 0.0696215148767324, 0.0696215148767324, 0.7168947448950314, 0.9114490762491841, 0.9109244266747412, 0.12333501361411692, 0.04933400544564676, 0.1480020163369403, 0.09866801089129353, 0.09866801089129353, 0.07400100816847015, 0.12333501361411692, 0.12333501361411692, 0.09866801089129353, 0.07400100816847015, 0.5366742866982137, 0.6971066613945438, 0.8248292943895574, 0.12344998400543851, 0.061724992002719255, 0.061724992002719255, 0.09258748800407889, 0.12344998400543851, 0.061724992002719255, 0.15431248000679815, 0.12344998400543851, 0.09258748800407889, 0.09258748800407889, 0.8250855200322278, 0.7777245890070223, 0.1447329822552283, 0.048244327418409436, 0.09648865483681887, 0.12061081854602358, 0.12061081854602358, 0.07236649112761415, 0.09648865483681887, 0.12061081854602358, 0.07236649112761415, 0.09648865483681887, 0.12121536790746021, 0.048486147162984085, 0.09697229432596817, 0.12121536790746021, 0.12121536790746021, 0.048486147162984085, 0.09697229432596817, 0.14545844148895226, 0.12121536790746021, 0.07272922074447613, 0.1471564657785992, 0.0367891164446498, 0.11036734933394939, 0.09810431051906612, 0.11036734933394939, 0.06131519407441633, 0.13489342696371592, 0.1471564657785992, 0.08584127170418286, 0.06131519407441633, 0.1842509096758801, 0.036850181935176016, 0.11055054580552806, 0.11055054580552806, 0.11055054580552806, 0.07370036387035203, 0.14740072774070406, 0.11055054580552806, 0.11055054580552806, 0.07370036387035203, 0.537888858809427, 0.8252134725485979, 0.729171294284888, 0.7656606176010675, 0.132654684586932, 0.0795928107521592, 0.1061237476695456, 0.0795928107521592, 0.132654684586932, 0.0530618738347728, 0.1061237476695456, 0.1061237476695456, 0.1061237476695456, 0.0795928107521592, 0.1640293079981842, 0.046865516570909774, 0.09373103314181955, 0.09373103314181955, 0.11716379142727443, 0.07029827485636465, 0.07029827485636465, 0.1874620662836391, 0.09373103314181955, 0.07029827485636465, 0.6972010164819308, 0.8243503611448699, 0.6993958790516529, 0.1313026034124909, 0.043767534470830295, 0.06565130170624545, 0.10941883617707575, 0.1313026034124909, 0.043767534470830295, 0.1313026034124909, 0.10941883617707575, 0.1313026034124909, 0.10941883617707575, 0.09886849056714851, 0.049434245283574256, 0.09886849056714851, 0.07415136792536138, 0.12358561320893564, 0.049434245283574256, 0.19773698113429702, 0.12358561320893564, 0.09886849056714851, 0.07415136792536138, 0.7616504652179747, 0.11579596423401477, 0.057897982117007384, 0.11579596423401477, 0.08684697317551107, 0.11579596423401477, 0.08684697317551107, 0.11579596423401477, 0.14474495529251846, 0.11579596423401477, 0.057897982117007384, 0.8252146826041965, 0.9107605382944367, 0.7565588375167112, 0.7133256634909375, 0.7133802020345398, 0.11624888403267579, 0.046499553613070316, 0.13949866083921095, 0.11624888403267579, 0.09299910722614063, 0.06974933041960547, 0.11624888403267579, 0.09299910722614063, 0.09299910722614063, 0.11624888403267579, 0.9113813962440108, 0.7295364124591703, 0.7712292377999402, 0.09671819729297373, 0.04835909864648687, 0.06447879819531582, 0.06447879819531582, 0.12895759639063165, 0.06447879819531582, 0.12895759639063165, 0.14507729593946062, 0.11283789684180269, 0.11283789684180269, 0.08219319809228162, 0.054795465394854415, 0.08219319809228162, 0.10959093078970883, 0.13698866348713604, 0.054795465394854415, 0.10959093078970883, 0.13698866348713604, 0.13698866348713604, 0.08219319809228162, 0.1578832744383944, 0.043059074846834834, 0.1578832744383944, 0.08611814969366967, 0.11482419959155957, 0.07176512474472473, 0.10047117464261462, 0.11482419959155957, 0.10047117464261462, 0.08611814969366967, 0.7238233413031082, 0.7762982684458462, 0.7709844085592422, 0.77794255338211, 0.1133852895343707, 0.0377950965114569, 0.09448774127864225, 0.09448774127864225, 0.1133852895343707, 0.0755901930229138, 0.13228283779009914, 0.1133852895343707, 0.09448774127864225, 0.1133852895343707, 0.1406585061948051, 0.07032925309740255, 0.10549387964610384, 0.07032925309740255, 0.1406585061948051, 0.07032925309740255, 0.10549387964610384, 0.10549387964610384, 0.07032925309740255, 0.10549387964610384, 0.09038561984056749, 0.06025707989371166, 0.09038561984056749, 0.09038561984056749, 0.12051415978742332, 0.06025707989371166, 0.12051415978742332, 0.15064269973427916, 0.12051415978742332, 0.09038561984056749, 0.12885051469562764, 0.04295017156520921, 0.10737542891302303, 0.10737542891302303, 0.12885051469562764, 0.04295017156520921, 0.10737542891302303, 0.15032560047823224, 0.10737542891302303, 0.06442525734781382, 0.13353682204627867, 0.057230066591262285, 0.11446013318252457, 0.09538344431877048, 0.11446013318252457, 0.057230066591262285, 0.09538344431877048, 0.15261351091003278, 0.09538344431877048, 0.07630675545501639, 0.7136746884508575, 0.8246436376112684, 0.14910130460931725, 0.054218656221569905, 0.12199197649853229, 0.06777332027696238, 0.13554664055392476, 0.054218656221569905, 0.13554664055392476, 0.12199197649853229, 0.09488264838774733, 0.06777332027696238, 0.11772918544199122, 0.04709167417679649, 0.09418334835359297, 0.09418334835359297, 0.14127502253038945, 0.07063751126519473, 0.11772918544199122, 0.14127502253038945, 0.09418334835359297, 0.09418334835359297], \"Term\": [\"000 high\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"10\", \"120 euros\", \"123 yards\", \"13 passing\", \"15 p\", \"15 passes\", \"171 passengers\", \"1915\", \"1949 ), earned\", \"1971\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"20 percent reduction\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2013\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"2015\", \"215 passengers\", \"22 percent statewide\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28\", \"28 hours\", \"29 depending\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"3\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"30\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"4\", \"52 e\", \"53 years\", \"6 million contract\", \"626\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7\", \"7256\", \"73 yards\", \"9 team searched\", \"90 saves\", \"abu dhabi\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"according\", \"active medium appears\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"added\", \"additional option\", \"air plant\", \"aircraft\", \"airline said\", \"al\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also adding engineers\", \"american team\", \"american telephone\", \"another departing\", \"ap\", \"april 2016\", \"architectural prowess\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"asked\", \"authorized cities\", \"avoided salary arbitration\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"baseball cards\", \"baylor\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"begin\", \"beverages\", \"blender\", \"boeing 757 aircraft\", \"boeing 777 aircraft\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"born\", \"bowl\", \"bryce petty\", \"build 100 high\", \"build houses\", \"bulgari hotel milan\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"ca\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"californians\", \"californias water\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"called\", \"career record\", \"carroll gardens\", \"catalan\", \"catalan art\", \"certifiable trend\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"chargers\", \"charging connectors\", \"charlie williams\", \"cincinnati\", \"closest\", \"cloudy liquid runoff\", \"collaborate\", \"collegiate bowl\", \"colorado state\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"confront\", \"cornhuskers\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"create one course\", \"created health problems\", \"danny bowien\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"december 2013 levels\", \"delicious ingredient\", \"denver last weekend\", \"designation\", \"development company planning\", \"developmental life transitions\", \"di pinto\", \"di pinto said\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"different well\", \"dinners take place\", \"disappointment often leads\", \"downtown san francisco\", \"downtown san francisco\", \"drought\", \"drought emergency\", \"easily removed\", \"elevating\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enjoyable\", \"entire plant\", \"european edition\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"every subject\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expected\", \"expendable\", \"extra coaches\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fans seeking autographs\", \"finally meet gov\", \"fine people\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"first time\", \"fizz\", \"flight 468\", \"flora grubb gardens\", \"floragrubb\", \"following concerns\", \"fore\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"found\", \"four sons\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"full 28 hours\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going\", \"going 29\", \"gonzalez admits\", \"governor called\", \"grayson completed 8\", \"greene -- marshall\", \"grubb\", \"grubb said\", \"guaranteed\", \"guest cooking stints\", \"harry\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"historical average\", \"hold plants\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hope\", \"hotels gardens\", \"hotels il ristorante\", \"hugely popular ride\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"immediate survivors include\", \"implosion\", \"inactive\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infrastructure deployment\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"interception\", \"interment\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"janssen\", \"january 12\", \"january 15\", \"jerry browns call\", \"jones said\", \"kennedy international airport\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"known chef\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"lawn watering\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"led\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"likely\", \"lima\", \"lineup began\", \"little tricky\", \"locals\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long toyed\", \"longtime pet project\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"los angeles\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"made\", \"major automakers tesla\", \"major investment\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"making\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"marlene levenson\", \"marvin kloss\", \"match made\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"meal inspired\", \"measurable rainfall\", \"mesh sieve\", \"minimalist appeal\", \"minna seidman greene\", \"mission chinese food\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"month food festival\", \"monthly water consumption\", \"mozzarella\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"mutual option\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"narisawa\", \"national team beat\", \"navigating relationship heartaches\", \"nebraska rushed\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never strengthen\", \"new charging locations\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"new york\", \"next two months\", \"noma\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"often outsourced\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one arriving\", \"online\", \"online\", \"online\", \"online\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"paramus\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"passed away\", \"passengers exited\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"past\", \"paul eggermann said\", \"pentangelo said\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peru\", \"petty\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plane\", \"plant come\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"plenty\", \"port authority\", \"possibly broadcasting\", \"president carried\", \"previously came\", \"profile chefs\", \"prolific chefs\", \"pronged cradle\", \"psychiatrist\", \"psychoanalyst\", \"psychologist\", \"pulse\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"quickly collapse candlestick\", \"quite dry\", \"reaching\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"ready\", \"really lets\", \"recorded history\", \"ren redzepi\", \"research results\", \"restrictions loom\", \"rich fluid\", \"ricotta\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rolfe\", \"roommate conflicts\", \"root structure\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said flora grubb\", \"said joe pentangelo\", \"salvaging\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco\", \"san francisco giant\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"says\", \"scrap\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"senior bowl\", \"september 26\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"settling\", \"settling\", \"settling\", \"several menu items\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"sharing app similar\", \"sierra nevada snowpack\", \"simple syrup\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since 2006\", \"sitting around\", \"soil\", \"solving\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"something\", \"sounds like fun\", \"speed chargers\", \"spindly steel base\", \"stadium might\", \"stalk\", \"stand really allows\", \"star anise\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state adapts\", \"stems\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stir\", \"strained yogurt\", \"striking facade\", \"stronger olympic stadiums\", \"stuyvesant high school\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"suny syracuse\", \"supplies\", \"survey released tuesday\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tarragon\", \"tel aviv\", \"telegraph company\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"theodore vail\", \"thigmotrope perch\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"though\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"tonjes farm dairy\", \"top passers\", \"toronto blue jays\", \"try cuisine thats\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"trying\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two aircraft\", \"two conversations\", \"unfounded\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"united states\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"upped\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using explosives\", \"violating restrictions\", \"visiting chefs\", \"volkswagen announced\", \"vw\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"washing cars\", \"washington nationals completed\", \"watering\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"west shrine classic\", \"whole stand\", \"williams continued\", \"williamss cards\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"worked\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"working\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would help open\", \"would return\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\", \"years\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el5428239924138649677659185\", ldavis_el5428239924138649677659185_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el5428239924138649677659185\", ldavis_el5428239924138649677659185_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el5428239924138649677659185\", ldavis_el5428239924138649677659185_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(NY_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Validating Our LDA Model: What Value of `K` Is Best?\n",
    "\n",
    "There are many other approaches to evaluate topic models, but most approaches are rather poor. One way is just human inspection, to see if these topics make sense. Hence, topic visualization is a good way to assess topic models. \n",
    "\n",
    "However, can we find some sort of quantifiable metric? One measure that is commonly used is perplexity, a measure of entropy.\n",
    "\n",
    "Perplexity is one of the intrinsic evaluation metrics, and is widely used for language model evaluation. It captures how surprised a model is of new data it has not seen before, and is measured as the normalized log-likelihood of a held-out test set. \n",
    "\n",
    "Focusing on the log-likelihood part, you can think of the perplexity metric as measuring how probable some new unseen data is given the model that was learned earlier. That is to say, how well does the model represent or reproduce the statistics of the held-out data? However, recent studies have shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated. In other words, optimizing for perplexity may not yield human interpretable topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Topic Coherence\n",
    "The concept of topic coherence combines a number of measures into a framework to evaluate the coherence between topics inferred by a model. \n",
    "\n",
    "Topic Coherence measures the score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "\n",
    "Coherence is a set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”\n",
    "\n",
    "There are several ways to measure coherence. We'll use a method called `c_v`. It's a measure based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity. \n",
    "\n",
    "Two other coherence measures are:\n",
    "1. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
    "2. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
    "\n",
    "First, let's import `CoherenceModel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the coherence score. We've run everything that we need already, so it's a matter of putting it into our function. The default `coherence` parameter is `c_v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                     texts=initial_corpus,\n",
    "                                     dictionary=dictionary_LDA,\n",
    "                                     coherence='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the `.get_coherence()` method from our coherence object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184718333827097"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a rather low coherence value. We want the lowest number of `K` topics while also yielding the highest coherence values. \n",
    "\n",
    "We would want to re-run the model with different values of `K` so that our model yields the highest coherence score possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## A Better Approach with `UMass`\n",
    "\n",
    "Coherence metric is popular because it’s the default metric in the `Gensim` topic coherence pipeline module, but it has some issues. Even the author of this metric doesn’t recommend using it.\n",
    "\n",
    "Instead of using the CV score, we recommend using the UMass coherence score. It calculates how often two words, w_{i} and w_{j} appear together in the corpus and it’s defined as\n",
    "\n",
    "\\begin{equation*} C_{UMass}(w_{i}, w_{j}) = \\log \\frac{D(w_{i}, w_{j}) + 1}{D(w_{i})}, \\end{equation*}\n",
    "\n",
    "where D(w_{i}, w_{j}) indicates how many times words w_{i} and w_{j} appear together in documents, and D(w_{i}) is how many time word w_{i} appeared alone. \n",
    "\n",
    "The greater the number, the better is coherence score. Also, this measure isn’t symmetric, which means that  C_{UMass}(w_{i}, w_{j})  is not equal to C_{UMass}(w_{j}, w_{i}). We calculate the global coherence of the topic as the average pairwise coherence scores on the top N words which describe the topic.\n",
    "\n",
    "All we have to do is pass in `u_mass` for the `coherence` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                     texts=initial_corpus,\n",
    "                                     dictionary=dictionary_LDA,\n",
    "                                     coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0915128652378938"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic coherence with using `umass` decrease with an increase in the number of `K` topics. By contrast, topic coherence with `c_v` goes up when number of `K` topic increases. \n",
    "\n",
    "Since `umass` coherence is calculated over the log of probabilities,  it is negative. As the value of `umass` coherence approaches 0, the topic coherence improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## A (Second) Better Approach with `UCI`\n",
    "\n",
    "The `UCI` coherence score is based on sliding windows and the pointwise mutual information of all word pairs using top N words by occurrence. \n",
    "\n",
    "Instead of calculating how often two words appear in the document, we calculate the word co-occurrence using a sliding window. It means that if our sliding window has a size of 10, for one particular word w_{i}, we observe only 10 words before and after the word w_{i}.\n",
    "\n",
    "Therefore, if both words w_{i} and w_{j} appeared in the document but they’re not together in one sliding window, we don’t count as they appeared together. Similarly, as for the UMass score, we define the UCI coherence between words w_{i} and w_{j} as\n",
    "\n",
    "\\begin{equation*} C_{UCI}(w_{i}, w_{j}) = \\log \\frac{P(w_{i}, w_{j}) + 1}{P(w_{i}) \\cdot P(w_{j})}. \\end{equation*}\n",
    "\n",
    "where P(w) is probability of seeing word w in the sliding window and P(w_{i}, w_{j}) is probability of appearing words w_{i} and w_{j} together in the sliding window. \n",
    "\n",
    "In the original paper, those probabilities were estimated from the entire corpus of over two million English Wikipedia articles using a 10-words sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                     texts=initial_corpus,\n",
    "                                     dictionary=dictionary_LDA,\n",
    "                                     coherence='c_uci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.965807267572388"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic coherence with using `uci` is similar to `umass` in that it is calculated over the log of probabilities, so it is also negative. It decrease with an increase in the number of `K` topics. So, as the value of `uci` coherence approaches 0, the topic coherence improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "***\n",
    "## LDA and `\"GridSearch\"`\n",
    "If you recall our `GridSearch` approach, we can perform a similar task here. We can actually test this out here. **However**, it'll require a lot of processing power! \n",
    "\n",
    "So, for our purposes here, we won't try it. That said, I provide code below where you can pass in the various parameters of the LDA model and it will calculate coherence scores. \n",
    "\n",
    "As with most machine learning models, you want to minimize `K` while yielding the highest value for coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=5):\n",
    "    \"\"\"\n",
    "    Compute u_mass coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics_K in range(start, limit, step):\n",
    "        lda_model_K = models.LdaMulticore(corpus,\\\n",
    "                            num_topics=num_topics_K,\\\n",
    "                                  id2word=dictionary,\\\n",
    "                                  alpha=[0.01]*num_topics_K)\n",
    "        \n",
    "        model_list.append(lda_model_K)\n",
    "        coherencemodel = CoherenceModel(model=lda_model_K, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it! This make take a few minutes, so be patient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary_LDA,\\\n",
    "                                                        corpus=LDA_corpus,\\\n",
    "                                                        texts=initial_corpus,\\\n",
    "                                                        start=5,\\\n",
    "                                                        limit=30,\\\n",
    "                                                        step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence_df = pd.DataFrame({\"K\":range(5,30,5),\"Coherence_Scores\":coherence_values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then map out these values and plot them to find what the best coherence score might be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ual-laptop\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib_inline\\config.py:68: DeprecationWarning: InlineBackend._figure_format_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 640
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure Size: (640 x 480)>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ggplot(data=Coherence_df,\n",
    "        mapping=aes(x=\"K\",y=\"Coherence_Scores\"))+\n",
    "   geom_point()+\n",
    "   geom_line()+\n",
    "   labs(y=\"Coherence Scores (U-Mass)\")+\n",
    "   theme_bw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using `u_mass` and we want our coherence score as close to zero as possible, it looks like `K`=10 topics is the best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 7\n",
    "\n",
    "Now you try!\n",
    "\n",
    "Re-run the LDA model with the New York Times data with two new different values of `K` (one larger than the decision you picked before and one smaller) and calculate the coherence scores for the two new values of `K`. (DO NOT use the function above, unless you have lots of time!) \n",
    "\n",
    "Based on the coherence scores, which of the three values of `K` is optimal?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYmodel_list, NYcoherence_values = compute_coherence_values(dictionary=NYTimes_dictionary_LDA,\\\n",
    "                                                        corpus=NYTimes_corpus,\\\n",
    "                                                        texts=NYTimes_initial_corpus,\\\n",
    "                                                        start=5,\\\n",
    "                                                        limit=30,\\\n",
    "                                                        step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NYCoherence_df = pd.DataFrame({\"K\":range(5,30,5),\"Coherence_Scores\":NYcoherence_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 640
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure Size: (640 x 480)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ggplot(data=NYCoherence_df,\n",
    "        mapping=aes(x=\"K\",y=\"Coherence_Scores\"))+\n",
    "   geom_point()+\n",
    "   geom_line()+\n",
    "   labs(y=\"Coherence Scores (U-Mass)\")+\n",
    "   theme_bw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Author-Topic Models (ATMs) \n",
    "Source - https://nbviewer.org/github/rare-technologies/gensim/blob/develop/docs/notebooks/atmodel_tutorial.ipynb\n",
    "\n",
    "Now that we've learned how to build an LDA model and how to use `gensim`, running more interesting models is streamlined. While the LDA model is good for some exploratory work and is the conceptual foundation for other topic models, we should look to use other topic models that can help us answer more interesting questions. \n",
    "\n",
    "The Author-Topic Model (ATM) is an extension of Latent Dirichlet Allocation (LDA), that allows us to learn topic representations of authors in a corpus. \n",
    "\n",
    "***The word \"Author\" in the model's name is misleading: The model can be applied to ANY kinds of labels on documents, such as tags on posts on the web. Note that it is being renamed locally to `LabelTopicModel` to reference the true functionality.*** \n",
    "\n",
    "The model can be used as a novel way of data exploration, as features in machine learning pipelines, for author (or tag) prediction, or to simply leverage your topic model with existing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import AuthorTopicModel as LabelTopicModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of an ATM is similar to that of an LDA using `gensim`. We have similar inputs, like the `corpus`, the number of topics `num_topics`, etc. \n",
    "\n",
    "The big difference is the `author2doc` input, which associated with each document in the corpus, the authors tagged to it. Again \"authors\" can mean any label associated with the documents (e.g., year, countries, etc.), so \"LTM\" (for Label-Topic Model) will be how it is referred to from now on.\n",
    "\n",
    "```python\n",
    "MY_LTM = LabelTopicModel(corpus=corpus, \n",
    "                num_topics=10, \n",
    "                id2word=dictionary.id2token,\n",
    "                author2doc=author2doc, #New Addition!\n",
    "                chunksize=2000, \n",
    "                passes=1, \n",
    "                eval_every=0,\n",
    "                iterations=1, \n",
    "                random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first pass in the value for `author2doc`. This ultimately will be a `Dictionary`, where the `keys`  are the unique country affiliations in our data and the `values` are the document ids where at least one country affiliation is associated to the document. \n",
    "\n",
    "We'll need to work with our `Text_df` `DataFrame` to create this `Dictionary`. \n",
    "\n",
    "First, let's select the column `countries` into it's own `DataFrame`.\n",
    "\n",
    "N.B., the indices for `Text_df` will serve as our ***de facto*** document id that we will later use to map on to our other values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2doc = ((Text_df >>\n",
    "               head(4000) >> #Recall we only looked at the first 4000 rows for the LDA model.\n",
    "select(\"countries\")).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           countries\n",
       "0      United States\n",
       "1     United Kingdom\n",
       "2            Germany\n",
       "3       South Africa\n",
       "4      United States\n",
       "...              ...\n",
       "3995          Russia\n",
       "3996         Ireland\n",
       "3997          Turkey\n",
       "3998         Austria\n",
       "3999  United Kingdom\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows will have more than one country associated with it, representing an international collaboration between authors in different countries. \n",
    "\n",
    "We need to take each entry and create a list of these country associations. For most rows, this will be a row with a single entry, but for others, it will be a list containing several country affiliations. \n",
    "\n",
    "Luckily with our data, each country affiliation in an international row is separated by a comma. So, let's use `apply()` to each row and split the string that contains country affiliations by the comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2doc = (label2doc.reset_index() >>\n",
    " rename(ID = 'index') >>\n",
    " mutate(countries = X.countries.apply(lambda x: x.split(\", \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[United States]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Germany]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[South Africa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[United States]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3995</td>\n",
       "      <td>[Russia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3996</td>\n",
       "      <td>[Ireland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3997</td>\n",
       "      <td>[Turkey]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3998</td>\n",
       "      <td>[Austria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3999</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID         countries\n",
       "0        0   [United States]\n",
       "1        1  [United Kingdom]\n",
       "2        2         [Germany]\n",
       "3        3    [South Africa]\n",
       "4        4   [United States]\n",
       "...    ...               ...\n",
       "3995  3995          [Russia]\n",
       "3996  3996         [Ireland]\n",
       "3997  3997          [Turkey]\n",
       "3998  3998         [Austria]\n",
       "3999  3999  [United Kingdom]\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when we pass in these data into our author topic model, we want one row per country affiliation. So, some rows with international collaborators will have mutliple rows, but will have the same ID. \n",
    "\n",
    "We can use the `pandas` method called `explore()` which expands lists in each row so that every element in the list is its own row. Hence, the method \"`explodes`\" the `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2doc = label2doc.explode(\"countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look. As you'll see, there aren't any more lists, and multiple entries are now there own rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3995</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3996</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3997</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3998</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3999</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID       countries\n",
       "0        0   United States\n",
       "1        1  United Kingdom\n",
       "2        2         Germany\n",
       "3        3    South Africa\n",
       "4        4   United States\n",
       "...    ...             ...\n",
       "3995  3995          Russia\n",
       "3996  3996         Ireland\n",
       "3997  3997          Turkey\n",
       "3998  3998         Austria\n",
       "3999  3999  United Kingdom\n",
       "\n",
       "[4917 rows x 2 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll need to pass in the affiliations as a `Dictionary` to the author topic model. The `key` will be the country affiliations and for each one, we'll compile the IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2doc = label2doc.groupby(\"countries\")[\"ID\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in action. Let's see which document IDs have at least one author from \"Australia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 33,\n",
       " 38,\n",
       " 46,\n",
       " 48,\n",
       " 59,\n",
       " 60,\n",
       " 63,\n",
       " 72,\n",
       " 108,\n",
       " 126,\n",
       " 142,\n",
       " 196,\n",
       " 207,\n",
       " 220,\n",
       " 222,\n",
       " 230,\n",
       " 249,\n",
       " 252,\n",
       " 314,\n",
       " 315,\n",
       " 361,\n",
       " 366,\n",
       " 372,\n",
       " 376,\n",
       " 380,\n",
       " 398,\n",
       " 415,\n",
       " 424,\n",
       " 425,\n",
       " 440,\n",
       " 451,\n",
       " 464,\n",
       " 466,\n",
       " 489,\n",
       " 496,\n",
       " 511,\n",
       " 537,\n",
       " 559,\n",
       " 566,\n",
       " 573,\n",
       " 578,\n",
       " 599,\n",
       " 620,\n",
       " 627,\n",
       " 665,\n",
       " 678,\n",
       " 692,\n",
       " 693,\n",
       " 703,\n",
       " 746,\n",
       " 756,\n",
       " 776,\n",
       " 787,\n",
       " 825,\n",
       " 834,\n",
       " 842,\n",
       " 855,\n",
       " 870,\n",
       " 885,\n",
       " 896,\n",
       " 905,\n",
       " 909,\n",
       " 912,\n",
       " 917,\n",
       " 927,\n",
       " 953,\n",
       " 985,\n",
       " 989,\n",
       " 993,\n",
       " 999,\n",
       " 1048,\n",
       " 1080,\n",
       " 1099,\n",
       " 1103,\n",
       " 1108,\n",
       " 1131,\n",
       " 1138,\n",
       " 1144,\n",
       " 1147,\n",
       " 1150,\n",
       " 1156,\n",
       " 1178,\n",
       " 1186,\n",
       " 1188,\n",
       " 1240,\n",
       " 1247,\n",
       " 1263,\n",
       " 1268,\n",
       " 1280,\n",
       " 1301,\n",
       " 1304,\n",
       " 1305,\n",
       " 1306,\n",
       " 1320,\n",
       " 1328,\n",
       " 1334,\n",
       " 1337,\n",
       " 1348,\n",
       " 1372,\n",
       " 1458,\n",
       " 1460,\n",
       " 1473,\n",
       " 1480,\n",
       " 1501,\n",
       " 1503,\n",
       " 1522,\n",
       " 1530,\n",
       " 1546,\n",
       " 1551,\n",
       " 1567,\n",
       " 1569,\n",
       " 1580,\n",
       " 1588,\n",
       " 1592,\n",
       " 1594,\n",
       " 1650,\n",
       " 1675,\n",
       " 1683,\n",
       " 1711,\n",
       " 1731,\n",
       " 1750,\n",
       " 1765,\n",
       " 1774,\n",
       " 1776,\n",
       " 1805,\n",
       " 1808,\n",
       " 1838,\n",
       " 1843,\n",
       " 1851,\n",
       " 1874,\n",
       " 1875,\n",
       " 1906,\n",
       " 1954,\n",
       " 1955,\n",
       " 1957,\n",
       " 1963,\n",
       " 1972,\n",
       " 1973,\n",
       " 1982,\n",
       " 1990,\n",
       " 2008,\n",
       " 2014,\n",
       " 2016,\n",
       " 2048,\n",
       " 2050,\n",
       " 2055,\n",
       " 2071,\n",
       " 2072,\n",
       " 2074,\n",
       " 2085,\n",
       " 2093,\n",
       " 2102,\n",
       " 2115,\n",
       " 2149,\n",
       " 2161,\n",
       " 2163,\n",
       " 2171,\n",
       " 2179,\n",
       " 2217,\n",
       " 2229,\n",
       " 2244,\n",
       " 2263,\n",
       " 2277,\n",
       " 2289,\n",
       " 2290,\n",
       " 2297,\n",
       " 2298,\n",
       " 2309,\n",
       " 2334,\n",
       " 2342,\n",
       " 2356,\n",
       " 2362,\n",
       " 2364,\n",
       " 2366,\n",
       " 2383,\n",
       " 2400,\n",
       " 2411,\n",
       " 2415,\n",
       " 2423,\n",
       " 2425,\n",
       " 2430,\n",
       " 2453,\n",
       " 2500,\n",
       " 2502,\n",
       " 2516,\n",
       " 2527,\n",
       " 2542,\n",
       " 2562,\n",
       " 2594,\n",
       " 2602,\n",
       " 2605,\n",
       " 2612,\n",
       " 2616,\n",
       " 2622,\n",
       " 2646,\n",
       " 2652,\n",
       " 2653,\n",
       " 2687,\n",
       " 2702,\n",
       " 2730,\n",
       " 2750,\n",
       " 2754,\n",
       " 2755,\n",
       " 2763,\n",
       " 2764,\n",
       " 2772,\n",
       " 2800,\n",
       " 2815,\n",
       " 2832,\n",
       " 2895,\n",
       " 2917,\n",
       " 2926,\n",
       " 2933,\n",
       " 2958,\n",
       " 2960,\n",
       " 2971,\n",
       " 2983,\n",
       " 2986,\n",
       " 3004,\n",
       " 3018,\n",
       " 3020,\n",
       " 3023,\n",
       " 3034,\n",
       " 3073,\n",
       " 3074,\n",
       " 3075,\n",
       " 3079,\n",
       " 3100,\n",
       " 3125,\n",
       " 3129,\n",
       " 3151,\n",
       " 3164,\n",
       " 3173,\n",
       " 3184,\n",
       " 3218,\n",
       " 3220,\n",
       " 3223,\n",
       " 3243,\n",
       " 3244,\n",
       " 3245,\n",
       " 3250,\n",
       " 3253,\n",
       " 3289,\n",
       " 3305,\n",
       " 3316,\n",
       " 3326,\n",
       " 3328,\n",
       " 3340,\n",
       " 3349,\n",
       " 3353,\n",
       " 3379,\n",
       " 3387,\n",
       " 3391,\n",
       " 3397,\n",
       " 3411,\n",
       " 3435,\n",
       " 3440,\n",
       " 3447,\n",
       " 3465,\n",
       " 3470,\n",
       " 3475,\n",
       " 3476,\n",
       " 3498,\n",
       " 3505,\n",
       " 3512,\n",
       " 3524,\n",
       " 3534,\n",
       " 3539,\n",
       " 3541,\n",
       " 3557,\n",
       " 3558,\n",
       " 3585,\n",
       " 3619,\n",
       " 3638,\n",
       " 3669,\n",
       " 3687,\n",
       " 3692,\n",
       " 3709,\n",
       " 3715,\n",
       " 3718,\n",
       " 3734,\n",
       " 3736,\n",
       " 3764,\n",
       " 3772,\n",
       " 3777,\n",
       " 3795,\n",
       " 3816,\n",
       " 3832,\n",
       " 3834,\n",
       " 3837,\n",
       " 3839,\n",
       " 3863,\n",
       " 3872,\n",
       " 3897,\n",
       " 3913,\n",
       " 3920,\n",
       " 3931,\n",
       " 3977,\n",
       " 3993]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2doc['Australia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up our model parameters in the same was as the LDA model (e.g., number of topics, alpha, etc.)\n",
    "\n",
    "The **only** difference is the dictionary that we'll pass in for the `author2doc` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m LT_Model \u001b[38;5;241m=\u001b[39m \u001b[43mLabelTopicModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLDA_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary_LDA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mauthor2doc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel2doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:323\u001b[0m, in \u001b[0;36mAuthorTopicModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, author2doc, doc2author, chunksize, passes, iterations, decay, offset, alpha, eta, update_every, eval_every, gamma_threshold, serialized, serialization_path, minimum_probability, random_state)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (author2doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m doc2author \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    322\u001b[0m     use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthor2doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc2author\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:847\u001b[0m, in \u001b[0;36mAuthorTopicModel.update\u001b[1;34m(self, corpus, author2doc, doc2author, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    844\u001b[0m reallen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_no, chunk_doc_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    846\u001b[0m         utils\u001b[38;5;241m.\u001b[39mgrouper(train_corpus_idx, chunksize, as_numpy\u001b[38;5;241m=\u001b[39mchunks_as_numpy)):\n\u001b[1;32m--> 847\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_doc_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    848\u001b[0m     reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;66;03m# log_perplexity requires the indexes of the documents being evaluated, to know what authors\u001b[39;00m\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# correspond to the documents.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:847\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    844\u001b[0m reallen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_no, chunk_doc_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    846\u001b[0m         utils\u001b[38;5;241m.\u001b[39mgrouper(train_corpus_idx, chunksize, as_numpy\u001b[38;5;241m=\u001b[39mchunks_as_numpy)):\n\u001b[1;32m--> 847\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m chunk_doc_idx]\n\u001b[0;32m    848\u001b[0m     reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;66;03m# log_perplexity requires the indexes of the documents being evaluated, to know what authors\u001b[39;00m\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# correspond to the documents.\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "LT_Model = LabelTopicModel(corpus=LDA_corpus, \n",
    "                             num_topics=10, \n",
    "                             id2word=dictionary_LDA,\n",
    "                             author2doc=label2doc, \n",
    "                             alpha=[0.01]*10,\n",
    "                             random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Optimizing the LTM\n",
    "\n",
    "Before we explore the model, let's try to improve it. \n",
    "\n",
    "To do this, we will train several models with different random initializations, by giving different seeds for the random number generator (random_state). We evaluate the topic coherence of the model using the top_topics method, and pick the model with the highest topic coherence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_list \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m#Create a list where each entry will be an ATM with a different number of topics. \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topics_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m35\u001b[39m,\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     lt_model \u001b[38;5;241m=\u001b[39m \u001b[43mLabelTopicModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLDA_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopics_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary_LDA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mauthor2doc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel2doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtopics_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     ltm_coherence_k \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlt_model, texts\u001b[38;5;241m=\u001b[39minitial_corpus, dictionary\u001b[38;5;241m=\u001b[39mdictionary_LDA, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_mass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     model_list[topics_] \u001b[38;5;241m=\u001b[39m ltm_coherence_k\u001b[38;5;241m.\u001b[39mget_coherence()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:323\u001b[0m, in \u001b[0;36mAuthorTopicModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, author2doc, doc2author, chunksize, passes, iterations, decay, offset, alpha, eta, update_every, eval_every, gamma_threshold, serialized, serialization_path, minimum_probability, random_state)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (author2doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m doc2author \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    322\u001b[0m     use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthor2doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc2author\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:847\u001b[0m, in \u001b[0;36mAuthorTopicModel.update\u001b[1;34m(self, corpus, author2doc, doc2author, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    844\u001b[0m reallen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_no, chunk_doc_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    846\u001b[0m         utils\u001b[38;5;241m.\u001b[39mgrouper(train_corpus_idx, chunksize, as_numpy\u001b[38;5;241m=\u001b[39mchunks_as_numpy)):\n\u001b[1;32m--> 847\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_doc_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    848\u001b[0m     reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;66;03m# log_perplexity requires the indexes of the documents being evaluated, to know what authors\u001b[39;00m\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# correspond to the documents.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\gensim\\models\\atmodel.py:847\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    844\u001b[0m reallen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_no, chunk_doc_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    846\u001b[0m         utils\u001b[38;5;241m.\u001b[39mgrouper(train_corpus_idx, chunksize, as_numpy\u001b[38;5;241m=\u001b[39mchunks_as_numpy)):\n\u001b[1;32m--> 847\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m chunk_doc_idx]\n\u001b[0;32m    848\u001b[0m     reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;66;03m# log_perplexity requires the indexes of the documents being evaluated, to know what authors\u001b[39;00m\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# correspond to the documents.\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model_list = {} #Create a list where each entry will be an ATM with a different number of topics. \n",
    "for topics_ in range(5,35,5):\n",
    "    lt_model = LabelTopicModel(corpus=LDA_corpus, \n",
    "                             num_topics=topics_, \n",
    "                             id2word=dictionary_LDA,\n",
    "                             author2doc=label2doc, \n",
    "                             alpha=[0.01]*topics_,\n",
    "                              random_state=0)\n",
    "    \n",
    "    ltm_coherence_k = CoherenceModel(model=lt_model, texts=initial_corpus, dictionary=dictionary_LDA, coherence='u_mass')\n",
    "    model_list[topics_] = ltm_coherence_k.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model with the highest topic coherence.\n",
    "\n",
    "Let's set up the data and plot it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTM_Coherence_df = pd.DataFrame.from_dict(model_list,columns=[\"Coherence\"],orient='index').rename_axis(\"K\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    701\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    702\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    704\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    705\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    706\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    707\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 708\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\lib\\pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[0;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\lib\\pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(obj)\n\u001b[0;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\ggplot.py:114\u001b[0m, in \u001b[0;36mggplot.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Print/show the plot\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     figure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     dpi \u001b[38;5;241m=\u001b[39m figure\u001b[38;5;241m.\u001b[39mget_dpi()\n\u001b[0;32m    117\u001b[0m     W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(figure\u001b[38;5;241m.\u001b[39mget_figwidth() \u001b[38;5;241m*\u001b[39m dpi)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\ggplot.py:224\u001b[0m, in \u001b[0;36mggplot.draw\u001b[1;34m(self, show)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_context(\u001b[38;5;28mself\u001b[39m, show\u001b[38;5;241m=\u001b[39mshow):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# setup\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     figure, axs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_figure()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\ggplot.py:325\u001b[0m, in \u001b[0;36mggplot._build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Map and train positions so that statistics have access\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# to ranges and all positions are numeric\u001b[39;00m\n\u001b[0;32m    324\u001b[0m layout\u001b[38;5;241m.\u001b[39mtrain_position(layers, scales)\n\u001b[1;32m--> 325\u001b[0m \u001b[43mlayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# Apply and map statistics\u001b[39;00m\n\u001b[0;32m    328\u001b[0m layers\u001b[38;5;241m.\u001b[39mcompute_statistic(layout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\facets\\layout.py:130\u001b[0m, in \u001b[0;36mLayout.map_position\u001b[1;34m(self, layers)\u001b[0m\n\u001b[0;32m    126\u001b[0m     x_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanel_scales_x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maesthetics) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m     SCALE_X \u001b[38;5;241m=\u001b[39m _layout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCALE_X\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[match_id]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpanel_scales_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCALE_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanel_scales_y:\n\u001b[0;32m    133\u001b[0m     y_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanel_scales_y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maesthetics) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    135\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\scales\\scales.py:181\u001b[0m, in \u001b[0;36mScales.map\u001b[1;34m(self, data, vars, idx)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    180\u001b[0m     bool_idx \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m==\u001b[39m idx\n\u001b[1;32m--> 181\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbool_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_df:\n\u001b[0;32m    183\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[bool_idx, col] \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\plotnine\\scales\\scale_xy.py:85\u001b[0m, in \u001b[0;36mscale_position_discrete.map\u001b[1;34m(self, series, limits)\u001b[0m\n\u001b[0;32m     82\u001b[0m     limits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimits\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array_kind\u001b[38;5;241m.\u001b[39mdiscrete(series):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# TODO: Rewrite without using numpy\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     seq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     86\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(match(series, limits, nomatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(series)))\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx):\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "(ggplot(data=LTM_Coherence_df,\n",
    "        mapping=aes(x=\"K\",y=\"Coherence\"))+\n",
    "   geom_point()+\n",
    "   geom_line()+\n",
    "   labs(y=\"Coherence Scores (U-Mass)\")+\n",
    "   theme_bw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `K`=5 works best!\n",
    "\n",
    "***\n",
    "## Saving the Model. \n",
    "\n",
    "Training these models take a long time! \n",
    "\n",
    "So, we save the model and its parameter files to avoid having to train it again. Let's use `pickle` here. \n",
    "\n",
    "Let's import `bz2` to compress the file to save hard drive space and `cPickle` to save these objects to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LT_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput/My_First_LT_Model.pbz2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bz2\u001b[38;5;241m.\u001b[39mBZ2File(output_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \u001b[38;5;66;03m# This is saving the file. \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     cPickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mLT_Model\u001b[49m, f) \u001b[38;5;66;03m# This is the model we just ran. \u001b[39;00m\n\u001b[0;32m      5\u001b[0m     cPickle\u001b[38;5;241m.\u001b[39mdump(dictionary_LDA, f) \u001b[38;5;66;03m# This is the dictionary. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     cPickle\u001b[38;5;241m.\u001b[39mdump(label2doc, f) \u001b[38;5;66;03m# This is the author2doc dictionary.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LT_Model' is not defined"
     ]
    }
   ],
   "source": [
    "output_filename = \"Output/My_First_LT_Model.pbz2\"\n",
    "\n",
    "with bz2.BZ2File(output_filename, 'w') as f: # This is saving the file. \n",
    "    cPickle.dump(LT_Model, f) # This is the model we just ran. \n",
    "    cPickle.dump(dictionary_LDA, f) # This is the dictionary. \n",
    "    cPickle.dump(label2doc, f) # This is the author2doc dictionary.\n",
    "f.close() # Close the buffer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after saving our model, let's re-load it back into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[188], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m f \u001b[38;5;241m=\u001b[39m bz2\u001b[38;5;241m.\u001b[39mBZ2File(output_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m LT_Model \u001b[38;5;241m=\u001b[39m \u001b[43mcPickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dictionary_LDA \u001b[38;5;241m=\u001b[39m cPickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m label2doc \u001b[38;5;241m=\u001b[39m cPickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "f = bz2.BZ2File(output_filename, 'rb')\n",
    "LT_Model = cPickle.load(f)\n",
    "dictionary_LDA = cPickle.load(f)\n",
    "label2doc = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 8\n",
    "\n",
    "Now you try!\n",
    "\n",
    "We initially ran our author-topic model with `K`=10 topics. Rerun it with the optimal number of `K` topics from our coherence figure. Be sure to rename your author-topic model object to something different, like `Optimal_LT_Model`.\n",
    "    \n",
    "Pickle just this model to your `Output/` folder and call it `My_Optimal_LT_Model.pbz2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Exploring Label-Topic Representation\n",
    "Now that we have trained a model, we can start exploring the labels and the topics.\n",
    "\n",
    "First, let's simply print the most important words in the topics. \n",
    "\n",
    "Let's look at the ten topics we created. \n",
    "\n",
    "As we can see, each topic is associated with a set of words, and each word has a probability of being expressed under that topic.\n",
    "\n",
    "For your own work, you'd want to run this multiple times, each time choosing different parameters and trimming your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LT_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mLT_Model\u001b[49m\u001b[38;5;241m.\u001b[39mshow_topic(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LT_Model' is not defined"
     ]
    }
   ],
   "source": [
    "LT_Model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LT_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mLT_Model\u001b[49m\u001b[38;5;241m.\u001b[39mshow_topic(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LT_Model' is not defined"
     ]
    }
   ],
   "source": [
    "LT_Model.show_topic(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would want to give a name to each topic based on what each one seems to be about intuitively. This is where topic modelling is more of an \"art\" than a \"science\" and requires subject matter expertise. \n",
    "\n",
    "For our purposes here and for simplicity, we're just going to call them by numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = [str(x) for x in range(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just calling `model.show_topics(num_topics=10)`, we format the output a bit so it is easier to get an overview.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LT_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[43mLT_Model\u001b[49m\u001b[38;5;241m.\u001b[39mshow_topics(num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m topic_labels[topic[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      3\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LT_Model' is not defined"
     ]
    }
   ],
   "source": [
    "for topic in LT_Model.show_topics(num_topics=10):\n",
    "    print('Topic: ' + topic_labels[topic[0]])\n",
    "    words = ''\n",
    "    \n",
    "    for word, prob in LT_Model.show_topic(topic[0]):\n",
    "        words += word + ' '\n",
    "    print('Words: ' + words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics are by no means perfect. They have problems such as chained topics, intruded words, random topics, and unbalanced topics (see Mimno and co-authors 2011). They will do for the purposes of this tutorial, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 9\n",
    "\n",
    "Now you try!\n",
    "\n",
    "Load in the optimal author-topic model you pickeled and print out the top terms for each of the `K`=5 topics. \n",
    "    \n",
    "Instead of numbering them 0 through 4, name these topics. There are not wrong answers, but give it a good try! You'll eventually need to do this with your own data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Label Similarity \n",
    "\n",
    "In this section, we are going to set up a system that takes a label and yields the labels that are most similar. This functionality can be used as a component in an information retrieval (i.e. a search engine of some kind), or in an author prediction system, i.e. a system that takes an unlabelled document and predicts the author(s) that wrote it.\n",
    "\n",
    "We simply need to search for the closest vector in the label-topic space. In this sense, the approach is similar to the t-SNE plot above.\n",
    "\n",
    "Below we illustrate a similarity query using a built-in similarity framework in Gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can use the `model[name]` syntax to retrieve the topic distribution for an author. Each topic has a probability of being expressed given the particular author, but only the ones above a certain threshold are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lt_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlt_model\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lt_model' is not defined"
     ]
    }
   ],
   "source": [
    "lt_model['United States']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is helpful, because we can see which topics are popular with certain countries. \n",
    "\n",
    "Alterntively, what if we wanted to see how similar each country is to every other country?\n",
    "\n",
    "Let's use `gensim.similarities` to create a matrix of topic similarity for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a similarity object for the transformed corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LT_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[211], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m MatrixSimilarity(\u001b[43mLT_Model\u001b[49m[\u001b[38;5;28mlist\u001b[39m(LT_Model\u001b[38;5;241m.\u001b[39mid2author\u001b[38;5;241m.\u001b[39mvalues())])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LT_Model' is not defined"
     ]
    }
   ],
   "source": [
    "index = MatrixSimilarity(LT_Model[list(LT_Model.id2author.values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a list of all the countries present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "labellist = [label for label in label2doc.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'Antigua and Barbuda',\n",
       " 'Argentina',\n",
       " 'Armenia',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Azerbaijan',\n",
       " 'Bahrain',\n",
       " 'Bangladesh',\n",
       " 'Belarus',\n",
       " 'Belgium',\n",
       " 'Bhutan',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Botswana',\n",
       " 'Brazil',\n",
       " 'Brunei',\n",
       " 'Bulgaria',\n",
       " 'Cambodia',\n",
       " 'Canada',\n",
       " 'Chile',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Cyprus',\n",
       " 'Czechia',\n",
       " 'Denmark',\n",
       " 'Ecuador',\n",
       " 'Egypt',\n",
       " 'Estonia',\n",
       " 'Eswatini',\n",
       " 'Ethiopia',\n",
       " 'Fiji',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'Georgia',\n",
       " 'Germany',\n",
       " 'Ghana',\n",
       " 'Greece',\n",
       " 'Hungary',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Iran',\n",
       " 'Iraq',\n",
       " 'Ireland',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Kazakhstan',\n",
       " 'Kenya',\n",
       " 'Kosovo',\n",
       " 'Kyrgyzstan',\n",
       " 'Latvia',\n",
       " 'Lebanon',\n",
       " 'Libya',\n",
       " 'Lithuania',\n",
       " 'Luxembourg',\n",
       " 'Malaysia',\n",
       " 'Mali',\n",
       " 'Malta',\n",
       " 'Mexico',\n",
       " 'Moldova',\n",
       " 'Mongolia',\n",
       " 'Montenegro',\n",
       " 'Morocco',\n",
       " 'Mozambique',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Nepal',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Nigeria',\n",
       " 'North Macedonia',\n",
       " 'Norway',\n",
       " 'Oman',\n",
       " 'Pakistan',\n",
       " 'Palestinian Territory',\n",
       " 'Paraguay',\n",
       " 'Peru',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Qatar',\n",
       " 'Romania',\n",
       " 'Russia',\n",
       " 'Saudi Arabia',\n",
       " 'Serbia',\n",
       " 'Singapore',\n",
       " 'Slovakia',\n",
       " 'Slovenia',\n",
       " 'South Africa',\n",
       " 'South Korea',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Taiwan',\n",
       " 'Tajikistan',\n",
       " 'Tanzania',\n",
       " 'Thailand',\n",
       " 'Trinidad and Tobago',\n",
       " 'Tunisia',\n",
       " 'Turkey',\n",
       " 'Uganda',\n",
       " 'Ukraine',\n",
       " 'United Arab Emirates',\n",
       " 'United Kingdom',\n",
       " 'United States',\n",
       " 'Uzbekistan',\n",
       " 'Vietnam',\n",
       " 'Zambia',\n",
       " 'Zimbabwe']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labellist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get similarities to a sample country. Let's pick the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m sims \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mindex\u001b[49m[LT_Model[label]],columns\u001b[38;5;241m=\u001b[39m[label],index\u001b[38;5;241m=\u001b[39mlabellist)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "label = 'United States'\n",
    "sims = pd.DataFrame(index[LT_Model[label]],columns=[label],index=labellist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, let's only consider other countries whose similarity is non-zero but less than 1. \n",
    "\n",
    "For this example, we'll get odd results. \n",
    "\n",
    "We'd likely need more data and to parse the data more extensively to really get some meaningful results. This would include more meaningfully removing certain non-informative terms, different parameters, excluding countris with small ***n*** number of documents, etc. \n",
    "\n",
    "The point here is that once you do this over several iterations, you can start to see meaningful patterns in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (\u001b[43msims\u001b[49m\u001b[38;5;241m>>\u001b[39m\n\u001b[0;32m      2\u001b[0m  mask(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m,X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m>>\u001b[39m\n\u001b[0;32m      3\u001b[0m arrange(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sims' is not defined"
     ]
    }
   ],
   "source": [
    "(sims>>\n",
    " mask(X['United States']>0,X['United States']!=1)>>\n",
    "arrange(X['United States']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create the full similarity matrix and look at how every country compares to every other country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[216], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m similarity_matrix_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[43m[\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLT_Model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlabel_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabellist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabellist\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[216], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m similarity_matrix_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mindex\u001b[49m[LT_Model[label_]],columns\u001b[38;5;241m=\u001b[39m[label_],index\u001b[38;5;241m=\u001b[39mlabellist) \u001b[38;5;28;01mfor\u001b[39;00m label_ \u001b[38;5;129;01min\u001b[39;00m labellist], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_matrix_df = pd.concat([pd.DataFrame(index[LT_Model[label_]],columns=[label_],index=labellist) for label_ in labellist], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_matrix_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[217], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msimilarity_matrix_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity_matrix_df' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_matrix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Checkpoint 10\n",
    "\n",
    "Now you try!\n",
    "\n",
    "Create the similarity matrix using your `K`=5 label-topic model. Also explore the most similar and most dis-similar countries compared to the United States. How do your results differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "***Be sure to turn off your kernel before closing!***\n",
    "    \n",
    "<p style=\"text-align:center;\">\n",
    "        <img src=Images/Best_Practice.png width=500 class=\"center\">\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
